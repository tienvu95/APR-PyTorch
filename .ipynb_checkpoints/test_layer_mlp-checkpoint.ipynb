{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6456030",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.regularizers import l1,l2\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Embedding,Input,Dense,Flatten,Lambda, Multiply, Concatenate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79641089",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(num_users,num_items,mf_dim=10,layers=[10],reg_layers=[0,0,0,0],reg_mf=0):\n",
    "    num_layer=len(layers)\n",
    "\n",
    "    user_input=Input(shape=(1,),dtype='int32')\n",
    "    item_input_pos=Input(shape=(1,),dtype='int32')\n",
    "    item_input_neg = Input(shape=(1,), dtype='int32')\n",
    "\n",
    "    ## in this context each point is projected to have 10 dimensional coordinates?\n",
    "    MF_embedding_user=Embedding(input_dim=num_users,output_dim=mf_dim,embeddings_initializer='random_normal',\n",
    "                                name='mf_user_embedding',embeddings_regularizer=l2(reg_mf),input_length=1)\n",
    "    MF_embedding_item = Embedding(input_dim=num_items, output_dim=mf_dim, embeddings_initializer='random_normal',\n",
    "                                  name='mf_item_embedding',embeddings_regularizer=l2(reg_mf), input_length=1)\n",
    "    MLP_embedding_user=Embedding(input_dim=num_users,output_dim=layers[0],embeddings_initializer='random_normal',\n",
    "                                 name='mlp_user_embedding', embeddings_regularizer=l2(reg_mf),input_length=1)\n",
    "    MLP_embedding_item = Embedding(input_dim=num_items, output_dim=layers[0], embeddings_initializer='random_normal',\n",
    "                                   name='mlp_item_embedding',embeddings_regularizer=l2(reg_mf), input_length=1)\n",
    "\n",
    "    mf_user_latent=Flatten()(MF_embedding_user(user_input))\n",
    "    mf_item_latent_pos=Flatten()(MF_embedding_item(item_input_pos))\n",
    "    mf_item_latent_neg = Flatten()(MF_embedding_item(item_input_neg))\n",
    "\n",
    "    ## merge = deprecated use keras.layers.Concatenate(axis=-1) instead\n",
    "    prefer_pos = merge([mf_user_latent, mf_item_latent_pos], mode='mul')\n",
    "    prefer_neg = merge([mf_user_latent, mf_item_latent_neg], mode='mul')\n",
    "    ## convert negative layer to negative, lambda layers should be re-written as subclass layer if too complex (eg: multiply by scale?)\n",
    "    prefer_neg = Lambda(lambda x: -x)(prefer_neg)\n",
    "    ## basically just merge 2 layer\n",
    "    mf_vector = merge([prefer_pos, prefer_neg], mode='concat')\n",
    "\n",
    "    ## flat matrix to an array\n",
    "    mlp_user_latent=Flatten()(MLP_embedding_user(user_input))\n",
    "    mlp_item_latent_pos=Flatten()(MLP_embedding_item(item_input_pos))\n",
    "    mlp_item_latent_neg=Flatten()(MLP_embedding_item(item_input_neg))\n",
    "    mlp_item_latent_neg=Lambda(lambda x:-x)(mlp_item_latent_neg)\n",
    "    mlp_vector=merge([mlp_user_latent,mlp_item_latent_pos,mlp_item_latent_neg],mode='concat')\n",
    "    for idx in range(1,num_layer):\n",
    "        #set up hidden layer of the network, why tanh and have to regularize?? L1 consider weight, l2 consider square of weight\n",
    "        layer=Dense(layers[idx],kernel_regularizer=l2(0.0000),activation='tanh',name=\"layer%d\" %idx)\n",
    "        mlp_vector=layer(mlp_vector)\n",
    "\n",
    "    ## concatenation of NBPR layer and DNCR layer\n",
    "    predict_vector=merge([mf_vector,mlp_vector],mode='concat')\n",
    "\n",
    "\n",
    "    #set up prediction --> final layer, sigmoid activate to give binary output\n",
    "    prediction=Dense(1,activation='sigmoid',kernel_initializer='lecun_uniform',name='prediction')(predict_vector)\n",
    "    model=Model(inputs=[user_input,item_input_pos,item_input_neg],outputs=prediction)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efe4fdc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input=Input(shape=(1,),dtype='int32')\n",
    "item_input_pos=Input(shape=(1,),dtype='int32')\n",
    "item_input_neg = Input(shape=(1,), dtype='int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cdc327c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mf_dim=10\n",
    "layers=[10]\n",
    "num_layer=len(layers)\n",
    "reg_layers=[0,0,0,0]\n",
    "reg_mf=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e40dcb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "MF_embedding_user=Embedding(input_dim=2000,output_dim=mf_dim,embeddings_initializer='random_normal',\n",
    "                                name='mf_user_embedding',embeddings_regularizer=l2(reg_mf),input_length=1)\n",
    "MF_embedding_item = Embedding(input_dim=50000, output_dim=mf_dim, embeddings_initializer='random_normal',\n",
    "                                  name='mf_item_embedding',embeddings_regularizer=l2(reg_mf), input_length=1)\n",
    "MLP_embedding_user=Embedding(input_dim=2000,output_dim=layers[0],embeddings_initializer='random_normal',\n",
    "                                 name='mlp_user_embedding', embeddings_regularizer=l2(reg_mf),input_length=1)\n",
    "MLP_embedding_item = Embedding(input_dim=50000, output_dim=layers[0], embeddings_initializer='random_normal',\n",
    "                                   name='mlp_item_embedding',embeddings_regularizer=l2(reg_mf), input_length=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be3b68ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-14 23:27:03.991416: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "mf_user_latent=Flatten()(MF_embedding_user(user_input))\n",
    "mf_item_latent_pos=Flatten()(MF_embedding_item(item_input_pos))\n",
    "mf_item_latent_neg = Flatten()(MF_embedding_item(item_input_neg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4fdbf484",
   "metadata": {},
   "outputs": [],
   "source": [
    "## merge = deprecated use keras.layers.Concatenate(axis=-1) instead\n",
    "prefer_pos = Multiply()([mf_user_latent, mf_item_latent_pos])\n",
    "prefer_neg = Multiply()([mf_user_latent, mf_item_latent_neg])\n",
    "## convert negative layer to negative, lambda layers should be re-written as subclass layer if too complex (eg: multiply by scale?)\n",
    "prefer_neg = Lambda(lambda x: -x)(prefer_neg)\n",
    "## basically just merge 2 layer\n",
    "mf_vector = Concatenate()([prefer_pos, prefer_neg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b20f4e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_user_latent=Flatten()(MLP_embedding_user(user_input))\n",
    "mlp_item_latent_pos=Flatten()(MLP_embedding_item(item_input_pos))\n",
    "mlp_item_latent_neg=Flatten()(MLP_embedding_item(item_input_neg))\n",
    "mlp_item_latent_neg=Lambda(lambda x:-x)(mlp_item_latent_neg)\n",
    "mlp_vector=Concatenate()([mlp_user_latent,mlp_item_latent_pos,mlp_item_latent_neg])\n",
    "for idx in range(1,num_layer):\n",
    "    #set up hidden layer of the network, why tanh and have to regularize?? L1 consider weight, l2 consider square of weight\n",
    "    layer=Dense(layers[idx],kernel_regularizer=l2(0.0000),activation='tanh',name=\"layer%d\" %idx)\n",
    "    mlp_vector=layer(mlp_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2f9ce829",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_vector=Concatenate()([mf_vector,mlp_vector])\n",
    "\n",
    "\n",
    "#set up prediction --> final layer, sigmoid activate to give binary output\n",
    "prediction=Dense(3,kernel_initializer='lecun_uniform',name='prediction')(predict_vector)\n",
    "model=Model(inputs=[user_input,item_input_pos,item_input_neg],outputs=prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9886b91e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 3) dtype=float32 (created by layer 'prediction')>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fe985b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer=Dense(1,kernel_regularizer=l2(0.0000),activation='tanh')\n",
    "mlp_vector=layer(mf_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "62650712",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'dense')>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9406f5de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6d221ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layer=len(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c08cc799",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134400d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = nn.Parameter(torch.empty(user_size, dim))  # User embedding\n",
    "H = nn.Parameter(torch.empty(item_size, dim))  # Item embedding\n",
    "nn.init.xavier_normal_(W.data)\n",
    "nn.init.xavier_normal_(H.data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
