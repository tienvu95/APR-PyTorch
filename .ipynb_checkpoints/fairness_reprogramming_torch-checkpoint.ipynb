{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35dba935",
   "metadata": {},
   "source": [
    "Thinking of APR. Are we doing the dual optimization with the classification model + the pertubation added?\n",
    "\n",
    "1. Run BPR and retrieve the model parameters + predict with fixed parameters\n",
    "2. Use predictions by BPR, train an adversary, save the trained parameters of the MLPs\n",
    "3. Load parameters of BPR, optimize for a perturbations with the new overall objective\n",
    "\n",
    "    Loss BPR (with fixed params + perturbation) + Loss adversary (with fixed params + perturbation)\n",
    "\n",
    "\n",
    "To Do?\n",
    "\n",
    "\n",
    "1. How to compute P(g = G1)? How to retrieve $P_{adv}(i)$ and $P_{adv}(j)$. As of now it is computed as, for a batch of 512 predictions for group membership, compute % of item predicted as G1, G2,...,Gn. Find conditional prob for each item\n",
    "2. Audit the formula for REO and RSP\n",
    "3. Tranformation function is necessary, how can we define such transformation? i.e. cannot directly optimize embedding + $\\delta$ if $\\delta$ is just a fixed tensor size = embedding dim\n",
    "4. Tuning for the adversary, check case for 6-groups\n",
    "5. Test on more extensive dataset\n",
    "6. Summarize pipeline\n",
    "7. Check the popularity of REO, RSP. Is this fairness definition widely used?\n",
    "    - https://github.com/sisinflab/The-Idiosyncratic-Effects-of-Adversarial-Training/tree/main/src/evaluation recsys\n",
    "    - https://www.semanticscholar.org/reader/f2c12f705aea19ab5e129f72ae9030375f06602f www\n",
    "    - https://www.semanticscholar.org/reader/1459f5a33ae88d4c26594d867201635651c1dd72 recsys\n",
    "    - https://oar.a-star.edu.sg/storage/8/8d1z0edy00/lzz-tois-fairness.pdf  TOIS\n",
    "    - https://www.semanticscholar.org/reader/9eb96c7554d4dac063b47443f38866adbf90b829 recsys\n",
    "    - https://arxiv.org/pdf/2203.01155.pdf UMAP\n",
    "8. Will the universal perturbation work for recsys? do we have to fine-tune, add complexity to the perturbation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "04a30440",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import relevant library\n",
    "\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import pickle\n",
    "import argparse\n",
    "from collections import deque\n",
    "import time\n",
    "import utility\n",
    "import tqdm\n",
    "import copy\n",
    "from operator import itemgetter\n",
    "from datetime import timedelta\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "# from torchvision.datasets import CIFAR10\n",
    "from torch.utils.data import DataLoader\n",
    "# from torchvision import transforms\n",
    "from torch.utils.data import IterableDataset, DataLoader, get_worker_info\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f262aa84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d897bb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## time the process\n",
    "def get_time_dif(start_time):\n",
    "    \"\"\"get the running time\"\"\"\n",
    "    end_time = time.time()\n",
    "    time_dif = end_time - start_time\n",
    "    return timedelta(seconds=int(round(time_dif)))\n",
    "\n",
    "\n",
    "## set up the u,i,j triplet for BPR framework\n",
    "class GetTriplePair(IterableDataset):\n",
    "    # for ml-1m we load in 3760 item 6040 user and 994169 train pair\n",
    "    def __init__(self, item_size, user_list, pair, shuffle, num_epochs):\n",
    "        self.item_size = item_size\n",
    "        self.user_list = user_list\n",
    "        self.pair = pair\n",
    "        self.shuffle = shuffle\n",
    "        self.num_epochs = num_epochs\n",
    "\n",
    "    def __iter__(self):\n",
    "        self.example_size = self.num_epochs * len(self.pair)\n",
    "        self.example_index_queue = deque([])\n",
    "        self.seed = 0\n",
    "        self.start_list_index = None\n",
    "        self.num_workers = 1\n",
    "        self.index = 0\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.index >= self.example_size:\n",
    "            raise StopIteration\n",
    "        # If `example_index_queue` is used up, replenish this list.\n",
    "        while len(self.example_index_queue) == 0:\n",
    "            index_list = list(range(len(self.pair)))\n",
    "            if self.shuffle:\n",
    "                random.Random(self.seed).shuffle(index_list)\n",
    "                self.seed += 1\n",
    "            if self.start_list_index is not None:\n",
    "                index_list = index_list[self.start_list_index::self.num_workers]\n",
    "\n",
    "                # Calculate next start index\n",
    "                self.start_list_index = (self.start_list_index + (self.num_workers - (len(self.pair) % self.num_workers))) % self.num_workers\n",
    "            self.example_index_queue.extend(index_list)\n",
    "        result = self._example(self.example_index_queue.popleft())\n",
    "        self.index += self.num_workers\n",
    "        return result\n",
    "\n",
    "    def _example(self, idx):\n",
    "        # in a train pair, format = (u,i), j = a random item which does not exist in user u's list of items\n",
    "        u = self.pair[idx][0]\n",
    "        i = self.pair[idx][1]\n",
    "        j = np.random.randint(self.item_size)\n",
    "        while j in self.user_list[u]:\n",
    "            j = np.random.randint(self.item_size)\n",
    "        return u, i, j\n",
    "\n",
    "## chunk to define matrix factorization part\n",
    "class MF(nn.Module):\n",
    "    def __init__(self, user_size, item_size, dim, reg, reg_adv, eps):\n",
    "        super().__init__()\n",
    "        ##init the embedding for U and I\n",
    "        self.W = nn.Parameter(torch.empty(user_size, dim))  # User embedding\n",
    "        self.H = nn.Parameter(torch.empty(item_size, dim))  # Item embedding\n",
    "        nn.init.xavier_normal_(self.W.data)\n",
    "        nn.init.xavier_normal_(self.H.data)\n",
    "        self.reg = reg\n",
    "        self.user_size = user_size\n",
    "        self.item_size = item_size\n",
    "        self.dim = dim\n",
    "        self.reg_adv = reg_adv\n",
    "        self.eps = eps\n",
    "        self.update_u = None\n",
    "        self.update_i = None\n",
    "        self.update_j = None\n",
    "\n",
    "## forward cal\n",
    "    def forward(self, u, i, j, epoch):\n",
    "        \"\"\"Return loss value.\n",
    "\n",
    "        Args:\n",
    "            u(torch.LongTensor): tensor stored user indexes. [batch_size,]\n",
    "            i(torch.LongTensor): tensor stored item indexes which is prefered by user. [batch_size,]\n",
    "            j(torch.LongTensor): tensor stored item indexes which is not prefered by user. [batch_size,]\n",
    "            epoch\n",
    "\n",
    "        Returns:\n",
    "            torch.FloatTensor\n",
    "        \"\"\"\n",
    "        ##u,i,j respectively, each is a vector of dim embedding (default = 64)\n",
    "        u = self.W[u, :]\n",
    "        i = self.H[i, :]\n",
    "        j = self.H[j, :]\n",
    "\n",
    "        ## Enables this Tensor to have their grad populated during backward(), convert any non-leaf tensor into a leaf tensor,\n",
    "        ##https://stackoverflow.com/questions/73698041/how-retain-grad-in-pytorch-works-i-found-its-position-changes-the-grad-result\n",
    "        u.retain_grad()\n",
    "        u_clone = u.data.clone()\n",
    "        i.retain_grad()\n",
    "        i_clone = i.data.clone()\n",
    "        j.retain_grad()\n",
    "        j_clone = j.data.clone()\n",
    "\n",
    "        ## mf, dot product of user with pos/neg item\n",
    "        x_ui = torch.mul(u, i).sum(dim=1)\n",
    "        x_uj = torch.mul(u, j).sum(dim=1)\n",
    "\n",
    "\n",
    "        #similar to clip value, find diff between ui and uj\n",
    "        x_uij =torch.clamp(x_ui - x_uj,min=-80.0,max=1e8)\n",
    "        #logsigmoid this is equivalent to equation 1 in the paper (classic loss of bpr)\n",
    "        log_prob = F.logsigmoid(x_uij).sum()\n",
    "        # regularization = lambda * l2 norm of u, i, j\n",
    "        regularization = self.reg * (u.norm(dim=1).pow(2).sum() + i.norm(dim=1).pow(2).sum() + j.norm(dim=1).pow(2).sum())\n",
    "\n",
    "        ## original bpr loss,\n",
    "        loss = -log_prob + regularization\n",
    "\n",
    "        loss.backward()\n",
    "        return loss\n",
    "        # add adv training after a certain number of epochs, here is the part which we add hypernet module\n",
    "        if epoch not in range(args.epochs, args.adv_epoch + args.epochs):\n",
    "            \"\"\"Normal training\"\"\"\n",
    "            loss.backward()\n",
    "            return loss\n",
    "\n",
    "        else:\n",
    "            \"\"\"Adversarial training:\n",
    "                    1.Backward to get grads\n",
    "                    2.Construct adversarial perturbation\n",
    "                    3.Add adversarial perturbation to embeddings\n",
    "                    4.Calculate APR loss\n",
    "            \"\"\"\n",
    "            # Backward to get grads\n",
    "            # this would be the part we change in defining delta, delta = HPN (phi)\n",
    "\n",
    "            # should we calculate based on gradient of the adv_loss instead of the loss function?, originally, computed based on loss function\n",
    "            loss.backward(retain_graph=True) ## need to retain graph here so as to we can backprop the adv_loss\n",
    "            ##recheck this\n",
    "            grad_u = u.grad\n",
    "            grad_i = i.grad\n",
    "            grad_j = j.grad\n",
    "\n",
    "            # Construct adversarial perturbation based on gradient of loss function, and normalize it with epsilon * norm\n",
    "            if grad_u is not None:\n",
    "                delta_u = nn.functional.normalize(grad_u, p=2, dim=1, eps=self.eps)\n",
    "            else:\n",
    "                delta_u = torch.rand(u.size())\n",
    "            if grad_i is not None:\n",
    "                delta_i = nn.functional.normalize(grad_i, p=2, dim=1, eps=self.eps)\n",
    "            else:\n",
    "                delta_i = torch.rand(i.size())\n",
    "            if grad_j is not None:\n",
    "                delta_j = nn.functional.normalize(grad_j, p=2, dim=1, eps=self.eps)\n",
    "            else:\n",
    "                delta_j = torch.rand(j.size())\n",
    "\n",
    "            # Add adversarial perturbation to embeddings, now we have q+delta, p+delta\n",
    "            x_ui_adv = torch.mul(u + delta_u, i + delta_i).sum(dim=1)\n",
    "            x_uj_adv = torch.mul(u + delta_u, j + delta_j).sum(dim=1)\n",
    "\n",
    "            # find difference between pos and neg item, then clip value\n",
    "            x_uij_adv = torch.clamp(x_ui_adv - x_uj_adv,min=-80.0,max=1e8)\n",
    "\n",
    "            # Calculate APR loss with logsigmoid\n",
    "            log_prob = F.logsigmoid(x_uij_adv).sum()\n",
    "            adv_loss = self.reg_adv *(-log_prob) + loss # this is adversarial loss (equation 4 in paper)\n",
    "            adv_loss.backward()\n",
    "\n",
    "            return adv_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c1a455a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_k(user_emb, item_emb, train_user_list, test_user_list, klist, batch=512):\n",
    "    \"\"\"Compute HR and NDCG at k.\n",
    "\n",
    "    Args:\n",
    "        user_emb (torch.Tensor): embedding for user [user_num, dim]\n",
    "        item_emb (torch.Tensor): embedding for item [item_num, dim]\n",
    "        train_user_list (list(set)):\n",
    "        test_user_list (list(set)):\n",
    "        k (list(int)):\n",
    "    Returns:\n",
    "        (torch.Tensor, torch.Tensor) HR and NDCG at k\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate max k value\n",
    "    max_k = max(klist)\n",
    "    result = None\n",
    "\n",
    "    # no iteration = user_num / batch size (which is 512)\n",
    "    for i in range(0, user_emb.shape[0], batch):\n",
    "\n",
    "        # Construct mask for each batch\n",
    "\n",
    "        #new_ones returns a Tensor of size size filled with 1\n",
    "\n",
    "        # size of the mask vector = (min of batch or user embed) * item+embed\n",
    "        mask = user_emb.new_ones([min([batch, user_emb.shape[0]-i]), item_emb.shape[0]])\n",
    "        for j in range(batch):\n",
    "            if i+j >= user_emb.shape[0]:\n",
    "                break\n",
    "            mask[j].scatter_(dim=0, index=torch.tensor(list(train_user_list[i + j])), value=torch.tensor(0.0))\n",
    "\n",
    "        # Get current result\n",
    "        cur_result = torch.mm(user_emb[i:i+min(batch, user_emb.shape[0]-i), :], item_emb.t())\n",
    "        cur_result = torch.sigmoid(cur_result)\n",
    "        assert not torch.any(torch.isnan(cur_result))\n",
    "\n",
    "        # Make zero for already observed item\n",
    "        cur_result = torch.mul(mask, cur_result)\n",
    "        _, cur_result = torch.topk(cur_result, k=max_k, dim=1)\n",
    "        result = cur_result if result is None else torch.cat((result, cur_result), dim=0)\n",
    "\n",
    "\n",
    "    ## basically this chunk collects the results\n",
    "    result = result.cpu()\n",
    "\n",
    "    # Sort indice and get HR_NDCG_topk\n",
    "    HRs, NDCGs = [], []\n",
    "    for k in klist:\n",
    "        ndcg, hr = 0, 0\n",
    "        #for all user\n",
    "        for i in range(user_emb.shape[0]):\n",
    "            #set helps to identify unique members in a list\n",
    "            test = set(test_user_list[i])\n",
    "            #top k item from prediction list\n",
    "            pred = set(result[i, :k].numpy().tolist())\n",
    "            #if topk lies on both test and pred list\n",
    "            val = len(test & pred)\n",
    "            #hit ratio = %item hit\n",
    "            hr += val / max([len(test), 1])\n",
    "            #convert pred back to list\n",
    "            pred = list(pred)\n",
    "            if test_user_list[i] == []:\n",
    "                continue\n",
    "            else:\n",
    "                x = int(test_user_list[i][0])\n",
    "                ## check if x is in the prediction where x = 1st member of user list\n",
    "                if pred.count(x) != 0:\n",
    "                    position = pred.index(x)\n",
    "                    ndcg += math.log(2) / math.log(position + 2) if position < k else 0\n",
    "                else:\n",
    "                    ndcg += 0                \n",
    "#                 for x in test_user_list[i]:\n",
    "#                     x = int(x)\n",
    "#                     ## check if x is in the prediction where x = 1st member of user list\n",
    "#                     if pred.count(x) != 0:\n",
    "#                         position = pred.index(x)\n",
    "#                         ndcg += math.log(2) / math.log(position + 2) if position < k else 0\n",
    "#                     else:\n",
    "#                         ndcg += 0\n",
    "        NDCGs.append(ndcg / user_emb.shape[0])\n",
    "        HRs.append(hr / user_emb.shape[0])\n",
    "        NDCGs.append(ndcg / user_emb.shape[0])\n",
    "    return HRs, NDCGs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f204e348",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('preprocessed/ml-1m-2.pickle', 'rb') as f:\n",
    "    dataset = pickle.load(f)\n",
    "    user_size, item_size = dataset['user_size'], dataset['item_size']\n",
    "    train_user_list, test_user_list = dataset['train_user_list'], dataset['test_user_list']\n",
    "    train_pair = dataset['train_pair']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2e7ffdb1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create dataset, model, optimizer\n",
    "dataset = GetTriplePair(item_size, train_user_list, train_pair, True, 1000)\n",
    "\n",
    "# load batch of 512 item triplets\n",
    "loader = DataLoader(dataset, batch_size=512)\n",
    "model = MF(user_size, item_size, 64, 0, 1, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d655d783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time 0:00:00\n",
      "BPR-MF Epoch [20/1000]\n",
      "loss: 354.7618\n",
      "HR@50: 0.0338, HR@100: 0.0672, NDCG@50: 0.0101, NDCG@100: 0.0101\n",
      "BPR-MF Epoch [40/1000]\n",
      "loss: 354.7697\n",
      "HR@50: 0.0338, HR@100: 0.0672, NDCG@50: 0.0095, NDCG@100: 0.0095\n",
      "BPR-MF Epoch [60/1000]\n",
      "loss: 354.8006\n",
      "HR@50: 0.0334, HR@100: 0.0663, NDCG@50: 0.0091, NDCG@100: 0.0091\n",
      "BPR-MF Epoch [80/1000]\n",
      "loss: 354.8113\n",
      "HR@50: 0.0338, HR@100: 0.0655, NDCG@50: 0.0097, NDCG@100: 0.0097\n",
      "BPR-MF Epoch [100/1000]\n",
      "loss: 354.7533\n",
      "HR@50: 0.0343, HR@100: 0.0671, NDCG@50: 0.0098, NDCG@100: 0.0098\n",
      "time 0:00:16\n",
      "BPR-MF Epoch [120/1000]\n",
      "loss: 354.8435\n",
      "HR@50: 0.0360, HR@100: 0.0698, NDCG@50: 0.0102, NDCG@100: 0.0102\n",
      "BPR-MF Epoch [140/1000]\n",
      "loss: 354.4033\n",
      "HR@50: 0.0388, HR@100: 0.0744, NDCG@50: 0.0105, NDCG@100: 0.0105\n",
      "BPR-MF Epoch [160/1000]\n",
      "loss: 354.3438\n",
      "HR@50: 0.0422, HR@100: 0.0810, NDCG@50: 0.0111, NDCG@100: 0.0111\n",
      "BPR-MF Epoch [180/1000]\n",
      "loss: 354.1532\n",
      "HR@50: 0.0498, HR@100: 0.0926, NDCG@50: 0.0139, NDCG@100: 0.0139\n",
      "BPR-MF Epoch [200/1000]\n",
      "loss: 352.8189\n",
      "HR@50: 0.0582, HR@100: 0.1083, NDCG@50: 0.0165, NDCG@100: 0.0165\n",
      "time 0:00:32\n",
      "BPR-MF Epoch [220/1000]\n",
      "loss: 351.0533\n",
      "HR@50: 0.0735, HR@100: 0.1326, NDCG@50: 0.0208, NDCG@100: 0.0208\n",
      "BPR-MF Epoch [240/1000]\n",
      "loss: 349.9149\n",
      "HR@50: 0.0929, HR@100: 0.1629, NDCG@50: 0.0257, NDCG@100: 0.0257\n",
      "BPR-MF Epoch [260/1000]\n",
      "loss: 346.5256\n",
      "HR@50: 0.1144, HR@100: 0.1977, NDCG@50: 0.0316, NDCG@100: 0.0316\n",
      "BPR-MF Epoch [280/1000]\n",
      "loss: 343.5892\n",
      "HR@50: 0.1363, HR@100: 0.2344, NDCG@50: 0.0387, NDCG@100: 0.0387\n",
      "BPR-MF Epoch [300/1000]\n",
      "loss: 334.6625\n",
      "HR@50: 0.1586, HR@100: 0.2645, NDCG@50: 0.0467, NDCG@100: 0.0467\n",
      "time 0:00:47\n",
      "BPR-MF Epoch [320/1000]\n",
      "loss: 328.8820\n",
      "HR@50: 0.1773, HR@100: 0.2923, NDCG@50: 0.0527, NDCG@100: 0.0527\n",
      "BPR-MF Epoch [340/1000]\n",
      "loss: 320.4246\n",
      "HR@50: 0.1926, HR@100: 0.3151, NDCG@50: 0.0572, NDCG@100: 0.0572\n",
      "BPR-MF Epoch [360/1000]\n",
      "loss: 306.3424\n",
      "HR@50: 0.2096, HR@100: 0.3341, NDCG@50: 0.0628, NDCG@100: 0.0628\n",
      "BPR-MF Epoch [380/1000]\n",
      "loss: 295.1659\n",
      "HR@50: 0.2210, HR@100: 0.3519, NDCG@50: 0.0675, NDCG@100: 0.0675\n",
      "BPR-MF Epoch [400/1000]\n",
      "loss: 278.0624\n",
      "HR@50: 0.2305, HR@100: 0.3639, NDCG@50: 0.0712, NDCG@100: 0.0712\n",
      "time 0:01:03\n",
      "BPR-MF Epoch [420/1000]\n",
      "loss: 266.1830\n",
      "HR@50: 0.2394, HR@100: 0.3749, NDCG@50: 0.0749, NDCG@100: 0.0749\n",
      "BPR-MF Epoch [440/1000]\n",
      "loss: 260.2266\n",
      "HR@50: 0.2463, HR@100: 0.3816, NDCG@50: 0.0776, NDCG@100: 0.0776\n",
      "BPR-MF Epoch [460/1000]\n",
      "loss: 260.3737\n",
      "HR@50: 0.2536, HR@100: 0.3888, NDCG@50: 0.0800, NDCG@100: 0.0800\n",
      "BPR-MF Epoch [480/1000]\n",
      "loss: 222.7483\n",
      "HR@50: 0.2605, HR@100: 0.3960, NDCG@50: 0.0822, NDCG@100: 0.0822\n",
      "BPR-MF Epoch [500/1000]\n",
      "loss: 229.6296\n",
      "HR@50: 0.2659, HR@100: 0.4014, NDCG@50: 0.0837, NDCG@100: 0.0837\n",
      "time 0:01:19\n",
      "BPR-MF Epoch [520/1000]\n",
      "loss: 216.8358\n",
      "HR@50: 0.2709, HR@100: 0.4068, NDCG@50: 0.0840, NDCG@100: 0.0840\n",
      "BPR-MF Epoch [540/1000]\n",
      "loss: 224.2073\n",
      "HR@50: 0.2749, HR@100: 0.4105, NDCG@50: 0.0847, NDCG@100: 0.0847\n",
      "BPR-MF Epoch [560/1000]\n",
      "loss: 199.4254\n",
      "HR@50: 0.2806, HR@100: 0.4135, NDCG@50: 0.0864, NDCG@100: 0.0864\n",
      "BPR-MF Epoch [580/1000]\n",
      "loss: 196.3864\n",
      "HR@50: 0.2846, HR@100: 0.4189, NDCG@50: 0.0880, NDCG@100: 0.0880\n",
      "BPR-MF Epoch [600/1000]\n",
      "loss: 213.8972\n",
      "HR@50: 0.2877, HR@100: 0.4212, NDCG@50: 0.0885, NDCG@100: 0.0885\n",
      "time 0:01:34\n",
      "BPR-MF Epoch [620/1000]\n",
      "loss: 209.9092\n",
      "HR@50: 0.2919, HR@100: 0.4245, NDCG@50: 0.0895, NDCG@100: 0.0895\n",
      "BPR-MF Epoch [640/1000]\n",
      "loss: 190.7745\n",
      "HR@50: 0.2936, HR@100: 0.4272, NDCG@50: 0.0893, NDCG@100: 0.0893\n",
      "BPR-MF Epoch [660/1000]\n",
      "loss: 192.6335\n",
      "HR@50: 0.2973, HR@100: 0.4304, NDCG@50: 0.0901, NDCG@100: 0.0901\n",
      "BPR-MF Epoch [680/1000]\n",
      "loss: 217.7017\n",
      "HR@50: 0.2992, HR@100: 0.4324, NDCG@50: 0.0902, NDCG@100: 0.0902\n",
      "BPR-MF Epoch [700/1000]\n",
      "loss: 180.1519\n",
      "HR@50: 0.3011, HR@100: 0.4332, NDCG@50: 0.0907, NDCG@100: 0.0907\n",
      "BPR-MF Epoch [720/1000]\n",
      "loss: 184.9807\n",
      "HR@50: 0.3015, HR@100: 0.4341, NDCG@50: 0.0907, NDCG@100: 0.0907\n",
      "BPR-MF Epoch [740/1000]\n",
      "loss: 183.6693\n",
      "HR@50: 0.3032, HR@100: 0.4341, NDCG@50: 0.0908, NDCG@100: 0.0908\n",
      "BPR-MF Epoch [760/1000]\n",
      "loss: 194.4984\n",
      "HR@50: 0.3043, HR@100: 0.4353, NDCG@50: 0.0909, NDCG@100: 0.0909\n",
      "BPR-MF Epoch [780/1000]\n",
      "loss: 184.3651\n",
      "HR@50: 0.3059, HR@100: 0.4369, NDCG@50: 0.0908, NDCG@100: 0.0908\n",
      "BPR-MF Epoch [800/1000]\n",
      "loss: 164.9961\n",
      "HR@50: 0.3081, HR@100: 0.4383, NDCG@50: 0.0912, NDCG@100: 0.0912\n",
      "BPR-MF Epoch [820/1000]\n",
      "loss: 191.8116\n",
      "HR@50: 0.3095, HR@100: 0.4406, NDCG@50: 0.0911, NDCG@100: 0.0911\n",
      "BPR-MF Epoch [840/1000]\n",
      "loss: 183.2152\n",
      "HR@50: 0.3106, HR@100: 0.4403, NDCG@50: 0.0913, NDCG@100: 0.0913\n",
      "BPR-MF Epoch [860/1000]\n",
      "loss: 188.7550\n",
      "HR@50: 0.3115, HR@100: 0.4413, NDCG@50: 0.0913, NDCG@100: 0.0913\n",
      "BPR-MF Epoch [880/1000]\n",
      "loss: 174.5380\n",
      "HR@50: 0.3133, HR@100: 0.4419, NDCG@50: 0.0918, NDCG@100: 0.0918\n",
      "BPR-MF Epoch [900/1000]\n",
      "loss: 192.0130\n",
      "HR@50: 0.3164, HR@100: 0.4437, NDCG@50: 0.0929, NDCG@100: 0.0929\n",
      "time 0:02:20\n",
      "BPR-MF Epoch [920/1000]\n",
      "loss: 210.2923\n",
      "HR@50: 0.3167, HR@100: 0.4456, NDCG@50: 0.0928, NDCG@100: 0.0928\n",
      "BPR-MF Epoch [940/1000]\n",
      "loss: 169.2608\n",
      "HR@50: 0.3183, HR@100: 0.4484, NDCG@50: 0.0929, NDCG@100: 0.0929\n",
      "BPR-MF Epoch [960/1000]\n",
      "loss: 174.3237\n",
      "HR@50: 0.3193, HR@100: 0.4498, NDCG@50: 0.0929, NDCG@100: 0.0929\n",
      "BPR-MF Epoch [980/1000]\n",
      "loss: 176.0770\n",
      "HR@50: 0.3198, HR@100: 0.4512, NDCG@50: 0.0922, NDCG@100: 0.0922\n",
      "BPR-MF Epoch [1000/1000]\n",
      "loss: 201.0581\n",
      "HR@50: 0.3216, HR@100: 0.4529, NDCG@50: 0.0926, NDCG@100: 0.0926\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.00025)\n",
    "\n",
    "# Training\n",
    "start_time = time.time()\n",
    "eval_best_loss = float('inf')\n",
    "\n",
    "##zero_grad: zeroes the grad attribute of all the parameters passed to the optimizer upon construction\n",
    "optimizer.zero_grad()\n",
    "epoch = 0\n",
    "HR_history = []\n",
    "NDCG_history = []\n",
    "# result_history = []\n",
    "#loader has batch size of 512. In each batch there are 3 tensors of u i j accordingly\n",
    "for u, i, j in loader:\n",
    "    if epoch in range(1000):\n",
    "        loss = model(u, i, j, epoch)\n",
    "\n",
    "        ##  updates the value of those parameters according to the optimization strategy implemented by the specific optimizer.\n",
    "        optimizer.step()\n",
    "        HR_list, NDCG_list = evaluate_k(model.W.detach(),\n",
    "                                        model.H.detach(),\n",
    "                                        train_user_list,\n",
    "                                        test_user_list,\n",
    "                                        klist=[50, 100])\n",
    "        if epoch % 20 == (20- 1):\n",
    "            if epoch in range(1000):\n",
    "                print('BPR-MF Epoch [{}/{}]'.format(epoch + 1, 1000))\n",
    "            print('loss: %.4f' % loss)\n",
    "            print('HR@50: %.4f, HR@100: %.4f, NDCG@50: %.4f, NDCG@100: %.4f' % (\n",
    "                HR_list[0], HR_list[1], NDCG_list[0], NDCG_list[1]))\n",
    "        HR_history.append(HR_list[1])\n",
    "        NDCG_history.append(NDCG_list[1])\n",
    "        if epoch % 100 == 0:\n",
    "            if loss < eval_best_loss:\n",
    "                eval_best_loss = loss\n",
    "                dirname = os.path.dirname(os.path.abspath('output/bpr_manual'))\n",
    "                os.makedirs(dirname, exist_ok=True)\n",
    "                torch.save(model.state_dict(), 'output/bpr_manual')\n",
    "                time_dif = get_time_dif(start_time)\n",
    "                print(\"time\", time_dif)\n",
    "        epoch += 1\n",
    "    else:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b039d9",
   "metadata": {},
   "source": [
    "for ml-1m-2 data set with continue , epoch 1000 has\n",
    "loss: 160.6638\n",
    "HR@50: 0.3218, HR@100: 0.4558, NDCG@50: 0.0939, NDCG@100: 0.0939\n",
    "\n",
    "\n",
    "\n",
    "for ml-1m-6 data set with continue , epoch 1000 has\n",
    "loss: 160.6638\n",
    "HR@50: 0.3218, HR@100: 0.4558, NDCG@50: 0.0939, NDCG@100: 0.0939\n",
    "\n",
    "for ml-1m-6 data set with continue + for loop for X in test user set , epoch 1000 has\n",
    "loss: 196.0934\n",
    "HR@50: 0.3266, HR@100: 0.4649, NDCG@50: 0.7004, NDCG@100: 0.7004\n",
    "\n",
    "\n",
    "ml-1m normal dataset\n",
    "loss: 150.8645\n",
    "HR@50: 0.1437, HR@100: 0.2245, NDCG@50: 0.0365, NDCG@100: 0.0365\n",
    "\n",
    "test ml-1m normal dataset with for loop for X in test user set\n",
    "loss: 181.7949\n",
    "HR@50: 0.1480, HR@100: 0.2252, NDCG@50: 0.0373, NDCG@100: 0.0373"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "29d7f1e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig_HR = plt.figure(edgecolor='blue')\n",
    "ax1 = fig_HR.add_subplot(111)\n",
    "plt.ylabel('HR@100')\n",
    "plt.xlabel('Epoch')\n",
    "plt.title('ML-1M')\n",
    "ax1.plot(range(len(HR_history)), HR_history, c=np.array([255, 71, 90]) / 255.)\n",
    "plt.show()\n",
    "fig_P = plt.figure(edgecolor='blue')\n",
    "ax1 = fig_P.add_subplot(111)\n",
    "plt.ylabel('NDCG@100')\n",
    "plt.xlabel('Epoch')\n",
    "plt.title('ML-1M')\n",
    "ax1.plot(range(len(NDCG_history)), NDCG_history, c=np.array([255, 71, 90]) / 255.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886dcf79",
   "metadata": {},
   "source": [
    "Running a saving output of BPR model\n",
    "\n",
    "Next up = train adversary based on fixed parameters of BPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b6ae75b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_pickle(r'ml1m-6/training_df.pkl')\n",
    "vali_df = pd.read_pickle(r'ml1m-6/valiing_df.pkl')\n",
    "key_genre = pd.read_pickle(r'ml1m-6/key_genre.pkl')  \n",
    "item_idd_genre_list = pd.read_pickle(r'ml1m-6/item_idd_genre_list.pkl')   \n",
    "genre_item_vector = pd.read_pickle(r'ml1m-6/genre_item_vector.pkl')    \n",
    "genre_count = pd.read_pickle(r'ml1m-6/genre_count.pkl')      \n",
    "user_genre_count = pd.read_pickle(r'ml1m-6/user_genre_count.pkl') \n",
    "\n",
    "num_item = len(train_df['item_id'].unique())\n",
    "num_user = len(train_df['user_id'].unique())\n",
    "num_genre = len(key_genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4a9335ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Sci-Fi': 271,\n",
       " 'Horror': 330,\n",
       " 'Crime': 193,\n",
       " 'Romance': 447,\n",
       " \"Children's\": 248,\n",
       " 'Adventure': 276}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "364be573",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_genre_list = []\n",
    "for u in range(num_item):\n",
    "    gl = item_idd_genre_list[u]\n",
    "    tmp = []\n",
    "    for g in gl:\n",
    "        if g in key_genre:\n",
    "            tmp.append(g)\n",
    "    item_genre_list.append(tmp)\n",
    "\n",
    "item_genre = np.zeros((num_item, num_genre))\n",
    "for i in range(num_item):\n",
    "    gl = item_genre_list[i]\n",
    "    for k in range(num_genre):\n",
    "        if key_genre[k] in gl:\n",
    "            item_genre[i, k] = 1.0\n",
    "\n",
    "genre_count_mean_reciprocal = []\n",
    "\n",
    "##there are six key_genre --> in the training dataset, count the number of movies for each genre\n",
    "#genre_count = dictionary with number of movies for each keygrenre\n",
    "for k in key_genre:\n",
    "    genre_count_mean_reciprocal.append(1.0 / genre_count[k])\n",
    "genre_count_mean_reciprocal = (np.array(genre_count_mean_reciprocal)).reshape((num_genre, 1))\n",
    "genre_error_weight = np.dot(item_genre, genre_count_mean_reciprocal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2326714e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00369004],\n",
       "       [0.0030303 ],\n",
       "       [0.00518135],\n",
       "       [0.00362319],\n",
       "       [0.00403226],\n",
       "       [0.00223714]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_count_mean_reciprocal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "55f5af0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1481, 6])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_genre = torch.from_numpy(item_genre).type(torch.float)\n",
    "item_genre.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2000011e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([6036, 64]), torch.Size([1481, 64]))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load the results of BPR\n",
    "model1 = (torch.load('output/bpr_manual'))\n",
    "list(model1.items())[0][1].size(),list(model1.items())[1][1].size()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0ed68cc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2921,  0.1865,  0.0794,  ...,  0.1468, -0.0041, -0.0735],\n",
       "        [-0.2600,  0.1871,  0.2491,  ..., -0.3320,  0.0178, -0.2817],\n",
       "        [-0.3179, -0.3081,  0.3536,  ..., -0.4377, -0.2081, -0.3050],\n",
       "        ...,\n",
       "        [ 0.2057,  0.3228, -0.3675,  ...,  0.3384, -0.1572,  0.3756],\n",
       "        [ 0.3807,  0.3103, -0.3507,  ...,  0.3664, -0.1035,  0.4241],\n",
       "        [ 0.2991,  0.2242, -0.3828,  ...,  0.2642,  0.2661,  0.3849]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model1.items())[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0c24762f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6036, 1481])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rec = np.matmul(list(model1.items())[0][1], list(model1.items())[1][1].T)\n",
    "Rec.size()\n",
    "# Rec[1,:].size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6d8d492c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'u_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_65711/3177922395.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m utility.ranking_analysis(Rec, vali_df, train_df, key_genre,\n\u001b[0m\u001b[1;32m      3\u001b[0m                                                       item_genre_list, user_genre_count)\n",
      "\u001b[0;32m~/Documents/code_base/APR-PyTorch/utility.py\u001b[0m in \u001b[0;36mranking_analysis\u001b[0;34m(Rec, test_df, train_df, key_genre, item_idd_genre_list, user_genre_count)\u001b[0m\n\u001b[1;32m    310\u001b[0m             \u001b[0mrecall_1_tmp_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecall_5_tmp_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecall_10_tmp_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecall_15_tmp_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0mcount_1_tmp_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount_5_tmp_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount_10_tmp_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount_15_tmp_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_tmp_dict\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m                 \u001b[0;34m=\u001b[0m \u001b[0muser_recall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_idd_genre_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_genre\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkey_genre\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m                 \u001b[0mcount1_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcount_1_tmp_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/code_base/APR-PyTorch/utility.py\u001b[0m in \u001b[0;36muser_recall\u001b[0;34m(new_user_prediction, test, item_idd_genre_list, key_genre)\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0mitem_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_user_prediction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mitem_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m             \u001b[0mgl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem_idd_genre_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'u_test' is not defined"
     ]
    }
   ],
   "source": [
    "import utility\n",
    "utility.ranking_analysis(Rec, vali_df, train_df, key_genre,\n",
    "                                                      item_genre_list, user_genre_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "90785b71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(434, 109, 434, 109)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(Rec.T, \n",
    "                                                    item_genre, \n",
    "                                                    test_size=0.2, # 20% test, 80% train\n",
    "                                                    random_state=181) # make the random split reproducible\n",
    "\n",
    "len(X_train), len(X_test), len(y_train), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "494ea526",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adv, linear-relu, linear-sigmoid last layer, numlayer = 4, 512,256,128,64 hidden units \n",
    "\n",
    "adversary = nn.Sequential(\n",
    "    nn.Linear(list(model1.items())[0][1].size()[0], 512),\n",
    "#     nn.ReLU(),\n",
    "    nn.Linear(512, 256),\n",
    "#     nn.ReLU(),\n",
    "    nn.Linear(256, 128),\n",
    "#     nn.ReLU(),\n",
    "    nn.Linear(128, 2),\n",
    "    nn.Sigmoid()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8bf3ee5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a loss function\n",
    "# loss_fn = nn.BCELoss() # BCELoss = no sigmoid built-in\n",
    "loss_fn = nn.BCEWithLogitsLoss() # BCEWithLogitsLoss = sigmoid built-in\n",
    "\n",
    "# Create an optimizer\n",
    "optimizer = torch.optim.Adam(params=adversary.parameters(), \n",
    "                            lr=0.000005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7d1f7bd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "896d5686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy (a classification metric)\n",
    "def accuracy_fn(y_true, y_pred):\n",
    "    correct = torch.eq(y_true, y_pred).sum().item() # torch.eq() calculates where two tensors are equal\n",
    "    acc = (correct / (y_true.size()[0]*y_true.size()[1])) * 100 \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "28bda2f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Loss: 0.77921, Accuracy: 39.98% | Test loss: 0.78000, Test acc: 41.74%\n",
      "Epoch: 10 | Loss: 0.76126, Accuracy: 44.82% | Test loss: 0.77477, Test acc: 44.04%\n",
      "Epoch: 20 | Loss: 0.75053, Accuracy: 47.93% | Test loss: 0.77157, Test acc: 45.41%\n",
      "Epoch: 30 | Loss: 0.74132, Accuracy: 50.35% | Test loss: 0.76744, Test acc: 46.79%\n",
      "Epoch: 40 | Loss: 0.73305, Accuracy: 52.65% | Test loss: 0.75986, Test acc: 49.08%\n",
      "Epoch: 50 | Loss: 0.71817, Accuracy: 55.07% | Test loss: 0.73932, Test acc: 52.75%\n",
      "Epoch: 60 | Loss: 0.70437, Accuracy: 57.60% | Test loss: 0.72047, Test acc: 55.96%\n",
      "Epoch: 70 | Loss: 0.68631, Accuracy: 59.45% | Test loss: 0.71377, Test acc: 55.96%\n",
      "Epoch: 80 | Loss: 0.68162, Accuracy: 60.02% | Test loss: 0.70245, Test acc: 57.80%\n",
      "Epoch: 90 | Loss: 0.68075, Accuracy: 60.25% | Test loss: 0.70243, Test acc: 57.80%\n",
      "Epoch: 100 | Loss: 0.68075, Accuracy: 60.25% | Test loss: 0.70241, Test acc: 57.80%\n",
      "Epoch: 110 | Loss: 0.67812, Accuracy: 60.94% | Test loss: 0.69893, Test acc: 58.72%\n",
      "Epoch: 120 | Loss: 0.67545, Accuracy: 61.87% | Test loss: 0.70225, Test acc: 58.72%\n",
      "Epoch: 130 | Loss: 0.66764, Accuracy: 63.94% | Test loss: 0.69527, Test acc: 60.55%\n",
      "Epoch: 140 | Loss: 0.65955, Accuracy: 66.13% | Test loss: 0.69768, Test acc: 60.55%\n",
      "Epoch: 150 | Loss: 0.65196, Accuracy: 68.09% | Test loss: 0.68527, Test acc: 63.76%\n",
      "Epoch: 160 | Loss: 0.65101, Accuracy: 69.12% | Test loss: 0.68684, Test acc: 64.22%\n",
      "Epoch: 170 | Loss: 0.65223, Accuracy: 69.35% | Test loss: 0.67815, Test acc: 66.51%\n",
      "Epoch: 180 | Loss: 0.64678, Accuracy: 70.51% | Test loss: 0.67992, Test acc: 66.06%\n",
      "Epoch: 190 | Loss: 0.63633, Accuracy: 72.24% | Test loss: 0.66569, Test acc: 68.35%\n",
      "Epoch: 200 | Loss: 0.61466, Accuracy: 75.12% | Test loss: 0.65273, Test acc: 69.72%\n",
      "Epoch: 210 | Loss: 0.60053, Accuracy: 77.07% | Test loss: 0.64700, Test acc: 70.18%\n",
      "Epoch: 220 | Loss: 0.59413, Accuracy: 77.88% | Test loss: 0.63021, Test acc: 72.48%\n",
      "Epoch: 230 | Loss: 0.58600, Accuracy: 79.26% | Test loss: 0.61706, Test acc: 74.77%\n",
      "Epoch: 240 | Loss: 0.57862, Accuracy: 80.65% | Test loss: 0.61991, Test acc: 74.31%\n",
      "Epoch: 250 | Loss: 0.57321, Accuracy: 81.57% | Test loss: 0.61140, Test acc: 75.69%\n",
      "Epoch: 260 | Loss: 0.57250, Accuracy: 81.68% | Test loss: 0.61137, Test acc: 75.69%\n",
      "Epoch: 270 | Loss: 0.57217, Accuracy: 81.68% | Test loss: 0.61130, Test acc: 75.69%\n",
      "Epoch: 280 | Loss: 0.56663, Accuracy: 82.49% | Test loss: 0.59990, Test acc: 77.52%\n",
      "Epoch: 290 | Loss: 0.56337, Accuracy: 83.06% | Test loss: 0.59679, Test acc: 77.98%\n",
      "Epoch: 300 | Loss: 0.56249, Accuracy: 83.29% | Test loss: 0.59626, Test acc: 77.98%\n",
      "Epoch: 310 | Loss: 0.56249, Accuracy: 83.29% | Test loss: 0.59594, Test acc: 77.98%\n",
      "Epoch: 320 | Loss: 0.56249, Accuracy: 83.29% | Test loss: 0.59409, Test acc: 78.44%\n",
      "Epoch: 330 | Loss: 0.56249, Accuracy: 83.29% | Test loss: 0.59405, Test acc: 78.44%\n",
      "Epoch: 340 | Loss: 0.56249, Accuracy: 83.29% | Test loss: 0.59403, Test acc: 78.44%\n",
      "Epoch: 350 | Loss: 0.56249, Accuracy: 83.29% | Test loss: 0.59403, Test acc: 78.44%\n",
      "Epoch: 360 | Loss: 0.56249, Accuracy: 83.29% | Test loss: 0.59403, Test acc: 78.44%\n",
      "Epoch: 370 | Loss: 0.56249, Accuracy: 83.29% | Test loss: 0.59403, Test acc: 78.44%\n",
      "Epoch: 380 | Loss: 0.56249, Accuracy: 83.29% | Test loss: 0.59403, Test acc: 78.44%\n",
      "Epoch: 390 | Loss: 0.56249, Accuracy: 83.29% | Test loss: 0.59403, Test acc: 78.44%\n",
      "Epoch: 400 | Loss: 0.56206, Accuracy: 83.41% | Test loss: 0.59408, Test acc: 78.44%\n",
      "Epoch: 410 | Loss: 0.56206, Accuracy: 83.41% | Test loss: 0.59410, Test acc: 78.44%\n",
      "Epoch: 420 | Loss: 0.56217, Accuracy: 83.53% | Test loss: 0.60087, Test acc: 77.52%\n",
      "Epoch: 430 | Loss: 0.56086, Accuracy: 83.87% | Test loss: 0.59926, Test acc: 78.44%\n",
      "Epoch: 440 | Loss: 0.56086, Accuracy: 83.87% | Test loss: 0.59807, Test acc: 78.90%\n",
      "Epoch: 450 | Loss: 0.56042, Accuracy: 83.99% | Test loss: 0.59807, Test acc: 78.90%\n",
      "Epoch: 460 | Loss: 0.56042, Accuracy: 83.99% | Test loss: 0.59807, Test acc: 78.90%\n",
      "Epoch: 470 | Loss: 0.56042, Accuracy: 83.99% | Test loss: 0.59807, Test acc: 78.90%\n",
      "Epoch: 480 | Loss: 0.56042, Accuracy: 83.99% | Test loss: 0.59807, Test acc: 78.90%\n",
      "Epoch: 490 | Loss: 0.56042, Accuracy: 83.99% | Test loss: 0.59807, Test acc: 78.90%\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(18)\n",
    "\n",
    "# Set the number of epochs\n",
    "epochs = 500\n",
    "\n",
    "# Put data to target device\n",
    "X_train, y_train = X_train.to(device), y_train.to(device)\n",
    "X_test, y_test = X_test.to(device), y_test.to(device)\n",
    "\n",
    "# Build training and evaluation loop\n",
    "for epoch in range(epochs):\n",
    "    ### Training\n",
    "    adversary.train()\n",
    "\n",
    "    # 1. Forward pass (model outputs raw logits)\n",
    "    y_logits = adversary(X_train).squeeze() # squeeze to remove extra `1` dimensions, this won't work unless model and data are on same device \n",
    "    y_pred = torch.round((y_logits)) # turn logits -> pred probs -> pred labls\n",
    "  \n",
    "    # 2. Calculate loss/accuracy\n",
    "    # loss = loss_fn(torch.sigmoid(y_logits), # Using nn.BCELoss you need torch.sigmoid()\n",
    "    #                y_train) \n",
    "    loss = loss_fn(y_logits, # Using nn.BCEWithLogitsLoss works with raw logits\n",
    "                   y_train) \n",
    "    acc = accuracy_fn(y_true=y_train, \n",
    "                      y_pred=y_pred) \n",
    "\n",
    "    # 3. Optimizer zero grad\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # 4. Loss backwards\n",
    "    loss.backward()\n",
    "\n",
    "    # 5. Optimizer step\n",
    "    optimizer.step()\n",
    "\n",
    "    ### Testing\n",
    "    adversary.eval()\n",
    "    with torch.inference_mode():\n",
    "        # 1. Forward pass\n",
    "        test_logits = adversary(X_test).squeeze() \n",
    "        test_pred = torch.round((test_logits))\n",
    "        # 2. Caculate loss/accuracy\n",
    "        test_loss = loss_fn(test_logits,\n",
    "                            y_test)\n",
    "        test_acc = accuracy_fn(y_true=y_test,\n",
    "                               y_pred=test_pred)\n",
    "\n",
    "    # Print out what's happening every 10 epochs\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch: {epoch} | Loss: {loss:.5f}, Accuracy: {acc:.2f}% | Test loss: {test_loss:.5f}, Test acc: {test_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97014932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # prepare model and training parameters\n",
    "# n_epochs = 500\n",
    "# batch_size = 50\n",
    "# batches_per_epoch = len(X_train) // batch_size\n",
    " \n",
    "# best_acc = - np.inf   # init to negative infinity\n",
    "# best_weights = None\n",
    "# train_loss_hist = []\n",
    "# train_acc_hist = []\n",
    "# test_loss_hist = []\n",
    "# test_acc_hist = []\n",
    " \n",
    "# # training loop\n",
    "# for epoch in range(n_epochs):\n",
    "#     epoch_loss = []\n",
    "#     epoch_acc = []\n",
    "#     # set model in training mode and run through each batch\n",
    "#     adversary.train()\n",
    "#     with tqdm.trange(batches_per_epoch, unit=\"batch\", mininterval=0) as bar:\n",
    "#         bar.set_description(f\"Epoch {epoch}\")\n",
    "#         for i in bar:\n",
    "#             # take a batch\n",
    "#             start = i * batch_size\n",
    "#             X_batch = X_train[start:start+batch_size]\n",
    "#             y_batch = y_train[start:start+batch_size]\n",
    "#             # forward pass\n",
    "#             y_pred = adversary(X_batch)\n",
    "#             loss = loss_fn(y_pred, y_batch)\n",
    "#             # backward pass\n",
    "#             optimizer.zero_grad()\n",
    "#             loss.backward()\n",
    "#             # update weights\n",
    "#             optimizer.step()\n",
    "#             # compute and store metrics\n",
    "#             acc = accuracy_fn(y_true=y_batch, \n",
    "#                       y_pred=y_pred)\n",
    "#             epoch_loss.append(float(loss))\n",
    "#             epoch_acc.append(float(acc))\n",
    "#             bar.set_postfix(\n",
    "#                 loss=float(loss),\n",
    "#                 acc=float(acc)\n",
    "#             )\n",
    "#     # set model in evaluation mode and run through the test set\n",
    "#     adversary.eval()\n",
    "#     y_pred = adversary(X_test)\n",
    "#     ce = loss_fn(y_pred, y_test)\n",
    "#     acc = accuracy_fn(y_true=y_test, \n",
    "#                       y_pred=y_pred)\n",
    "#     ce = float(ce)\n",
    "#     acc = float(acc)\n",
    "#     train_loss_hist.append(np.mean(epoch_loss))\n",
    "#     train_acc_hist.append(np.mean(epoch_acc))\n",
    "#     test_loss_hist.append(ce)\n",
    "#     test_acc_hist.append(acc)\n",
    "#     if acc > best_acc:\n",
    "#         best_acc = acc\n",
    "#         best_weights = copy.deepcopy(adversary.state_dict())\n",
    "#     print(f\"Epoch {epoch} validation: Cross-entropy={ce:.2f}, Accuracy={acc:.1f}%\")\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a737340",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'adversary' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4850/2717534567.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Restore best model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0madversary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Plot the loss and accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss_hist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'adversary' is not defined"
     ]
    }
   ],
   "source": [
    " \n",
    "# Restore best model\n",
    "adversary.load_state_dict(best_weights)\n",
    " \n",
    "# Plot the loss and accuracy\n",
    "plt.plot(train_loss_hist, label=\"train\")\n",
    "plt.plot(test_loss_hist, label=\"test\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"cross entropy\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    " \n",
    "plt.plot(train_acc_hist, label=\"train\")\n",
    "plt.plot(test_acc_hist, label=\"test\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f758b8a9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'adversary' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4850/589744199.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdirname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'output/adversary'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madversary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'output/adversary'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'adversary' is not defined"
     ]
    }
   ],
   "source": [
    "dirname = os.path.dirname(os.path.abspath('output/adversary'))\n",
    "os.makedirs(dirname, exist_ok=True)\n",
    "torch.save(adversary, 'output/adversary')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c04f7d0",
   "metadata": {},
   "source": [
    "Take it as it is for now, now save the parameters trained for BPR and adversary\n",
    "\n",
    "Then train for an universal perturbation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "00f95259",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Load\n",
    "adversary = torch.load('output/adversary')\n",
    "# model(X_train)\n",
    "uniform_dist = torch.Tensor([0.5, 0.5])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "70bd1698",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is for indirectly optimize the pertubation\n",
    "\n",
    "criteria = torch.nn.MSELoss()\n",
    "transform_func = torch.nn.Linear(64, 64)#.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "319e9fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class fairness_reprogramming(nn.Module):\n",
    "    def __init__(self, user_emb, item_emb, Rec, reg):\n",
    "        super().__init__()\n",
    "        ##init the embedding for U and I\n",
    "        self.user_emb = user_emb\n",
    "        self.item_emb = item_emb  \n",
    "        self.reg = reg\n",
    "        self.perturb = nn.Parameter(torch.empty(1, 64))  # dim embedding\n",
    "        nn.init.xavier_normal_(self.perturb.data)\n",
    "\n",
    "        \n",
    "## forward cal\n",
    "    def forward(self, u, i, j, epoch):\n",
    "        \"\"\"Return loss value.\n",
    "        \n",
    "        Args:\n",
    "            u(torch.LongTensor): tensor stored user indexes. [batch_size,]\n",
    "            i(torch.LongTensor): tensor stored item indexes which is prefered by user. [batch_size,]\n",
    "            j(torch.LongTensor): tensor stored item indexes which is not prefered by user. [batch_size,]\n",
    "            epoch\n",
    "\n",
    "        Returns:\n",
    "            torch.FloatTensor\n",
    "        \"\"\"\n",
    "        ##u,i,j respectively, each is a vector of dim embedding (default = 64)\n",
    "#         u = self.user_emb[u, :]\n",
    "#         i = self.item_emb[i, :]\n",
    "#         j = self.item_emb[j, :]\n",
    "\n",
    "        ## Enables this Tensor to have their grad populated during backward(), convert any non-leaf tensor into a leaf tensor,\n",
    "        ##https://stackoverflow.com/questions/73698041/how-retain-grad-in-pytorch-works-i-found-its-position-changes-the-grad-result\n",
    "#         self.perturb.retain_grad()\n",
    "\n",
    "#       transform perturbation\n",
    "        perturb = transform_func(self.perturb)\n",
    "    \n",
    "        transformation_loss = criteria(self.perturb,perturb)\n",
    "        ## mf, dot product of user with pos/neg item\n",
    "        x_ui = torch.mul(self.user_emb[u, :] , self.item_emb[i, :] + perturb).sum(dim=1)\n",
    "        x_uj = torch.mul(self.user_emb[u, :] , self.item_emb[j, :] + perturb).sum(dim=1)\n",
    "        \n",
    "\n",
    "        #extract prediction for item and genres \n",
    "        \n",
    "        \n",
    "        ## Fix here, adversary needs to predict the recommendation for embedding + perturbation\n",
    "        \n",
    "        #torch.matmul(list(model1.items())[0][1], list(model1.items())[1][1][i,:].T)\n",
    "        #torch.matmul(self.user_emb,(self.item_emb[i, :] + perturb).T).T[i,:]\n",
    "#         i_feature = torch.matmul(self.user_emb,(self.item_emb[i, :] + perturb).T).T[i,:]\n",
    "#         j_feature = torch.matmul(self.user_emb,(self.item_emb[j, :] + perturb).T).T[j,:]\n",
    "        i_feature = Rec.T[i,:]\n",
    "        j_feature = Rec.T[j,:]\n",
    "        \n",
    "#         i_genre = item_genre[i,:]\n",
    "#         j_genre = item_genre[j,:]\n",
    "        \n",
    "        \n",
    "        i.prob = adversary(i_feature).mean(axis = 0)\n",
    "        j.prob = adversary(j_feature).mean(axis = 0)\n",
    "        \n",
    "        \n",
    "        \n",
    "#         1000 in a batch, group A & B\n",
    "#         A 300, B 700 (    [0.3, 0.7] vs [0.5 0.5]    )\n",
    "        \n",
    "#         Conditional prob P(g=Ga|i) for each item\n",
    "        \n",
    "        #similar to clip value, find diff between ui and uj\n",
    "        x_uij =torch.clamp(x_ui - x_uj,min=-80.0,max=1e8)\n",
    "        #logsigmoid this is equivalent to equation 1 in the paper (classic loss of bpr)\n",
    "        log_prob = F.logsigmoid(x_uij).sum()\n",
    "        # regularization = lambda * l2 norm of u, i, j\n",
    "        regularization = self.reg * (self.user_emb[u, :].norm(dim=1).pow(2).sum() + self.item_emb[i, :].norm(dim=1).pow(2).sum() + self.item_emb[j, :].norm(dim=1).pow(2).sum())\n",
    "\n",
    "        ## original bpr loss,\n",
    "        loss_bpr = -log_prob + regularization\n",
    "#         loss_bpr.backward(retain_graph=True)\n",
    "        \n",
    "        \n",
    "        loss_adv = F.kl_div(uniform_dist.log(), i.prob, None, None, 'sum') + F.kl_div(uniform_dist.log(), j.prob , None, None, 'sum')\n",
    "        total_loss = transformation_loss + loss_bpr + loss_adv\n",
    "\n",
    "        total_loss.backward()\n",
    "        \n",
    "        \n",
    "        return total_loss, perturb\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c95449f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4a9ed903",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('preprocessed/ml-1m-3.pickle', 'rb') as f:\n",
    "    dataset = pickle.load(f)\n",
    "    user_size, item_size = dataset['user_size'], dataset['item_size']\n",
    "    train_user_list, test_user_list = dataset['train_user_list'], dataset['test_user_list']\n",
    "    train_pair = dataset['train_pair']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3d1f537f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset, model, optimizer\n",
    "dataset = GetTriplePair(item_size, train_user_list, train_pair, True, 200)\n",
    "#list(model1.items())[0][1], list(model1.items())[1][1]\n",
    "# load batch of 512 item triplets\n",
    "loader = DataLoader(dataset, batch_size=512)\n",
    "model = fairness_reprogramming(list(model1.items())[0][1], list(model1.items())[1][1], Rec, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f82a9fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perturb tensor([[ 1.0600e-01,  6.5238e-02, -2.6381e-01, -1.4774e-02,  2.8193e-01,\n",
      "         -9.1815e-02, -8.1203e-02, -3.5143e-01, -1.3697e-01,  4.1094e-01,\n",
      "          1.7212e-01, -3.4257e-01, -1.9636e-01, -2.2342e-01, -9.2034e-02,\n",
      "          2.1856e-01, -3.3790e-02,  1.3517e-01, -4.1042e-02, -9.4797e-02,\n",
      "         -1.2732e-01,  7.4473e-02,  1.1121e-01, -2.7012e-01,  4.4458e-01,\n",
      "          7.1873e-02, -3.1197e-02, -2.9815e-01,  4.9906e-02,  1.3369e-01,\n",
      "         -2.4740e-04,  1.6069e-01, -2.2408e-01, -4.9899e-02, -1.4498e-01,\n",
      "          1.9026e-01,  1.9839e-01, -1.3061e-01, -8.1006e-02, -2.5560e-01,\n",
      "          1.9954e-01, -8.6621e-02, -3.0126e-02, -2.2062e-01, -9.8317e-02,\n",
      "         -1.9159e-01,  1.6894e-02, -3.2057e-01, -1.1384e-01,  1.1021e-01,\n",
      "          1.1109e-01,  1.3879e-01, -6.7672e-02, -1.5262e-01,  5.2401e-02,\n",
      "         -3.2221e-01,  5.7577e-02, -2.0666e-01,  8.4511e-02,  7.6068e-03,\n",
      "         -3.7681e-01,  7.1875e-03, -1.1640e-01,  2.1399e-03]]) None\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print (name, param.data, param.data.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "df76aaed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time 0:00:01\n",
      "BPR-MF Epoch [20/1000]\n",
      "loss: 135.0531\n",
      "HR@50: 0.4536, HR@100: 0.5974, NDCG@50: 0.1472, NDCG@100: 0.1472\n",
      "BPR-MF Epoch [40/1000]\n",
      "loss: 160.0160\n",
      "HR@50: 0.4536, HR@100: 0.5975, NDCG@50: 0.1472, NDCG@100: 0.1472\n",
      "BPR-MF Epoch [60/1000]\n",
      "loss: 171.9583\n",
      "HR@50: 0.4536, HR@100: 0.5976, NDCG@50: 0.1472, NDCG@100: 0.1472\n",
      "BPR-MF Epoch [80/1000]\n",
      "loss: 135.7449\n",
      "HR@50: 0.4537, HR@100: 0.5976, NDCG@50: 0.1472, NDCG@100: 0.1472\n",
      "BPR-MF Epoch [100/1000]\n",
      "loss: 149.3399\n",
      "HR@50: 0.4537, HR@100: 0.5976, NDCG@50: 0.1472, NDCG@100: 0.1472\n",
      "time 0:00:55\n",
      "BPR-MF Epoch [120/1000]\n",
      "loss: 202.9521\n",
      "HR@50: 0.4537, HR@100: 0.5976, NDCG@50: 0.1472, NDCG@100: 0.1472\n",
      "BPR-MF Epoch [140/1000]\n",
      "loss: 172.0774\n",
      "HR@50: 0.4537, HR@100: 0.5976, NDCG@50: 0.1472, NDCG@100: 0.1472\n",
      "BPR-MF Epoch [160/1000]\n",
      "loss: 180.4559\n",
      "HR@50: 0.4537, HR@100: 0.5976, NDCG@50: 0.1472, NDCG@100: 0.1472\n",
      "BPR-MF Epoch [180/1000]\n",
      "loss: 177.8299\n",
      "HR@50: 0.4537, HR@100: 0.5976, NDCG@50: 0.1472, NDCG@100: 0.1472\n",
      "BPR-MF Epoch [200/1000]\n",
      "loss: 140.0361\n",
      "HR@50: 0.4537, HR@100: 0.5975, NDCG@50: 0.1472, NDCG@100: 0.1472\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.000025)\n",
    "\n",
    "# Training\n",
    "start_time = time.time()\n",
    "eval_best_loss = float('inf')\n",
    "\n",
    "##zero_grad: zeroes the grad attribute of all the parameters passed to the optimizer upon construction\n",
    "optimizer.zero_grad()\n",
    "epoch = 0\n",
    "HR_history = []\n",
    "NDCG_history = []\n",
    "perturb_list = []\n",
    "# result_history = []\n",
    "#loader has batch size of 512. In each batch there are 3 tensors of u i j accordingly\n",
    "for u, i, j in loader:\n",
    "    if epoch in range(200):\n",
    "        loss,perturb = model(u, i, j, epoch)\n",
    "\n",
    "        ##  updates the value of those parameters according to the optimization strategy implemented by the specific optimizer.\n",
    "        optimizer.step()\n",
    "        HR_list, NDCG_list = evaluate_k(list(model1.items())[0][1] + perturb,\n",
    "                                        list(model1.items())[1][1] + perturb,\n",
    "                                        train_user_list,\n",
    "                                        test_user_list,\n",
    "                                        klist=[50, 100])\n",
    "        if epoch % 20 == (20- 1):\n",
    "            if epoch in range(1000):\n",
    "                print('BPR-MF Epoch [{}/{}]'.format(epoch + 1, 1000))\n",
    "            print('loss: %.4f' % loss)\n",
    "            print('HR@50: %.4f, HR@100: %.4f, NDCG@50: %.4f, NDCG@100: %.4f' % (\n",
    "                HR_list[0], HR_list[1], NDCG_list[0], NDCG_list[1]))\n",
    "        perturb_list.append(perturb)\n",
    "        HR_history.append(HR_list[1])\n",
    "        NDCG_history.append(NDCG_list[1])\n",
    "        if epoch % 100 == 0:\n",
    "            if loss < eval_best_loss:\n",
    "                eval_best_loss = loss\n",
    "                dirname = os.path.dirname(os.path.abspath('output/perturbation'))\n",
    "                os.makedirs(dirname, exist_ok=True)\n",
    "                torch.save(model.state_dict(), 'output/perturbation')\n",
    "                time_dif = get_time_dif(start_time)\n",
    "                print(\"time\", time_dif)\n",
    "        epoch += 1\n",
    "    else:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b31e3f",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/66572604/optimize-input-instead-of-network-in-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "614bc549",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load the results of BPR\n",
    "pertubation = (torch.load('output/perturbation'))\n",
    "list(pertubation.items())[0][1].size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "caa01e15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5562, 543])"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load the results of BPR\n",
    "model1 = (torch.load('output/bpr_manual'))\n",
    "list(model1.items())[0][1].size(),list(model1.items())[1][1].size()\n",
    "\n",
    "\n",
    "\n",
    "Rec = np.matmul(list(model1.items())[0][1]+list(pertubation.items())[0][1], (list(model1.items())[1][1]+list(pertubation.items())[0][1]).T)\n",
    "Rec.size()\n",
    "# Rec[1,:].size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "5d4e7ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vuhoang181/Documents/code_base/APR-PyTorch/utility.py:291: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  top15 = (np.array([top15_item_idx_no_train, u_pred[top15_item_idx_no_train]])).T\n",
      "/home/vuhoang181/Documents/code_base/APR-PyTorch/utility.py:291: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  top15 = (np.array([top15_item_idx_no_train, u_pred[top15_item_idx_no_train]])).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "####################################################################################################\n",
      "# System-level Recall:\n",
      "# \t\t\tRecall@1\tRecall@5\tRecall@10\tRecall@15\n",
      "# Sci-Fi\t\t0.00743\t\t0.04135\t\t0.08665\t\t0.13359\n",
      "# Horror\t\t0.00027\t\t0.00214\t\t0.00547\t\t0.00828\n",
      "# relative std\t\t0.93061\t\t0.90176\t\t0.88116\t\t0.88330\n",
      "####################################################################################################\n",
      "# User-level Recall:\n",
      "# \t\t\tRecall@1\tRecall@5\tRecall@10\tRecall@15\n",
      "# Sci-Fi\t\t0.00967\t\t0.05499\t\t0.11560\t\t0.17443\n",
      "# Horror\t\t0.00051\t\t0.00464\t\t0.01163\t\t0.01687\n",
      "# relative std\t\t0.90049\t\t0.84452\t\t0.81715\t\t0.82363\n",
      "####################################################################################################\n",
      "# System-level top ranking probability:\n",
      "# \t\t\t@1\t\t@5\t\t@10\t\t@15\n",
      "# Sci-Fi\t\t0.00370\t\t0.00764\t\t0.00764\t\t0.00764\n",
      "# Horror\t\t0.00035\t\t0.00041\t\t0.00041\t\t0.00041\n",
      "# relative std\t\t0.82604\t\t0.89932\t\t0.89932\t\t0.89932\n",
      "####################################################################################################\n",
      "# User-level top ranking probability:\n",
      "# \t\t\t@1\t\t@5\t\t@10\t\t@15\n",
      "# Sci-Fi\t\t0.00374\t\t0.00773\t\t0.00773\t\t0.00773\n",
      "# Horror\t\t0.00036\t\t0.00042\t\t0.00042\t\t0.00042\n",
      "# relative std\t\t0.82259\t\t0.89772\t\t0.89772\t\t0.89772\n",
      "####################################################################################################\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.82603744, 0.89931872, 0.89931872, 0.89931872]),\n",
       " array([0.93060609, 0.90175728, 0.88115807, 0.88330188]))"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import utility\n",
    "utility.ranking_analysis(Rec, vali_df, train_df, key_genre,\n",
    "                                                      item_genre_list, user_genre_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6adf9362",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vuhoang/Documents/code_base/APR-PyTorch/utility.py:291: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  top15 = (np.array([top15_item_idx_no_train, u_pred[top15_item_idx_no_train]])).T\n",
      "/Users/vuhoang/Documents/code_base/APR-PyTorch/utility.py:291: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  top15 = (np.array([top15_item_idx_no_train, u_pred[top15_item_idx_no_train]])).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "####################################################################################################\n",
      "# System-level Recall:\n",
      "# \t\t\tRecall@1\tRecall@5\tRecall@10\tRecall@15\n",
      "# Sci-Fi\t\t0.01387\t\t0.07008\t\t0.13872\t\t0.20853\n",
      "# Horror\t\t0.00013\t\t0.00027\t\t0.00067\t\t0.00160\n",
      "# relative std\t\t0.98093\t\t0.99241\t\t0.99042\t\t0.98475\n",
      "####################################################################################################\n",
      "# User-level Recall:\n",
      "# \t\t\tRecall@1\tRecall@5\tRecall@10\tRecall@15\n",
      "# Sci-Fi\t\t0.01711\t\t0.08543\t\t0.17070\t\t0.25925\n",
      "# Horror\t\t0.00019\t\t0.00038\t\t0.00099\t\t0.00234\n",
      "# relative std\t\t0.97804\t\t0.99115\t\t0.98849\t\t0.98214\n",
      "####################################################################################################\n",
      "# System-level top ranking probability:\n",
      "# \t\t\t@1\t\t@5\t\t@10\t\t@15\n",
      "# Sci-Fi\t\t0.00357\t\t0.00752\t\t0.00752\t\t0.00752\n",
      "# Horror\t\t0.00044\t\t0.00047\t\t0.00047\t\t0.00047\n",
      "# relative std\t\t0.78056\t\t0.88257\t\t0.88257\t\t0.88257\n",
      "####################################################################################################\n",
      "# User-level top ranking probability:\n",
      "# \t\t\t@1\t\t@5\t\t@10\t\t@15\n",
      "# Sci-Fi\t\t0.00361\t\t0.00761\t\t0.00761\t\t0.00761\n",
      "# Horror\t\t0.00045\t\t0.00048\t\t0.00048\t\t0.00048\n",
      "# relative std\t\t0.77751\t\t0.88108\t\t0.88108\t\t0.88108\n",
      "####################################################################################################\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.78055942, 0.88256852, 0.88256852, 0.88256852]),\n",
       " array([0.98093382, 0.99240851, 0.99042126, 0.98475139]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#before training\n",
    "import utility\n",
    "utility.ranking_analysis(Rec, vali_df, train_df, key_genre,\n",
    "                                                      item_genre_list, user_genre_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd769aa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.9876, 3.1480, 2.5682,  ..., 1.8456, 2.9970, 1.9240])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(list(model1.items())[0][1], list(model1.items())[1][1][43,:].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "76d6f44f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_65711/1973552975.py:12: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  top15 = (np.array([top15_item_idx_no_train, u_pred[top15_item_idx_no_train]])).T\n",
      "/tmp/ipykernel_65711/1973552975.py:12: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  top15 = (np.array([top15_item_idx_no_train, u_pred[top15_item_idx_no_train]])).T\n"
     ]
    }
   ],
   "source": [
    "for u in range(num_user):\n",
    "        #for each user list all the items that he likes, mark that to -10000\n",
    "        like_item = (train_df.loc[train_df['user_id'] == u, 'item_id']).tolist()\n",
    "        Rec[u, like_item] = -100000.0\n",
    "\n",
    "for u in range(num_user):  # iterate each user\n",
    "    #extract item that user actually match during testing, extract the prediction\n",
    "    u_test = (vali_df.loc[vali_df['user_id'] == u, 'item_id']).tolist()\n",
    "    u_pred = Rec[u, :]\n",
    "    \n",
    "    top15_item_idx_no_train = np.argpartition(u_pred, -1 * 15)[-1 * 15:]\n",
    "    top15 = (np.array([top15_item_idx_no_train, u_pred[top15_item_idx_no_train]])).T\n",
    "    top15 = sorted(top15, key=itemgetter(1), reverse=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e2cb0058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([ 13,   4,  69,  70, 101,  65,   3,   9,  22,  28,  17,   0,  93,  37,\n",
       "          25]),\n",
       " tensor([3.0920, 3.1099, 3.2114, 3.3218, 3.2073, 3.1634, 3.3581, 3.4992, 3.4403,\n",
       "         3.4401, 3.4102, 3.5279, 3.6224, 3.5806, 3.6968])]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d829144d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[38, 17, 46, 25, 0, 209]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "edca8e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not len(u_test) == 0:\n",
    "            recall_1_tmp_dict, recall_5_tmp_dict, recall_10_tmp_dict, recall_15_tmp_dict, \\\n",
    "            count_1_tmp_dict, count_5_tmp_dict, count_10_tmp_dict, count_15_tmp_dict, test_tmp_dict\\\n",
    "                = user_recall(top15, u_test, item_idd_genre_list, key_genre)\n",
    "            for k in key_genre:\n",
    "                count1_dict[k] += count_1_tmp_dict[k]\n",
    "                count5_dict[k] += count_5_tmp_dict[k]\n",
    "                count10_dict[k] += count_10_tmp_dict[k]\n",
    "                count15_dict[k] += count_15_tmp_dict[k]\n",
    "                test_count[k] += test_tmp_dict[k]\n",
    "                if recall_1_tmp_dict[k] == -1:\n",
    "                    continue\n",
    "                recall1_dict[k] += recall_1_tmp_dict[k]\n",
    "                recall5_dict[k] += recall_5_tmp_dict[k]\n",
    "                recall10_dict[k] += recall_10_tmp_dict[k]\n",
    "                recall15_dict[k] += recall_15_tmp_dict[k]\n",
    "                user_count_dict[k] += 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "945714b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank = 1\n",
    "for r in top15[0]:#top 15 items sorted\n",
    "# extract the genre of each topk movie\n",
    "    gl = item_idd_genre_list[int(r)]\n",
    "    for g in gl:\n",
    "        if g in key_genre:\n",
    "            #if the movie belongs to a key genre ==> add 1 to the dict\n",
    "            genre_rank_count[g][rank - 1] += 1.0 #size = no. of items\n",
    "            rank_count[rank - 1] += 1.0\n",
    "            if rank <= 15:\n",
    "                tmp_top15_dict[g] += 1.0 #no of movie in top15 for each key genre\n",
    "                if rank <= 10:\n",
    "                    tmp_top10_dict[g] += 1.0\n",
    "                    if rank <= 5:\n",
    "                        tmp_top5_dict[g] += 1.0\n",
    "                        if rank <= 1:\n",
    "                            tmp_top1_dict[g] += 1.0\n",
    "    rank += 1 #15 rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c72ef83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in key_genre:\n",
    "            top1_dict[k] += tmp_top1_dict[k]\n",
    "            top5_dict[k] += tmp_top5_dict[k]\n",
    "            top10_dict[k] += tmp_top10_dict[k]\n",
    "            top15_dict[k] += tmp_top15_dict[k]\n",
    "            avg_top1_dict[k] += (1.0 * tmp_top1_dict[k] / user_genre_count[u][k])\n",
    "            avg_top5_dict[k] += (1.0 * tmp_top5_dict[k] / user_genre_count[u][k])\n",
    "            avg_top10_dict[k] += (1.0 * tmp_top10_dict[k] / user_genre_count[u][k])\n",
    "            avg_top15_dict[k] += (1.0 * tmp_top15_dict[k] / user_genre_count[u][k])\n",
    "            tmp_top1_dict[k] = 0.0\n",
    "            tmp_top5_dict[k] = 0.0\n",
    "            tmp_top10_dict[k] = 0.0\n",
    "            tmp_top15_dict[k] = 0.0\n",
    "\n",
    "            genre_to_be_rank[k] += user_genre_count[u][k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "81c7cfb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Sci-Fi': 244.0, 'Horror': 313.0}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_to_be_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "01623f7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Horror': 298, 'Sci-Fi': 153}"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " user_genre_count[u]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "e59ad254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Sci-Fi': 17.0, 'Horror': 3.0}"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0909b04f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Sci-Fi': 0.0, 'Horror': 0.0}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count1_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2cbb1c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_65711/3143874929.py:77: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  top15 = (np.array([top15_item_idx_no_train, u_pred[top15_item_idx_no_train]])).T\n",
      "/tmp/ipykernel_65711/3143874929.py:77: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  top15 = (np.array([top15_item_idx_no_train, u_pred[top15_item_idx_no_train]])).T\n"
     ]
    }
   ],
   "source": [
    "Rec = copy.copy(Rec)\n",
    "\n",
    "count1_dict = dict()\n",
    "count5_dict = dict()\n",
    "count10_dict = dict()\n",
    "count15_dict = dict()\n",
    "test_count = dict()\n",
    "\n",
    "recall1_dict = dict()\n",
    "recall5_dict = dict()\n",
    "recall10_dict = dict()\n",
    "recall15_dict = dict()\n",
    "user_count_dict = dict()\n",
    "\n",
    "num_user = Rec.shape[0]\n",
    "num_item = Rec.shape[1]\n",
    "\n",
    "top1_dict = dict()\n",
    "top5_dict = dict()\n",
    "top10_dict = dict()\n",
    "top15_dict = dict()\n",
    "avg_top1_dict = dict()\n",
    "avg_top5_dict = dict()\n",
    "avg_top10_dict = dict()\n",
    "avg_top15_dict = dict()\n",
    "tmp_top1_dict = dict()\n",
    "tmp_top5_dict = dict()\n",
    "tmp_top10_dict = dict()\n",
    "tmp_top15_dict = dict()\n",
    "genre_rank_count = dict()\n",
    "rank_count = np.ones(num_item) * 1e-10\n",
    "\n",
    "genre_to_be_rank = dict()\n",
    "\n",
    "for k in key_genre:\n",
    "    genre_rank_count[k] = np.zeros(num_item)\n",
    "    top1_dict[k] = 0.0\n",
    "    top5_dict[k] = 0.0\n",
    "    top10_dict[k] = 0.0\n",
    "    top15_dict[k] = 0.0\n",
    "    avg_top1_dict[k] = 0.0\n",
    "    avg_top5_dict[k] = 0.0\n",
    "    avg_top10_dict[k] = 0.0\n",
    "    avg_top15_dict[k] = 0.0\n",
    "    tmp_top1_dict[k] = 0.0\n",
    "    tmp_top5_dict[k] = 0.0\n",
    "    tmp_top10_dict[k] = 0.0\n",
    "    tmp_top15_dict[k] = 0.0\n",
    "\n",
    "    recall1_dict[k] = 0.0\n",
    "    recall5_dict[k] = 0.0\n",
    "    recall10_dict[k] = 0.0\n",
    "    recall15_dict[k] = 0.0\n",
    "    user_count_dict[k] = 0.0\n",
    "\n",
    "    count1_dict[k] = 0.0\n",
    "    count5_dict[k] = 0.0\n",
    "    count10_dict[k] = 0.0\n",
    "    count15_dict[k] = 0.0\n",
    "\n",
    "    genre_to_be_rank[k] = 0.0\n",
    "    test_count[k] = 0.0\n",
    "\n",
    "for u in range(num_user):\n",
    "    #for each user list all the items that he likes, mark that to -10000\n",
    "    like_item = (train_df.loc[train_df['user_id'] == u, 'item_id']).tolist()\n",
    "    Rec[u, like_item] = -100000.0\n",
    "\n",
    "for u in range(num_user):  # iterate each user\n",
    "    #extract item that user actually match during testing, extract the prediction\n",
    "    u_test = (vali_df.loc[vali_df['user_id'] == u, 'item_id']).tolist()\n",
    "    u_pred = Rec[u, :]\n",
    "\n",
    "\n",
    "    #get top 15 items\n",
    "    top15_item_idx_no_train = np.argpartition(u_pred, -1 * top4)[-1 * top4:]\n",
    "    top15 = (np.array([top15_item_idx_no_train, u_pred[top15_item_idx_no_train]])).T\n",
    "    top15 = sorted(top15, key=itemgetter(1), reverse=True)\n",
    "\n",
    "    # calculate the recall for different genres\n",
    "    if not len(u_test) == 0:\n",
    "        recall_1_tmp_dict, recall_5_tmp_dict, recall_10_tmp_dict, recall_15_tmp_dict, \\\n",
    "        count_1_tmp_dict, count_5_tmp_dict, count_10_tmp_dict, count_15_tmp_dict, test_tmp_dict\\\n",
    "            = user_recall(top15, u_test, item_idd_genre_list, key_genre)\n",
    "        for k in key_genre:\n",
    "            count1_dict[k] += count_1_tmp_dict[k]\n",
    "            count5_dict[k] += count_5_tmp_dict[k]\n",
    "            count10_dict[k] += count_10_tmp_dict[k]\n",
    "            count15_dict[k] += count_15_tmp_dict[k]\n",
    "            test_count[k] += test_tmp_dict[k]\n",
    "            if recall_1_tmp_dict[k] == -1:\n",
    "                continue\n",
    "            recall1_dict[k] += recall_1_tmp_dict[k]\n",
    "            recall5_dict[k] += recall_5_tmp_dict[k]\n",
    "            recall10_dict[k] += recall_10_tmp_dict[k]\n",
    "            recall15_dict[k] += recall_15_tmp_dict[k]\n",
    "            user_count_dict[k] += 1.0\n",
    "\n",
    "    # calculate ranking probability\n",
    "    rank = 1\n",
    "    for r in top15[0]:#top 15 items sorted\n",
    "    # extract the genre of each topk movie\n",
    "        gl = item_idd_genre_list[int(r)]\n",
    "        for g in gl:\n",
    "            if g in key_genre:\n",
    "                #if the movie belongs to a key genre ==> add 1 to the dict\n",
    "                genre_rank_count[g][rank - 1] += 1.0 #size = no. of items\n",
    "                rank_count[rank - 1] += 1.0\n",
    "                if rank <= top4:\n",
    "                    tmp_top15_dict[g] += 1.0 #no of movie in top15 for each key genre\n",
    "                    if rank <= 10:\n",
    "                        tmp_top10_dict[g] += 1.0\n",
    "                        if rank <= 5:\n",
    "                            tmp_top5_dict[g] += 1.0\n",
    "                            if rank <= 1:\n",
    "                                tmp_top1_dict[g] += 1.0\n",
    "        rank += 1 #15 rank\n",
    "    for k in key_genre:\n",
    "        top1_dict[k] += tmp_top1_dict[k]\n",
    "        top5_dict[k] += tmp_top5_dict[k]\n",
    "        top10_dict[k] += tmp_top10_dict[k]\n",
    "        top15_dict[k] += tmp_top15_dict[k]\n",
    "        avg_top1_dict[k] += (1.0 * tmp_top1_dict[k] / user_genre_count[u][k]) #user_genre_count = no. of more in each key_genre that the user has not intereacted with in training\n",
    "        avg_top5_dict[k] += (1.0 * tmp_top5_dict[k] / user_genre_count[u][k]) #no. of uninteracted items that appears in topj kust if yser\n",
    "        avg_top10_dict[k] += (1.0 * tmp_top10_dict[k] / user_genre_count[u][k])\n",
    "        avg_top15_dict[k] += (1.0 * tmp_top15_dict[k] / user_genre_count[u][k])\n",
    "        tmp_top1_dict[k] = 0.0 #reset tmp dict\n",
    "        tmp_top5_dict[k] = 0.0\n",
    "        tmp_top10_dict[k] = 0.0\n",
    "        tmp_top15_dict[k] = 0.0\n",
    "\n",
    "        genre_to_be_rank[k] += user_genre_count[u][k]\n",
    "\n",
    "# compute the average recall for different genres, and print out the results\n",
    "for k in key_genre:\n",
    "    #count1_dict track no. of movie in key_genre that make it to topk (in topk list predicted)\n",
    "    count1_dict[k] /= test_count[k]\n",
    "    count5_dict[k] /= test_count[k]\n",
    "    count10_dict[k] /= test_count[k]\n",
    "    count15_dict[k] /= test_count[k]\n",
    "    recall1_dict[k] /= user_count_dict[k]\n",
    "    recall5_dict[k] /= user_count_dict[k]\n",
    "    recall10_dict[k] /= user_count_dict[k]\n",
    "    recall15_dict[k] /= user_count_dict[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "68239d60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Sci-Fi': 0.013871540332654, 'Horror': 0.0001335113484646195}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count1_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cdaab24c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Sci-Fi': 0.017110188410931936, 'Horror': 0.00018996960486322188}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall1_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8449acd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relative_std(dictionary):\n",
    "    tmp = []\n",
    "    for key, value in sorted(dictionary.items(), key = lambda x: x[0]):\n",
    "        tmp.append(value)\n",
    "#     rstd = np.std(tmp) / (np.mean(tmp) + 1e-10)\n",
    "    return np.std(tmp),np.mean(tmp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a81544cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.00686901449209469, 0.0070025258405593096)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relative_std(count1_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f475ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
