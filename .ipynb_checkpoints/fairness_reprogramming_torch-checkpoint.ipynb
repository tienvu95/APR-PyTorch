{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35dba935",
   "metadata": {},
   "source": [
    "Thinking of APR. Are we doing the dual optimization with the classification model + the pertubation added?\n",
    "\n",
    "1. Run BPR and retrieve the model parameters + predict with fixed parameters\n",
    "2. Use predictions by BPR, train an adversary, save the trained parameters of the MLPs\n",
    "3. Load parameters of BPR, optimize for a perturbations with the new overall objective\n",
    "\n",
    "    Loss BPR (with fixed params + perturbation) + Loss adversary (with fixed params + perturbation)\n",
    "\n",
    "\n",
    "To Do?\n",
    "\n",
    "\n",
    "1. How to compute P(g = G1)? How to retrieve $P_{adv}(i)$ and $P_{adv}(j)$. As of now it is computed as, for a batch of 512 predictions for group membership, compute % of item predicted as G1, G2,...,Gn. Find conditional prob for each item -- TO FIX\n",
    "2. Audit the formula for REO and RSP -- Seems alright but cannot reproduce the recall for R@5, R@10, R@15\n",
    "3. Tranformation function is necessary, how can we define such transformation? i.e. cannot directly optimize embedding + $\\delta$ if $\\delta$ is just a fixed tensor size = embedding dim\n",
    "4. Tuning for the adversary, check case for 6-groups\n",
    "5. Test on more extensive dataset\n",
    "6. Summarize pipeline\n",
    "7. Check the popularity of REO, RSP. Is this fairness definition widely used?\n",
    "    - https://github.com/sisinflab/The-Idiosyncratic-Effects-of-Adversarial-Training/tree/main/src/evaluation recsys\n",
    "    - https://www.semanticscholar.org/reader/f2c12f705aea19ab5e129f72ae9030375f06602f www\n",
    "    - https://www.semanticscholar.org/reader/1459f5a33ae88d4c26594d867201635651c1dd72 recsys\n",
    "    - https://oar.a-star.edu.sg/storage/8/8d1z0edy00/lzz-tois-fairness.pdf  TOIS\n",
    "    - https://www.semanticscholar.org/reader/9eb96c7554d4dac063b47443f38866adbf90b829 recsys\n",
    "    - https://arxiv.org/pdf/2203.01155.pdf UMAP\n",
    "8. Will the universal perturbation work for recsys? do we have to fine-tune, add complexity to the perturbation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04a30440",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import relevant library\n",
    "\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import pickle\n",
    "import argparse\n",
    "from collections import deque\n",
    "import time\n",
    "import utility\n",
    "import tqdm\n",
    "import copy\n",
    "from operator import itemgetter\n",
    "from datetime import timedelta\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "# from torchvision.datasets import CIFAR10\n",
    "from torch.utils.data import DataLoader\n",
    "# from torchvision import transforms\n",
    "from torch.utils.data import IterableDataset, DataLoader, get_worker_info\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f262aa84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d897bb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## time the process\n",
    "def get_time_dif(start_time):\n",
    "    \"\"\"get the running time\"\"\"\n",
    "    end_time = time.time()\n",
    "    time_dif = end_time - start_time\n",
    "    return timedelta(seconds=int(round(time_dif)))\n",
    "\n",
    "\n",
    "## set up the u,i,j triplet for BPR framework\n",
    "class GetTriplePair(IterableDataset):\n",
    "    # for ml-1m we load in 3760 item 6040 user and 994169 train pair\n",
    "    def __init__(self, item_size, user_list, pair, shuffle, num_epochs):\n",
    "        self.item_size = item_size\n",
    "        self.user_list = user_list\n",
    "        self.pair = pair\n",
    "        self.shuffle = shuffle\n",
    "        self.num_epochs = num_epochs\n",
    "\n",
    "    def __iter__(self):\n",
    "        self.example_size = self.num_epochs * len(self.pair)\n",
    "        self.example_index_queue = deque([])\n",
    "        self.seed = 0\n",
    "        self.start_list_index = None\n",
    "        self.num_workers = 1\n",
    "        self.index = 0\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.index >= self.example_size:\n",
    "            raise StopIteration\n",
    "        # If `example_index_queue` is used up, replenish this list.\n",
    "        while len(self.example_index_queue) == 0:\n",
    "            index_list = list(range(len(self.pair)))\n",
    "            if self.shuffle:\n",
    "                random.Random(self.seed).shuffle(index_list)\n",
    "                self.seed += 1\n",
    "            if self.start_list_index is not None:\n",
    "                index_list = index_list[self.start_list_index::self.num_workers]\n",
    "\n",
    "                # Calculate next start index\n",
    "                self.start_list_index = (self.start_list_index + (self.num_workers - (len(self.pair) % self.num_workers))) % self.num_workers\n",
    "            self.example_index_queue.extend(index_list)\n",
    "        result = self._example(self.example_index_queue.popleft())\n",
    "        self.index += self.num_workers\n",
    "        return result\n",
    "\n",
    "    def _example(self, idx):\n",
    "        # in a train pair, format = (u,i), j = a random item which does not exist in user u's list of items\n",
    "        u = self.pair[idx][0]\n",
    "        i = self.pair[idx][1]\n",
    "        j = np.random.randint(self.item_size)\n",
    "        while j in self.user_list[u]:\n",
    "            j = np.random.randint(self.item_size)\n",
    "        return u, i, j\n",
    "\n",
    "## chunk to define matrix factorization part\n",
    "class MF(nn.Module):\n",
    "    def __init__(self, user_size, item_size, dim, reg, reg_adv, eps):\n",
    "        super().__init__()\n",
    "        ##init the embedding for U and I\n",
    "        self.W = nn.Parameter(torch.empty(user_size, dim))  # User embedding\n",
    "        self.H = nn.Parameter(torch.empty(item_size, dim))  # Item embedding\n",
    "        nn.init.xavier_normal_(self.W.data)\n",
    "        nn.init.xavier_normal_(self.H.data)\n",
    "        self.reg = reg\n",
    "        self.user_size = user_size\n",
    "        self.item_size = item_size\n",
    "        self.dim = dim\n",
    "        self.reg_adv = reg_adv\n",
    "        self.eps = eps\n",
    "        self.update_u = None\n",
    "        self.update_i = None\n",
    "        self.update_j = None\n",
    "\n",
    "## forward cal\n",
    "    def forward(self, u, i, j, epoch):\n",
    "        \"\"\"Return loss value.\n",
    "\n",
    "        Args:\n",
    "            u(torch.LongTensor): tensor stored user indexes. [batch_size,]\n",
    "            i(torch.LongTensor): tensor stored item indexes which is prefered by user. [batch_size,]\n",
    "            j(torch.LongTensor): tensor stored item indexes which is not prefered by user. [batch_size,]\n",
    "            epoch\n",
    "\n",
    "        Returns:\n",
    "            torch.FloatTensor\n",
    "        \"\"\"\n",
    "        ##u,i,j respectively, each is a vector of dim embedding (default = 64)\n",
    "        u = self.W[u, :]\n",
    "        i = self.H[i, :]\n",
    "        j = self.H[j, :]\n",
    "\n",
    "        ## Enables this Tensor to have their grad populated during backward(), convert any non-leaf tensor into a leaf tensor,\n",
    "        ##https://stackoverflow.com/questions/73698041/how-retain-grad-in-pytorch-works-i-found-its-position-changes-the-grad-result\n",
    "        u.retain_grad()\n",
    "        u_clone = u.data.clone()\n",
    "        i.retain_grad()\n",
    "        i_clone = i.data.clone()\n",
    "        j.retain_grad()\n",
    "        j_clone = j.data.clone()\n",
    "\n",
    "        ## mf, dot product of user with pos/neg item\n",
    "        x_ui = torch.mul(u, i).sum(dim=1)\n",
    "        x_uj = torch.mul(u, j).sum(dim=1)\n",
    "\n",
    "\n",
    "        #similar to clip value, find diff between ui and uj\n",
    "        x_uij =torch.clamp(x_ui - x_uj,min=-80.0,max=1e8)\n",
    "        #logsigmoid this is equivalent to equation 1 in the paper (classic loss of bpr)\n",
    "        log_prob = F.logsigmoid(x_uij).sum()\n",
    "        # regularization = lambda * l2 norm of u, i, j\n",
    "        regularization = self.reg * (u.norm(dim=1).pow(2).sum() + i.norm(dim=1).pow(2).sum() + j.norm(dim=1).pow(2).sum())\n",
    "\n",
    "        ## original bpr loss,\n",
    "        loss = -log_prob + regularization\n",
    "\n",
    "        loss.backward()\n",
    "        return loss\n",
    "        # add adv training after a certain number of epochs, here is the part which we add hypernet module\n",
    "        if epoch not in range(args.epochs, args.adv_epoch + args.epochs):\n",
    "            \"\"\"Normal training\"\"\"\n",
    "            loss.backward()\n",
    "            return loss\n",
    "\n",
    "        else:\n",
    "            \"\"\"Adversarial training:\n",
    "                    1.Backward to get grads\n",
    "                    2.Construct adversarial perturbation\n",
    "                    3.Add adversarial perturbation to embeddings\n",
    "                    4.Calculate APR loss\n",
    "            \"\"\"\n",
    "            # Backward to get grads\n",
    "            # this would be the part we change in defining delta, delta = HPN (phi)\n",
    "\n",
    "            # should we calculate based on gradient of the adv_loss instead of the loss function?, originally, computed based on loss function\n",
    "            loss.backward(retain_graph=True) ## need to retain graph here so as to we can backprop the adv_loss\n",
    "            ##recheck this\n",
    "            grad_u = u.grad\n",
    "            grad_i = i.grad\n",
    "            grad_j = j.grad\n",
    "\n",
    "            # Construct adversarial perturbation based on gradient of loss function, and normalize it with epsilon * norm\n",
    "            if grad_u is not None:\n",
    "                delta_u = nn.functional.normalize(grad_u, p=2, dim=1, eps=self.eps)\n",
    "            else:\n",
    "                delta_u = torch.rand(u.size())\n",
    "            if grad_i is not None:\n",
    "                delta_i = nn.functional.normalize(grad_i, p=2, dim=1, eps=self.eps)\n",
    "            else:\n",
    "                delta_i = torch.rand(i.size())\n",
    "            if grad_j is not None:\n",
    "                delta_j = nn.functional.normalize(grad_j, p=2, dim=1, eps=self.eps)\n",
    "            else:\n",
    "                delta_j = torch.rand(j.size())\n",
    "\n",
    "            # Add adversarial perturbation to embeddings, now we have q+delta, p+delta\n",
    "            x_ui_adv = torch.mul(u + delta_u, i + delta_i).sum(dim=1)\n",
    "            x_uj_adv = torch.mul(u + delta_u, j + delta_j).sum(dim=1)\n",
    "\n",
    "            # find difference between pos and neg item, then clip value\n",
    "            x_uij_adv = torch.clamp(x_ui_adv - x_uj_adv,min=-80.0,max=1e8)\n",
    "\n",
    "            # Calculate APR loss with logsigmoid\n",
    "            log_prob = F.logsigmoid(x_uij_adv).sum()\n",
    "            adv_loss = self.reg_adv *(-log_prob) + loss # this is adversarial loss (equation 4 in paper)\n",
    "            adv_loss.backward()\n",
    "\n",
    "            return adv_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1a455a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_k(user_emb, item_emb, train_user_list, test_user_list, klist, batch=512):\n",
    "    \"\"\"Compute HR and NDCG at k.\n",
    "\n",
    "    Args:\n",
    "        user_emb (torch.Tensor): embedding for user [user_num, dim]\n",
    "        item_emb (torch.Tensor): embedding for item [item_num, dim]\n",
    "        train_user_list (list(set)):\n",
    "        test_user_list (list(set)):\n",
    "        k (list(int)):\n",
    "    Returns:\n",
    "        (torch.Tensor, torch.Tensor) HR and NDCG at k\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate max k value\n",
    "    max_k = max(klist)\n",
    "    result = None\n",
    "\n",
    "    # no iteration = user_num / batch size (which is 512)\n",
    "    for i in range(0, user_emb.shape[0], batch):\n",
    "\n",
    "        # Construct mask for each batch\n",
    "\n",
    "        #new_ones returns a Tensor of size size filled with 1\n",
    "\n",
    "        # size of the mask vector = (min of batch or user embed) * item+embed\n",
    "        mask = user_emb.new_ones([min([batch, user_emb.shape[0]-i]), item_emb.shape[0]])\n",
    "        for j in range(batch):\n",
    "            if i+j >= user_emb.shape[0]:\n",
    "                break\n",
    "            mask[j].scatter_(dim=0, index=torch.tensor(list(train_user_list[i + j])), value=torch.tensor(0.0))\n",
    "\n",
    "        # Get current result\n",
    "        cur_result = torch.mm(user_emb[i:i+min(batch, user_emb.shape[0]-i), :], item_emb.t())\n",
    "        cur_result = torch.sigmoid(cur_result)\n",
    "        assert not torch.any(torch.isnan(cur_result))\n",
    "\n",
    "        # Make zero for already observed item\n",
    "        cur_result = torch.mul(mask, cur_result)\n",
    "        _, cur_result = torch.topk(cur_result, k=max_k, dim=1)\n",
    "        result = cur_result if result is None else torch.cat((result, cur_result), dim=0)\n",
    "\n",
    "\n",
    "    ## basically this chunk collects the results\n",
    "    result = result.cpu()\n",
    "\n",
    "    # Sort indice and get HR_NDCG_topk\n",
    "    HRs, NDCGs = [], []\n",
    "    for k in klist:\n",
    "        ndcg, hr = 0, 0\n",
    "        #for all user\n",
    "        for i in range(user_emb.shape[0]):\n",
    "            #set helps to identify unique members in a list\n",
    "            test = set(test_user_list[i])\n",
    "            #top k item from prediction list\n",
    "            pred = set(result[i, :k].numpy().tolist())\n",
    "            #if topk lies on both test and pred list\n",
    "            val = len(test & pred)\n",
    "            #hit ratio = %item hit\n",
    "            hr += val / max([len(test), 1])\n",
    "            #convert pred back to list\n",
    "            pred = list(pred)\n",
    "            if test_user_list[i] == []:\n",
    "                continue\n",
    "            else:\n",
    "                x = int(test_user_list[i][0])\n",
    "                ## check if x is in the prediction where x = 1st member of user list\n",
    "                if pred.count(x) != 0:\n",
    "                    position = pred.index(x)\n",
    "                    ndcg += math.log(2) / math.log(position + 2) if position < k else 0\n",
    "                else:\n",
    "                    ndcg += 0                \n",
    "#                 for x in test_user_list[i]:\n",
    "#                     x = int(x)\n",
    "#                     ## check if x is in the prediction where x = 1st member of user list\n",
    "#                     if pred.count(x) != 0:\n",
    "#                         position = pred.index(x)\n",
    "#                         ndcg += math.log(2) / math.log(position + 2) if position < k else 0\n",
    "#                     else:\n",
    "#                         ndcg += 0\n",
    "        NDCGs.append(ndcg / user_emb.shape[0])\n",
    "        HRs.append(hr / user_emb.shape[0])\n",
    "        NDCGs.append(ndcg / user_emb.shape[0])\n",
    "    return HRs, NDCGs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f204e348",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('preprocessed/ml-1m-2.pickle', 'rb') as f:\n",
    "    dataset = pickle.load(f)\n",
    "    user_size, item_size = dataset['user_size'], dataset['item_size']\n",
    "    train_user_list, test_user_list = dataset['train_user_list'], dataset['test_user_list']\n",
    "    train_pair = dataset['train_pair']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2e7ffdb1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create dataset, model, optimizer\n",
    "dataset = GetTriplePair(item_size, train_user_list, train_pair, True, 1000)\n",
    "\n",
    "# load batch of 512 item triplets\n",
    "loader = DataLoader(dataset, batch_size=512)\n",
    "model = MF(user_size, item_size, 64, 0, 1, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d655d783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time 0:00:00\n",
      "BPR-MF Epoch [20/1000]\n",
      "loss: 354.8626\n",
      "HR@50: 0.0328, HR@100: 0.0680, NDCG@50: 0.0082, NDCG@100: 0.0082\n",
      "BPR-MF Epoch [40/1000]\n",
      "loss: 354.9197\n",
      "HR@50: 0.0333, HR@100: 0.0702, NDCG@50: 0.0086, NDCG@100: 0.0086\n",
      "BPR-MF Epoch [60/1000]\n",
      "loss: 354.9126\n",
      "HR@50: 0.0334, HR@100: 0.0695, NDCG@50: 0.0078, NDCG@100: 0.0078\n",
      "BPR-MF Epoch [80/1000]\n",
      "loss: 355.1970\n",
      "HR@50: 0.0346, HR@100: 0.0688, NDCG@50: 0.0077, NDCG@100: 0.0077\n",
      "BPR-MF Epoch [100/1000]\n",
      "loss: 354.6462\n",
      "HR@50: 0.0359, HR@100: 0.0696, NDCG@50: 0.0087, NDCG@100: 0.0087\n",
      "BPR-MF Epoch [120/1000]\n",
      "loss: 354.7908\n",
      "HR@50: 0.0379, HR@100: 0.0725, NDCG@50: 0.0092, NDCG@100: 0.0092\n",
      "BPR-MF Epoch [140/1000]\n",
      "loss: 354.4792\n",
      "HR@50: 0.0401, HR@100: 0.0799, NDCG@50: 0.0102, NDCG@100: 0.0102\n",
      "BPR-MF Epoch [160/1000]\n",
      "loss: 354.4339\n",
      "HR@50: 0.0463, HR@100: 0.0867, NDCG@50: 0.0121, NDCG@100: 0.0121\n",
      "BPR-MF Epoch [180/1000]\n",
      "loss: 353.4958\n",
      "HR@50: 0.0548, HR@100: 0.1001, NDCG@50: 0.0140, NDCG@100: 0.0140\n",
      "BPR-MF Epoch [200/1000]\n",
      "loss: 353.2401\n",
      "HR@50: 0.0665, HR@100: 0.1203, NDCG@50: 0.0172, NDCG@100: 0.0172\n",
      "time 0:00:33\n",
      "BPR-MF Epoch [220/1000]\n",
      "loss: 351.4318\n",
      "HR@50: 0.0815, HR@100: 0.1452, NDCG@50: 0.0206, NDCG@100: 0.0206\n",
      "BPR-MF Epoch [240/1000]\n",
      "loss: 349.2975\n",
      "HR@50: 0.1023, HR@100: 0.1776, NDCG@50: 0.0262, NDCG@100: 0.0262\n",
      "BPR-MF Epoch [260/1000]\n",
      "loss: 346.9237\n",
      "HR@50: 0.1241, HR@100: 0.2115, NDCG@50: 0.0320, NDCG@100: 0.0320\n",
      "BPR-MF Epoch [280/1000]\n",
      "loss: 342.9560\n",
      "HR@50: 0.1468, HR@100: 0.2441, NDCG@50: 0.0390, NDCG@100: 0.0390\n",
      "BPR-MF Epoch [300/1000]\n",
      "loss: 336.2942\n",
      "HR@50: 0.1666, HR@100: 0.2738, NDCG@50: 0.0447, NDCG@100: 0.0447\n",
      "time 0:00:50\n",
      "BPR-MF Epoch [320/1000]\n",
      "loss: 329.4124\n",
      "HR@50: 0.1830, HR@100: 0.2964, NDCG@50: 0.0484, NDCG@100: 0.0484\n",
      "BPR-MF Epoch [340/1000]\n",
      "loss: 315.7037\n",
      "HR@50: 0.1979, HR@100: 0.3197, NDCG@50: 0.0532, NDCG@100: 0.0532\n",
      "BPR-MF Epoch [360/1000]\n",
      "loss: 307.5340\n",
      "HR@50: 0.2101, HR@100: 0.3373, NDCG@50: 0.0569, NDCG@100: 0.0569\n",
      "BPR-MF Epoch [380/1000]\n",
      "loss: 294.7388\n",
      "HR@50: 0.2212, HR@100: 0.3504, NDCG@50: 0.0606, NDCG@100: 0.0606\n",
      "BPR-MF Epoch [400/1000]\n",
      "loss: 279.7023\n",
      "HR@50: 0.2310, HR@100: 0.3597, NDCG@50: 0.0633, NDCG@100: 0.0633\n",
      "time 0:01:06\n",
      "BPR-MF Epoch [420/1000]\n",
      "loss: 267.5856\n",
      "HR@50: 0.2386, HR@100: 0.3687, NDCG@50: 0.0666, NDCG@100: 0.0666\n",
      "BPR-MF Epoch [440/1000]\n",
      "loss: 259.0987\n",
      "HR@50: 0.2439, HR@100: 0.3762, NDCG@50: 0.0683, NDCG@100: 0.0683\n",
      "BPR-MF Epoch [460/1000]\n",
      "loss: 257.4637\n",
      "HR@50: 0.2499, HR@100: 0.3826, NDCG@50: 0.0709, NDCG@100: 0.0709\n",
      "BPR-MF Epoch [480/1000]\n",
      "loss: 237.8245\n",
      "HR@50: 0.2543, HR@100: 0.3874, NDCG@50: 0.0726, NDCG@100: 0.0726\n",
      "BPR-MF Epoch [500/1000]\n",
      "loss: 236.6560\n",
      "HR@50: 0.2594, HR@100: 0.3929, NDCG@50: 0.0738, NDCG@100: 0.0738\n",
      "time 0:01:23\n",
      "BPR-MF Epoch [520/1000]\n",
      "loss: 217.8620\n",
      "HR@50: 0.2631, HR@100: 0.3962, NDCG@50: 0.0754, NDCG@100: 0.0754\n",
      "BPR-MF Epoch [540/1000]\n",
      "loss: 215.8915\n",
      "HR@50: 0.2670, HR@100: 0.4002, NDCG@50: 0.0768, NDCG@100: 0.0768\n",
      "BPR-MF Epoch [560/1000]\n",
      "loss: 204.3703\n",
      "HR@50: 0.2716, HR@100: 0.4044, NDCG@50: 0.0788, NDCG@100: 0.0788\n",
      "BPR-MF Epoch [580/1000]\n",
      "loss: 202.2787\n",
      "HR@50: 0.2762, HR@100: 0.4083, NDCG@50: 0.0798, NDCG@100: 0.0798\n",
      "BPR-MF Epoch [600/1000]\n",
      "loss: 174.1266\n",
      "HR@50: 0.2819, HR@100: 0.4126, NDCG@50: 0.0811, NDCG@100: 0.0811\n",
      "time 0:01:39\n",
      "BPR-MF Epoch [620/1000]\n",
      "loss: 214.1581\n",
      "HR@50: 0.2860, HR@100: 0.4154, NDCG@50: 0.0822, NDCG@100: 0.0822\n",
      "BPR-MF Epoch [640/1000]\n",
      "loss: 197.5949\n",
      "HR@50: 0.2891, HR@100: 0.4183, NDCG@50: 0.0835, NDCG@100: 0.0835\n",
      "BPR-MF Epoch [660/1000]\n",
      "loss: 205.6474\n",
      "HR@50: 0.2917, HR@100: 0.4208, NDCG@50: 0.0845, NDCG@100: 0.0845\n",
      "BPR-MF Epoch [680/1000]\n",
      "loss: 206.1370\n",
      "HR@50: 0.2952, HR@100: 0.4237, NDCG@50: 0.0859, NDCG@100: 0.0859\n",
      "BPR-MF Epoch [700/1000]\n",
      "loss: 168.9118\n",
      "HR@50: 0.2996, HR@100: 0.4255, NDCG@50: 0.0876, NDCG@100: 0.0876\n",
      "time 0:01:55\n",
      "BPR-MF Epoch [720/1000]\n",
      "loss: 191.4801\n",
      "HR@50: 0.3016, HR@100: 0.4270, NDCG@50: 0.0883, NDCG@100: 0.0883\n",
      "BPR-MF Epoch [740/1000]\n",
      "loss: 188.3932\n",
      "HR@50: 0.3034, HR@100: 0.4288, NDCG@50: 0.0887, NDCG@100: 0.0887\n",
      "BPR-MF Epoch [760/1000]\n",
      "loss: 185.9254\n",
      "HR@50: 0.3041, HR@100: 0.4310, NDCG@50: 0.0889, NDCG@100: 0.0889\n",
      "BPR-MF Epoch [780/1000]\n",
      "loss: 151.7047\n",
      "HR@50: 0.3056, HR@100: 0.4329, NDCG@50: 0.0893, NDCG@100: 0.0893\n",
      "BPR-MF Epoch [800/1000]\n",
      "loss: 182.0482\n",
      "HR@50: 0.3085, HR@100: 0.4339, NDCG@50: 0.0902, NDCG@100: 0.0902\n",
      "BPR-MF Epoch [820/1000]\n",
      "loss: 196.8978\n",
      "HR@50: 0.3090, HR@100: 0.4347, NDCG@50: 0.0900, NDCG@100: 0.0900\n",
      "BPR-MF Epoch [840/1000]\n",
      "loss: 192.9309\n",
      "HR@50: 0.3108, HR@100: 0.4365, NDCG@50: 0.0905, NDCG@100: 0.0905\n",
      "BPR-MF Epoch [860/1000]\n",
      "loss: 219.8609\n",
      "HR@50: 0.3130, HR@100: 0.4373, NDCG@50: 0.0913, NDCG@100: 0.0913\n",
      "BPR-MF Epoch [880/1000]\n",
      "loss: 206.7970\n",
      "HR@50: 0.3136, HR@100: 0.4390, NDCG@50: 0.0914, NDCG@100: 0.0914\n",
      "BPR-MF Epoch [900/1000]\n",
      "loss: 169.2448\n",
      "HR@50: 0.3143, HR@100: 0.4408, NDCG@50: 0.0911, NDCG@100: 0.0911\n",
      "time 0:02:27\n",
      "BPR-MF Epoch [920/1000]\n",
      "loss: 176.5931\n",
      "HR@50: 0.3152, HR@100: 0.4421, NDCG@50: 0.0912, NDCG@100: 0.0912\n",
      "BPR-MF Epoch [940/1000]\n",
      "loss: 195.1898\n",
      "HR@50: 0.3163, HR@100: 0.4432, NDCG@50: 0.0911, NDCG@100: 0.0911\n",
      "BPR-MF Epoch [960/1000]\n",
      "loss: 204.5227\n",
      "HR@50: 0.3166, HR@100: 0.4456, NDCG@50: 0.0905, NDCG@100: 0.0905\n",
      "BPR-MF Epoch [980/1000]\n",
      "loss: 201.4071\n",
      "HR@50: 0.3177, HR@100: 0.4469, NDCG@50: 0.0907, NDCG@100: 0.0907\n",
      "BPR-MF Epoch [1000/1000]\n",
      "loss: 198.0921\n",
      "HR@50: 0.3181, HR@100: 0.4486, NDCG@50: 0.0906, NDCG@100: 0.0906\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.00025) #.00025\n",
    "\n",
    "# Training\n",
    "start_time = time.time()\n",
    "eval_best_loss = float('inf')\n",
    "\n",
    "##zero_grad: zeroes the grad attribute of all the parameters passed to the optimizer upon construction\n",
    "optimizer.zero_grad()\n",
    "epoch = 0\n",
    "HR_history = []\n",
    "NDCG_history = []\n",
    "# result_history = []\n",
    "#loader has batch size of 512. In each batch there are 3 tensors of u i j accordingly\n",
    "for u, i, j in loader:\n",
    "    if epoch in range(1000):\n",
    "        loss = model(u, i, j, epoch)\n",
    "\n",
    "        ##  updates the value of those parameters according to the optimization strategy implemented by the specific optimizer.\n",
    "        optimizer.step()\n",
    "        HR_list, NDCG_list = evaluate_k(model.W.detach(),\n",
    "                                        model.H.detach(),\n",
    "                                        train_user_list,\n",
    "                                        test_user_list,\n",
    "                                        klist=[50, 100])\n",
    "        if epoch % 20 == (20- 1):\n",
    "            if epoch in range(1000):\n",
    "                print('BPR-MF Epoch [{}/{}]'.format(epoch + 1, 1000))\n",
    "            print('loss: %.4f' % loss)\n",
    "            print('HR@50: %.4f, HR@100: %.4f, NDCG@50: %.4f, NDCG@100: %.4f' % (\n",
    "                HR_list[0], HR_list[1], NDCG_list[0], NDCG_list[1]))\n",
    "        HR_history.append(HR_list[1])\n",
    "        NDCG_history.append(NDCG_list[1])\n",
    "        if epoch % 100 == 0:\n",
    "            if loss < eval_best_loss:\n",
    "                eval_best_loss = loss\n",
    "                dirname = os.path.dirname(os.path.abspath('output/bpr_manual'))\n",
    "                os.makedirs(dirname, exist_ok=True)\n",
    "                torch.save(model.state_dict(), 'output/bpr_manual')\n",
    "                time_dif = get_time_dif(start_time)\n",
    "                print(\"time\", time_dif)\n",
    "        epoch += 1\n",
    "    else:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b039d9",
   "metadata": {},
   "source": [
    "for ml-1m-2 data set with continue , epoch 1000 has\n",
    "loss: 160.6638\n",
    "HR@50: 0.3218, HR@100: 0.4558, NDCG@50: 0.0939, NDCG@100: 0.0939\n",
    "\n",
    "\n",
    "\n",
    "for ml-1m-6 data set with continue , epoch 1000 has\n",
    "loss: 160.6638\n",
    "HR@50: 0.3218, HR@100: 0.4558, NDCG@50: 0.0939, NDCG@100: 0.0939\n",
    "\n",
    "for ml-1m-6 data set with continue + for loop for X in test user set , epoch 1000 has\n",
    "loss: 196.0934\n",
    "HR@50: 0.3266, HR@100: 0.4649, NDCG@50: 0.7004, NDCG@100: 0.7004\n",
    "\n",
    "\n",
    "ml-1m normal dataset\n",
    "loss: 150.8645\n",
    "HR@50: 0.1437, HR@100: 0.2245, NDCG@50: 0.0365, NDCG@100: 0.0365\n",
    "\n",
    "test ml-1m normal dataset with for loop for X in test user set\n",
    "loss: 181.7949\n",
    "HR@50: 0.1480, HR@100: 0.2252, NDCG@50: 0.0373, NDCG@100: 0.0373"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "29d7f1e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig_HR = plt.figure(edgecolor='blue')\n",
    "ax1 = fig_HR.add_subplot(111)\n",
    "plt.ylabel('HR@100')\n",
    "plt.xlabel('Epoch')\n",
    "plt.title('ML-1M')\n",
    "ax1.plot(range(len(HR_history)), HR_history, c=np.array([255, 71, 90]) / 255.)\n",
    "plt.show()\n",
    "fig_P = plt.figure(edgecolor='blue')\n",
    "ax1 = fig_P.add_subplot(111)\n",
    "plt.ylabel('NDCG@100')\n",
    "plt.xlabel('Epoch')\n",
    "plt.title('ML-1M')\n",
    "ax1.plot(range(len(NDCG_history)), NDCG_history, c=np.array([255, 71, 90]) / 255.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886dcf79",
   "metadata": {},
   "source": [
    "Running a saving output of BPR model\n",
    "\n",
    "Next up = train adversary based on fixed parameters of BPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b6ae75b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_pickle(r'ml1m-6/training_df.pkl')\n",
    "vali_df = pd.read_pickle(r'ml1m-6/valiing_df.pkl')\n",
    "key_genre = pd.read_pickle(r'ml1m-6/key_genre.pkl')  \n",
    "item_idd_genre_list = pd.read_pickle(r'ml1m-6/item_idd_genre_list.pkl')   \n",
    "genre_item_vector = pd.read_pickle(r'ml1m-6/genre_item_vector.pkl')    \n",
    "genre_count = pd.read_pickle(r'ml1m-6/genre_count.pkl')      \n",
    "user_genre_count = pd.read_pickle(r'ml1m-6/user_genre_count.pkl') \n",
    "\n",
    "num_item = len(train_df['item_id'].unique())\n",
    "num_user = len(train_df['user_id'].unique())\n",
    "num_genre = len(key_genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4a9335ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Sci-Fi': 271,\n",
       " 'Horror': 330,\n",
       " 'Crime': 193,\n",
       " 'Romance': 447,\n",
       " \"Children's\": 248,\n",
       " 'Adventure': 276}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "364be573",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_genre_list = []\n",
    "for u in range(num_item):\n",
    "    gl = item_idd_genre_list[u]\n",
    "    tmp = []\n",
    "    for g in gl:\n",
    "        if g in key_genre:\n",
    "            tmp.append(g)\n",
    "    item_genre_list.append(tmp)\n",
    "\n",
    "item_genre = np.zeros((num_item, num_genre))\n",
    "for i in range(num_item):\n",
    "    gl = item_genre_list[i]\n",
    "    for k in range(num_genre):\n",
    "        if key_genre[k] in gl:\n",
    "            item_genre[i, k] = 1.0\n",
    "\n",
    "genre_count_mean_reciprocal = []\n",
    "\n",
    "##there are six key_genre --> in the training dataset, count the number of movies for each genre\n",
    "#genre_count = dictionary with number of movies for each keygrenre\n",
    "for k in key_genre:\n",
    "    genre_count_mean_reciprocal.append(1.0 / genre_count[k])\n",
    "genre_count_mean_reciprocal = (np.array(genre_count_mean_reciprocal)).reshape((num_genre, 1))\n",
    "genre_error_weight = np.dot(item_genre, genre_count_mean_reciprocal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2326714e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00369004],\n",
       "       [0.0030303 ],\n",
       "       [0.00518135],\n",
       "       [0.00362319],\n",
       "       [0.00403226],\n",
       "       [0.00223714]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_count_mean_reciprocal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "55f5af0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1481, 6])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_genre = torch.from_numpy(item_genre).type(torch.float)\n",
    "item_genre.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2000011e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([6036, 64]), torch.Size([1481, 64]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load the results of BPR\n",
    "model1 = (torch.load('output/bpr_manual'))\n",
    "list(model1.items())[0][1].size(),list(model1.items())[1][1].size()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0ed68cc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0092, -0.0653,  0.3428,  ...,  0.1458, -0.0469,  0.1185],\n",
       "        [ 0.0618, -0.2057,  0.3163,  ..., -0.2386,  0.2494,  0.1920],\n",
       "        [ 0.4285, -0.3056,  0.2651,  ..., -0.3803,  0.3952,  0.0155],\n",
       "        ...,\n",
       "        [-0.3824,  0.2999, -0.3718,  ...,  0.2618, -0.3942, -0.4001],\n",
       "        [-0.3730,  0.3332, -0.3430,  ...,  0.3450, -0.3255, -0.3645],\n",
       "        [-0.3742,  0.4088, -0.2902,  ...,  0.3808, -0.2644, -0.3951]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model1.items())[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0c24762f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6036, 1481])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rec = np.matmul(list(model1.items())[0][1], list(model1.items())[1][1].T)\n",
    "Rec.size()\n",
    "# Rec[1,:].size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6d8d492c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "####################################################################################################\n",
      "# System-level Recall:\n",
      "# \t\t\tRecall@1\tRecall@5\tRecall@10\tRecall@15\n",
      "# Sci-Fi\t\t0.00013\t\t0.00045\t\t0.00140\t\t0.00242\n",
      "# Horror\t\t0.00000\t\t0.00013\t\t0.00040\t\t0.00053\n",
      "# Crime\t\t0.00000\t\t0.00038\t\t0.00140\t\t0.00178\n",
      "# Adventure\t\t0.00628\t\t0.02959\t\t0.05562\t\t0.08120\n",
      "# Children's\t\t0.00374\t\t0.02011\t\t0.04465\t\t0.07114\n",
      "# Romance\t\t0.00354\t\t0.01697\t\t0.03142\t\t0.04730\n",
      "# relative std\t\t1.05464\t\t1.02820\t\t1.00215\t\t0.99836\n",
      "####################################################################################################\n",
      "# User-level Recall:\n",
      "# \t\t\tRecall@1\tRecall@5\tRecall@10\tRecall@15\n",
      "# Sci-Fi\t\t0.00038\t\t0.00080\t\t0.00295\t\t0.00451\n",
      "# Horror\t\t0.00000\t\t0.00008\t\t0.00053\t\t0.00072\n",
      "# Crime\t\t0.00000\t\t0.00040\t\t0.00145\t\t0.00164\n",
      "# Adventure\t\t0.00965\t\t0.04555\t\t0.08526\t\t0.12335\n",
      "# Children's\t\t0.00424\t\t0.02234\t\t0.04805\t\t0.07371\n",
      "# Romance\t\t0.00494\t\t0.02405\t\t0.04609\t\t0.07052\n",
      "# relative std\t\t1.09754\t\t1.08499\t\t1.03368\t\t1.02115\n",
      "####################################################################################################\n",
      "# System-level top ranking probability:\n",
      "# \t\t\t@1\t\t@5\t\t@10\t\t@15\n",
      "# Sci-Fi\t\t0.00153\t\t0.00834\t\t0.01819\t\t0.02769\n",
      "# Horror\t\t0.00031\t\t0.00139\t\t0.00250\t\t0.00343\n",
      "# Crime\t\t0.00091\t\t0.00449\t\t0.00847\t\t0.01177\n",
      "# Adventure\t\t0.00125\t\t0.00627\t\t0.01324\t\t0.02232\n",
      "# Children's\t\t0.00038\t\t0.00223\t\t0.00400\t\t0.00522\n",
      "# Romance\t\t0.00048\t\t0.00242\t\t0.00487\t\t0.00824\n",
      "# relative std\t\t0.56675\t\t0.58848\t\t0.65105\t\t0.68131\n",
      "####################################################################################################\n",
      "# User-level top ranking probability:\n",
      "# \t\t\t@1\t\t@5\t\t@10\t\t@15\n",
      "# Sci-Fi\t\t0.00154\t\t0.00842\t\t0.01839\t\t0.02807\n",
      "# Horror\t\t0.00032\t\t0.00143\t\t0.00258\t\t0.00356\n",
      "# Crime\t\t0.00091\t\t0.00450\t\t0.00851\t\t0.01183\n",
      "# Adventure\t\t0.00127\t\t0.00633\t\t0.01333\t\t0.02247\n",
      "# Children's\t\t0.00038\t\t0.00224\t\t0.00403\t\t0.00528\n",
      "# Romance\t\t0.00048\t\t0.00242\t\t0.00489\t\t0.00826\n",
      "# relative std\t\t0.56620\t\t0.58855\t\t0.65124\t\t0.68173\n",
      "####################################################################################################\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.56674985, 0.58847769, 0.65104521, 0.68130923]),\n",
       " array([1.05464461, 1.02820059, 1.00215035, 0.99836008]))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import utility\n",
    "utility.ranking_analysis(Rec, vali_df, train_df, key_genre,\n",
    "                                                      item_genre_list, user_genre_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "90785b71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1184, 297, 1184, 297)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(Rec.T, \n",
    "                                                    item_genre, \n",
    "                                                    test_size=0.2, # 20% test, 80% train\n",
    "                                                    random_state=181) # make the random split reproducible\n",
    "\n",
    "len(X_train), len(X_test), len(y_train), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "494ea526",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adv, linear-relu, linear-sigmoid last layer, numlayer = 4, 512,256,128,64 hidden units \n",
    "\n",
    "adversary = nn.Sequential(\n",
    "    nn.Linear(list(model1.items())[0][1].size()[0], 512),\n",
    "#     nn.ReLU(),\n",
    "    nn.Linear(512, 256),\n",
    "#     nn.ReLU(),\n",
    "    nn.Linear(256, 128),\n",
    "#     nn.ReLU(),\n",
    "    nn.Linear(128, 6),\n",
    "    nn.Softmax()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8bf3ee5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a loss function\n",
    "# loss_fn = nn.BCELoss() # BCELoss = no sigmoid built-in\n",
    "loss_fn = nn.BCEWithLogitsLoss() # BCEWithLogitsLoss = sigmoid built-in\n",
    "\n",
    "# Create an optimizer\n",
    "optimizer = torch.optim.Adam(params=adversary.parameters(), \n",
    "                            lr=0.000005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7d1f7bd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "896d5686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy (a classification metric)\n",
    "def accuracy_fn(y_true, y_pred):\n",
    "    correct = torch.eq(y_true, y_pred).sum().item() # torch.eq() calculates where two tensors are equal\n",
    "    acc = (correct / (y_true.size()[0]*y_true.size()[1])) * 100 \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "28bda2f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vuhoang181/anaconda3/lib/python3.9/site-packages/torch/nn/modules/container.py:204: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Loss: 0.75218, Accuracy: 72.40% | Test loss: 0.76171, Test acc: 70.20%\n",
      "Epoch: 10 | Loss: 0.75060, Accuracy: 72.71% | Test loss: 0.75816, Test acc: 70.88%\n",
      "Epoch: 20 | Loss: 0.74821, Accuracy: 73.18% | Test loss: 0.75442, Test acc: 71.66%\n",
      "Epoch: 30 | Loss: 0.74609, Accuracy: 73.61% | Test loss: 0.75217, Test acc: 72.11%\n",
      "Epoch: 40 | Loss: 0.74497, Accuracy: 73.83% | Test loss: 0.75102, Test acc: 72.33%\n",
      "Epoch: 50 | Loss: 0.74383, Accuracy: 74.06% | Test loss: 0.75158, Test acc: 72.22%\n",
      "Epoch: 60 | Loss: 0.74326, Accuracy: 74.17% | Test loss: 0.75047, Test acc: 72.45%\n",
      "Epoch: 70 | Loss: 0.74235, Accuracy: 74.34% | Test loss: 0.74879, Test acc: 72.78%\n",
      "Epoch: 80 | Loss: 0.74200, Accuracy: 74.42% | Test loss: 0.74988, Test acc: 72.56%\n",
      "Epoch: 90 | Loss: 0.74031, Accuracy: 74.76% | Test loss: 0.74874, Test acc: 72.78%\n",
      "Epoch: 100 | Loss: 0.73876, Accuracy: 75.07% | Test loss: 0.74587, Test acc: 73.34%\n",
      "Epoch: 110 | Loss: 0.73739, Accuracy: 75.32% | Test loss: 0.74541, Test acc: 73.46%\n",
      "Epoch: 120 | Loss: 0.73398, Accuracy: 76.03% | Test loss: 0.74204, Test acc: 74.13%\n",
      "Epoch: 130 | Loss: 0.73215, Accuracy: 76.39% | Test loss: 0.74235, Test acc: 74.02%\n",
      "Epoch: 140 | Loss: 0.73017, Accuracy: 76.79% | Test loss: 0.73644, Test acc: 75.25%\n",
      "Epoch: 150 | Loss: 0.72666, Accuracy: 77.49% | Test loss: 0.73641, Test acc: 75.25%\n",
      "Epoch: 160 | Loss: 0.72271, Accuracy: 78.28% | Test loss: 0.73476, Test acc: 75.59%\n",
      "Epoch: 170 | Loss: 0.71977, Accuracy: 78.87% | Test loss: 0.72969, Test acc: 76.60%\n",
      "Epoch: 180 | Loss: 0.71808, Accuracy: 79.21% | Test loss: 0.72860, Test acc: 76.82%\n",
      "Epoch: 190 | Loss: 0.71710, Accuracy: 79.41% | Test loss: 0.72800, Test acc: 76.94%\n",
      "Epoch: 200 | Loss: 0.71596, Accuracy: 79.63% | Test loss: 0.72529, Test acc: 77.50%\n",
      "Epoch: 210 | Loss: 0.71385, Accuracy: 80.05% | Test loss: 0.72187, Test acc: 78.17%\n",
      "Epoch: 220 | Loss: 0.70992, Accuracy: 80.84% | Test loss: 0.72116, Test acc: 78.28%\n",
      "Epoch: 230 | Loss: 0.70639, Accuracy: 81.55% | Test loss: 0.71520, Test acc: 79.52%\n",
      "Epoch: 240 | Loss: 0.70319, Accuracy: 82.19% | Test loss: 0.71345, Test acc: 79.85%\n",
      "Epoch: 250 | Loss: 0.70302, Accuracy: 82.22% | Test loss: 0.71336, Test acc: 79.85%\n",
      "Epoch: 260 | Loss: 0.70259, Accuracy: 82.31% | Test loss: 0.71348, Test acc: 79.85%\n",
      "Epoch: 270 | Loss: 0.70252, Accuracy: 82.33% | Test loss: 0.71569, Test acc: 79.41%\n",
      "Epoch: 280 | Loss: 0.70204, Accuracy: 82.42% | Test loss: 0.71549, Test acc: 79.41%\n",
      "Epoch: 290 | Loss: 0.70147, Accuracy: 82.53% | Test loss: 0.71687, Test acc: 79.18%\n",
      "Epoch: 300 | Loss: 0.70147, Accuracy: 82.53% | Test loss: 0.71717, Test acc: 79.07%\n",
      "Epoch: 310 | Loss: 0.70133, Accuracy: 82.56% | Test loss: 0.71633, Test acc: 79.29%\n",
      "Epoch: 320 | Loss: 0.70104, Accuracy: 82.62% | Test loss: 0.71681, Test acc: 79.18%\n",
      "Epoch: 330 | Loss: 0.70047, Accuracy: 82.76% | Test loss: 0.71457, Test acc: 79.63%\n",
      "Epoch: 340 | Loss: 0.69873, Accuracy: 83.09% | Test loss: 0.71510, Test acc: 79.52%\n",
      "Epoch: 350 | Loss: 0.69754, Accuracy: 83.32% | Test loss: 0.71335, Test acc: 79.85%\n",
      "Epoch: 360 | Loss: 0.69688, Accuracy: 83.46% | Test loss: 0.71457, Test acc: 79.63%\n",
      "Epoch: 370 | Loss: 0.69472, Accuracy: 83.88% | Test loss: 0.71177, Test acc: 80.19%\n",
      "Epoch: 380 | Loss: 0.69348, Accuracy: 84.14% | Test loss: 0.71280, Test acc: 79.97%\n",
      "Epoch: 390 | Loss: 0.69216, Accuracy: 84.39% | Test loss: 0.71174, Test acc: 80.19%\n",
      "Epoch: 400 | Loss: 0.68952, Accuracy: 84.92% | Test loss: 0.71174, Test acc: 80.19%\n",
      "Epoch: 410 | Loss: 0.68952, Accuracy: 84.92% | Test loss: 0.70781, Test acc: 80.98%\n",
      "Epoch: 420 | Loss: 0.68853, Accuracy: 85.12% | Test loss: 0.70807, Test acc: 80.98%\n",
      "Epoch: 430 | Loss: 0.68762, Accuracy: 85.29% | Test loss: 0.70727, Test acc: 81.09%\n",
      "Epoch: 440 | Loss: 0.68810, Accuracy: 85.21% | Test loss: 0.70780, Test acc: 80.98%\n",
      "Epoch: 450 | Loss: 0.68670, Accuracy: 85.49% | Test loss: 0.70671, Test acc: 81.20%\n",
      "Epoch: 460 | Loss: 0.68375, Accuracy: 86.08% | Test loss: 0.70496, Test acc: 81.54%\n",
      "Epoch: 470 | Loss: 0.68163, Accuracy: 86.50% | Test loss: 0.70165, Test acc: 82.21%\n",
      "Epoch: 480 | Loss: 0.68163, Accuracy: 86.50% | Test loss: 0.69920, Test acc: 82.66%\n",
      "Epoch: 490 | Loss: 0.68064, Accuracy: 86.70% | Test loss: 0.69937, Test acc: 82.66%\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(18)\n",
    "\n",
    "# Set the number of epochs\n",
    "epochs = 500\n",
    "\n",
    "# Put data to target device\n",
    "X_train, y_train = X_train.to(device), y_train.to(device)\n",
    "X_test, y_test = X_test.to(device), y_test.to(device)\n",
    "\n",
    "# Build training and evaluation loop\n",
    "for epoch in range(epochs):\n",
    "    ### Training\n",
    "    adversary.train()\n",
    "\n",
    "    # 1. Forward pass (model outputs raw logits)\n",
    "    y_logits = adversary(X_train).squeeze() # squeeze to remove extra `1` dimensions, this won't work unless model and data are on same device \n",
    "    y_pred = torch.round((y_logits)) # turn logits -> pred probs -> pred labls\n",
    "  \n",
    "    # 2. Calculate loss/accuracy\n",
    "    # loss = loss_fn(torch.sigmoid(y_logits), # Using nn.BCELoss you need torch.sigmoid()\n",
    "    #                y_train) \n",
    "    loss = loss_fn(y_logits, # Using nn.BCEWithLogitsLoss works with raw logits\n",
    "                   y_train) \n",
    "    acc = accuracy_fn(y_true=y_train, \n",
    "                      y_pred=y_pred) \n",
    "\n",
    "    # 3. Optimizer zero grad\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # 4. Loss backwards\n",
    "    loss.backward()\n",
    "\n",
    "    # 5. Optimizer step\n",
    "    optimizer.step()\n",
    "\n",
    "    ### Testing\n",
    "    adversary.eval()\n",
    "    with torch.inference_mode():\n",
    "        # 1. Forward pass\n",
    "        test_logits = adversary(X_test).squeeze() \n",
    "        test_pred = torch.round((test_logits))\n",
    "        # 2. Caculate loss/accuracy\n",
    "        test_loss = loss_fn(test_logits,\n",
    "                            y_test)\n",
    "        test_acc = accuracy_fn(y_true=y_test,\n",
    "                               y_pred=test_pred)\n",
    "\n",
    "    # Print out what's happening every 10 epochs\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch: {epoch} | Loss: {loss:.5f}, Accuracy: {acc:.2f}% | Test loss: {test_loss:.5f}, Test acc: {test_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97014932",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|| 23/23 [00:00<00:00, 46.62batch/s, acc=83, loss=0.69]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 validation: Cross-entropy=0.70, Accuracy=81.9%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|| 23/23 [00:00<00:00, 66.94batch/s, acc=82.3, loss=0.687]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 validation: Cross-entropy=0.70, Accuracy=81.9%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|| 23/23 [00:00<00:00, 70.19batch/s, acc=84, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 validation: Cross-entropy=0.69, Accuracy=82.4%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|| 23/23 [00:00<00:00, 62.75batch/s, acc=84, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 validation: Cross-entropy=0.69, Accuracy=82.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|| 23/23 [00:00<00:00, 59.55batch/s, acc=84.7, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 validation: Cross-entropy=0.69, Accuracy=82.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|| 23/23 [00:00<00:00, 49.47batch/s, acc=84, loss=0.686]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 validation: Cross-entropy=0.69, Accuracy=82.6%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|| 23/23 [00:00<00:00, 58.61batch/s, acc=84, loss=0.686]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 validation: Cross-entropy=0.69, Accuracy=82.9%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|| 23/23 [00:00<00:00, 59.63batch/s, acc=86, loss=0.68]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 validation: Cross-entropy=0.69, Accuracy=82.4%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|| 23/23 [00:00<00:00, 59.61batch/s, acc=86, loss=0.68]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 validation: Cross-entropy=0.69, Accuracy=82.7%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|| 23/23 [00:00<00:00, 51.23batch/s, acc=86, loss=0.68]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 validation: Cross-entropy=0.69, Accuracy=82.9%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|| 23/23 [00:00<00:00, 56.61batch/s, acc=86, loss=0.68]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 validation: Cross-entropy=0.69, Accuracy=82.9%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|| 23/23 [00:00<00:00, 54.33batch/s, acc=85.3, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 validation: Cross-entropy=0.69, Accuracy=82.9%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|| 23/23 [00:00<00:00, 67.02batch/s, acc=84.7, loss=0.684]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 validation: Cross-entropy=0.69, Accuracy=83.2%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|| 23/23 [00:00<00:00, 58.63batch/s, acc=86.3, loss=0.673]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 validation: Cross-entropy=0.69, Accuracy=83.1%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|| 23/23 [00:00<00:00, 49.54batch/s, acc=87.3, loss=0.673]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 validation: Cross-entropy=0.69, Accuracy=83.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|| 23/23 [00:00<00:00, 53.75batch/s, acc=87, loss=0.673]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 validation: Cross-entropy=0.69, Accuracy=83.1%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|| 23/23 [00:00<00:00, 54.58batch/s, acc=87, loss=0.673]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 validation: Cross-entropy=0.69, Accuracy=83.1%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|| 23/23 [00:00<00:00, 53.12batch/s, acc=87, loss=0.673]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 validation: Cross-entropy=0.69, Accuracy=83.1%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|| 23/23 [00:00<00:00, 54.96batch/s, acc=87, loss=0.673]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 validation: Cross-entropy=0.69, Accuracy=83.1%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|| 23/23 [00:00<00:00, 53.28batch/s, acc=87, loss=0.673]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 validation: Cross-entropy=0.69, Accuracy=83.1%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|| 23/23 [00:00<00:00, 54.19batch/s, acc=87, loss=0.673]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 validation: Cross-entropy=0.69, Accuracy=83.1%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|| 23/23 [00:00<00:00, 55.62batch/s, acc=88.3, loss=0.67]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 validation: Cross-entropy=0.69, Accuracy=82.8%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|| 23/23 [00:00<00:00, 61.52batch/s, acc=87.7, loss=0.673]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 validation: Cross-entropy=0.69, Accuracy=82.9%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|| 23/23 [00:00<00:00, 68.16batch/s, acc=87.7, loss=0.673]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 validation: Cross-entropy=0.69, Accuracy=82.9%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|| 23/23 [00:00<00:00, 65.36batch/s, acc=87, loss=0.673]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 validation: Cross-entropy=0.70, Accuracy=81.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|| 23/23 [00:00<00:00, 57.03batch/s, acc=86.7, loss=0.673]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 validation: Cross-entropy=0.70, Accuracy=81.4%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|| 23/23 [00:00<00:00, 62.36batch/s, acc=86.7, loss=0.673]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 validation: Cross-entropy=0.70, Accuracy=81.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|| 23/23 [00:00<00:00, 57.39batch/s, acc=86.7, loss=0.673]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 validation: Cross-entropy=0.70, Accuracy=81.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|| 23/23 [00:00<00:00, 55.72batch/s, acc=87, loss=0.673]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 validation: Cross-entropy=0.70, Accuracy=81.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|| 23/23 [00:00<00:00, 58.67batch/s, acc=87, loss=0.673]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 validation: Cross-entropy=0.70, Accuracy=81.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30: 100%|| 23/23 [00:00<00:00, 64.62batch/s, acc=85.7, loss=0.68]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 validation: Cross-entropy=0.70, Accuracy=81.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31: 100%|| 23/23 [00:00<00:00, 59.93batch/s, acc=86, loss=0.68]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 validation: Cross-entropy=0.70, Accuracy=81.6%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32: 100%|| 23/23 [00:00<00:00, 67.48batch/s, acc=85.3, loss=0.68]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 validation: Cross-entropy=0.70, Accuracy=81.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33: 100%|| 23/23 [00:00<00:00, 74.51batch/s, acc=85.7, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 validation: Cross-entropy=0.70, Accuracy=80.9%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|| 23/23 [00:00<00:00, 64.95batch/s, acc=85.7, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 validation: Cross-entropy=0.70, Accuracy=80.9%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35: 100%|| 23/23 [00:00<00:00, 62.31batch/s, acc=85.7, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 validation: Cross-entropy=0.70, Accuracy=80.8%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36: 100%|| 23/23 [00:00<00:00, 68.95batch/s, acc=85.3, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 validation: Cross-entropy=0.70, Accuracy=80.9%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37: 100%|| 23/23 [00:00<00:00, 60.60batch/s, acc=85.3, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37 validation: Cross-entropy=0.70, Accuracy=80.8%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38: 100%|| 23/23 [00:00<00:00, 58.92batch/s, acc=85.3, loss=0.68]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 validation: Cross-entropy=0.70, Accuracy=81.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39: 100%|| 23/23 [00:00<00:00, 62.90batch/s, acc=85.3, loss=0.68]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 validation: Cross-entropy=0.70, Accuracy=82.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40: 100%|| 23/23 [00:00<00:00, 63.09batch/s, acc=85.3, loss=0.68]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41: 100%|| 23/23 [00:00<00:00, 57.43batch/s, acc=85.3, loss=0.68]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 validation: Cross-entropy=0.70, Accuracy=82.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42: 100%|| 23/23 [00:00<00:00, 64.08batch/s, acc=85.3, loss=0.68]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42 validation: Cross-entropy=0.70, Accuracy=82.4%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43: 100%|| 23/23 [00:00<00:00, 75.49batch/s, acc=85, loss=0.68]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43 validation: Cross-entropy=0.70, Accuracy=82.2%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44: 100%|| 23/23 [00:00<00:00, 54.32batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44 validation: Cross-entropy=0.70, Accuracy=82.4%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45: 100%|| 23/23 [00:00<00:00, 52.33batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46: 100%|| 23/23 [00:00<00:00, 59.29batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47: 100%|| 23/23 [00:00<00:00, 59.08batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48: 100%|| 23/23 [00:00<00:00, 60.05batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|| 23/23 [00:00<00:00, 59.68batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50: 100%|| 23/23 [00:00<00:00, 58.16batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51: 100%|| 23/23 [00:00<00:00, 53.59batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52: 100%|| 23/23 [00:00<00:00, 57.75batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53: 100%|| 23/23 [00:00<00:00, 53.71batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54: 100%|| 23/23 [00:00<00:00, 55.73batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55: 100%|| 23/23 [00:00<00:00, 60.52batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56: 100%|| 23/23 [00:00<00:00, 60.08batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57: 100%|| 23/23 [00:00<00:00, 56.31batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 58: 100%|| 23/23 [00:00<00:00, 55.88batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59: 100%|| 23/23 [00:00<00:00, 55.38batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 60: 100%|| 23/23 [00:00<00:00, 54.58batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 61: 100%|| 23/23 [00:00<00:00, 54.89batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 62: 100%|| 23/23 [00:00<00:00, 60.04batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 63: 100%|| 23/23 [00:00<00:00, 54.68batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 64: 100%|| 23/23 [00:00<00:00, 57.96batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 65: 100%|| 23/23 [00:00<00:00, 57.65batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 66: 100%|| 23/23 [00:00<00:00, 54.91batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 67: 100%|| 23/23 [00:00<00:00, 55.73batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 68: 100%|| 23/23 [00:00<00:00, 56.44batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 69: 100%|| 23/23 [00:00<00:00, 55.50batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70: 100%|| 23/23 [00:00<00:00, 56.55batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 71: 100%|| 23/23 [00:00<00:00, 53.56batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 72: 100%|| 23/23 [00:00<00:00, 58.77batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 73: 100%|| 23/23 [00:00<00:00, 56.64batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 74: 100%|| 23/23 [00:00<00:00, 62.64batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 75: 100%|| 23/23 [00:00<00:00, 58.78batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 76: 100%|| 23/23 [00:00<00:00, 54.60batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 77: 100%|| 23/23 [00:00<00:00, 58.57batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 78: 100%|| 23/23 [00:00<00:00, 58.18batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 79: 100%|| 23/23 [00:00<00:00, 58.86batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 80: 100%|| 23/23 [00:00<00:00, 53.28batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 81: 100%|| 23/23 [00:00<00:00, 54.65batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 82: 100%|| 23/23 [00:00<00:00, 55.01batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 83: 100%|| 23/23 [00:00<00:00, 59.71batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 84: 100%|| 23/23 [00:00<00:00, 56.67batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 85: 100%|| 23/23 [00:00<00:00, 55.81batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 86: 100%|| 23/23 [00:00<00:00, 52.09batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 87: 100%|| 23/23 [00:00<00:00, 57.83batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 88: 100%|| 23/23 [00:00<00:00, 54.25batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 89: 100%|| 23/23 [00:00<00:00, 56.26batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 90: 100%|| 23/23 [00:00<00:00, 57.49batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 91: 100%|| 23/23 [00:00<00:00, 51.31batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 92: 100%|| 23/23 [00:00<00:00, 57.54batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 93: 100%|| 23/23 [00:00<00:00, 58.59batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 94: 100%|| 23/23 [00:00<00:00, 55.70batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 95: 100%|| 23/23 [00:00<00:00, 57.89batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 96: 100%|| 23/23 [00:00<00:00, 55.65batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 97: 100%|| 23/23 [00:00<00:00, 55.41batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 98: 100%|| 23/23 [00:00<00:00, 56.55batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|| 23/23 [00:00<00:00, 57.10batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 100: 100%|| 23/23 [00:00<00:00, 60.08batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 101: 100%|| 23/23 [00:00<00:00, 59.34batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 101 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 102: 100%|| 23/23 [00:00<00:00, 60.11batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 102 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 103: 100%|| 23/23 [00:00<00:00, 58.86batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 103 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 104: 100%|| 23/23 [00:00<00:00, 57.03batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 104 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 105: 100%|| 23/23 [00:00<00:00, 57.53batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 106: 100%|| 23/23 [00:00<00:00, 60.09batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 106 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 107: 100%|| 23/23 [00:00<00:00, 54.11batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 107 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 108: 100%|| 23/23 [00:00<00:00, 53.80batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 108 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 109: 100%|| 23/23 [00:00<00:00, 58.71batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 109 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 110: 100%|| 23/23 [00:00<00:00, 56.90batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 110 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 111: 100%|| 23/23 [00:00<00:00, 57.92batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 112: 100%|| 23/23 [00:00<00:00, 56.42batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 113: 100%|| 23/23 [00:00<00:00, 59.17batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 114: 100%|| 23/23 [00:00<00:00, 51.11batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 115: 100%|| 23/23 [00:00<00:00, 53.49batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 116: 100%|| 23/23 [00:00<00:00, 52.53batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 116 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 117: 100%|| 23/23 [00:00<00:00, 58.22batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 118: 100%|| 23/23 [00:00<00:00, 55.38batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 119: 100%|| 23/23 [00:00<00:00, 54.57batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 120: 100%|| 23/23 [00:00<00:00, 59.65batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 121: 100%|| 23/23 [00:00<00:00, 55.65batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 121 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 122: 100%|| 23/23 [00:00<00:00, 51.59batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 122 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 123: 100%|| 23/23 [00:00<00:00, 57.52batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 124: 100%|| 23/23 [00:00<00:00, 58.23batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 124 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 125: 100%|| 23/23 [00:00<00:00, 55.37batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 125 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 126: 100%|| 23/23 [00:00<00:00, 56.45batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 126 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 127: 100%|| 23/23 [00:00<00:00, 57.31batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 127 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 128: 100%|| 23/23 [00:00<00:00, 61.10batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 128 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 129: 100%|| 23/23 [00:00<00:00, 56.40batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 129 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 130: 100%|| 23/23 [00:00<00:00, 55.42batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 130 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 131: 100%|| 23/23 [00:00<00:00, 56.63batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 131 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 132: 100%|| 23/23 [00:00<00:00, 53.42batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 132 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 133: 100%|| 23/23 [00:00<00:00, 58.01batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 133 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 134: 100%|| 23/23 [00:00<00:00, 53.31batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 134 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 135: 100%|| 23/23 [00:00<00:00, 58.95batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 135 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 136: 100%|| 23/23 [00:00<00:00, 54.59batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 136 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 137: 100%|| 23/23 [00:00<00:00, 59.26batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 137 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 138: 100%|| 23/23 [00:00<00:00, 54.66batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 138 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 139: 100%|| 23/23 [00:00<00:00, 54.50batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 139 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 140: 100%|| 23/23 [00:00<00:00, 55.28batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 140 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 141: 100%|| 23/23 [00:00<00:00, 53.76batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 141 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 142: 100%|| 23/23 [00:00<00:00, 56.83batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 142 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 143: 100%|| 23/23 [00:00<00:00, 56.13batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 143 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 144: 100%|| 23/23 [00:00<00:00, 58.26batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 144 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 145: 100%|| 23/23 [00:00<00:00, 55.32batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 145 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 146: 100%|| 23/23 [00:00<00:00, 57.56batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 146 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 147: 100%|| 23/23 [00:00<00:00, 58.54batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 147 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 148: 100%|| 23/23 [00:00<00:00, 56.41batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 148 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|| 23/23 [00:00<00:00, 60.13batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 150: 100%|| 23/23 [00:00<00:00, 61.60batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 151: 100%|| 23/23 [00:00<00:00, 58.61batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 152: 100%|| 23/23 [00:00<00:00, 60.83batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 152 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 153: 100%|| 23/23 [00:00<00:00, 53.93batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 153 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 154: 100%|| 23/23 [00:00<00:00, 56.10batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 154 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 155: 100%|| 23/23 [00:00<00:00, 57.05batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 155 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 156: 100%|| 23/23 [00:00<00:00, 58.67batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 156 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 157: 100%|| 23/23 [00:00<00:00, 58.02batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 157 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 158: 100%|| 23/23 [00:00<00:00, 62.80batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 158 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 159: 100%|| 23/23 [00:00<00:00, 53.77batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 159 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 160: 100%|| 23/23 [00:00<00:00, 56.98batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 160 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 161: 100%|| 23/23 [00:00<00:00, 57.15batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 161 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 162: 100%|| 23/23 [00:00<00:00, 58.44batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 162 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 163: 100%|| 23/23 [00:00<00:00, 57.32batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 163 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 164: 100%|| 23/23 [00:00<00:00, 53.24batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 164 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 165: 100%|| 23/23 [00:00<00:00, 60.11batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 165 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 166: 100%|| 23/23 [00:00<00:00, 57.77batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 166 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 167: 100%|| 23/23 [00:00<00:00, 56.81batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 167 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 168: 100%|| 23/23 [00:00<00:00, 57.25batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 168 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 169: 100%|| 23/23 [00:00<00:00, 58.29batch/s, acc=85, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169 validation: Cross-entropy=0.70, Accuracy=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 170:   9%|       | 2/23 [00:00<00:00, 85.12batch/s, acc=91.3, loss=0.656]"
     ]
    }
   ],
   "source": [
    "# prepare model and training parameters\n",
    "n_epochs = 500\n",
    "batch_size = 50\n",
    "batches_per_epoch = len(X_train) // batch_size\n",
    " \n",
    "best_acc = - np.inf   # init to negative infinity\n",
    "best_weights = None\n",
    "train_loss_hist = []\n",
    "train_acc_hist = []\n",
    "test_loss_hist = []\n",
    "test_acc_hist = []\n",
    " \n",
    "# training loop\n",
    "for epoch in range(n_epochs):\n",
    "    epoch_loss = []\n",
    "    epoch_acc = []\n",
    "    # set model in training mode and run through each batch\n",
    "    adversary.train()\n",
    "    with tqdm.trange(batches_per_epoch, unit=\"batch\", mininterval=0) as bar:\n",
    "        bar.set_description(f\"Epoch {epoch}\")\n",
    "        for i in bar:\n",
    "            # take a batch\n",
    "            start = i * batch_size\n",
    "            X_batch = X_train[start:start+batch_size]\n",
    "            y_batch = y_train[start:start+batch_size]\n",
    "            # forward pass\n",
    "            y_pred = adversary(X_batch)\n",
    "            loss = loss_fn(y_pred, y_batch)\n",
    "            # backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            # update weights\n",
    "            optimizer.step()\n",
    "            # compute and store metrics\n",
    "            acc = accuracy_fn(y_true=y_batch, \n",
    "                      y_pred=y_pred)\n",
    "            epoch_loss.append(float(loss))\n",
    "            epoch_acc.append(float(acc))\n",
    "            bar.set_postfix(\n",
    "                loss=float(loss),\n",
    "                acc=float(acc)\n",
    "            )\n",
    "    # set model in evaluation mode and run through the test set\n",
    "    adversary.eval()\n",
    "    y_pred = adversary(X_test)\n",
    "    ce = loss_fn(y_pred, y_test)\n",
    "    acc = accuracy_fn(y_true=y_test, \n",
    "                      y_pred=y_pred)\n",
    "    ce = float(ce)\n",
    "    acc = float(acc)\n",
    "    train_loss_hist.append(np.mean(epoch_loss))\n",
    "    train_acc_hist.append(np.mean(epoch_acc))\n",
    "    test_loss_hist.append(ce)\n",
    "    test_acc_hist.append(acc)\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        best_weights = copy.deepcopy(adversary.state_dict())\n",
    "    print(f\"Epoch {epoch} validation: Cross-entropy={ce:.2f}, Accuracy={acc:.1f}%\")\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4a737340",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_weights' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4087/2717534567.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Restore best model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0madversary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Plot the loss and accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss_hist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'best_weights' is not defined"
     ]
    }
   ],
   "source": [
    " \n",
    "# Restore best model\n",
    "adversary.load_state_dict(best_weights)\n",
    " \n",
    "# Plot the loss and accuracy\n",
    "plt.plot(train_loss_hist, label=\"train\")\n",
    "plt.plot(test_loss_hist, label=\"test\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"cross entropy\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    " \n",
    "plt.plot(train_acc_hist, label=\"train\")\n",
    "plt.plot(test_acc_hist, label=\"test\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f758b8a9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'adversary' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4850/589744199.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdirname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'output/adversary'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madversary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'output/adversary'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'adversary' is not defined"
     ]
    }
   ],
   "source": [
    "dirname = os.path.dirname(os.path.abspath('output/adversary'))\n",
    "os.makedirs(dirname, exist_ok=True)\n",
    "torch.save(adversary, 'output/adversary')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c04f7d0",
   "metadata": {},
   "source": [
    "Take it as it is for now, now save the parameters trained for BPR and adversary\n",
    "\n",
    "Then train for an universal perturbation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "00f95259",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Load\n",
    "adversary = torch.load('output/adversary')\n",
    "# model(X_train)\n",
    "uniform_dist = torch.Tensor([0.5, 0.5])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "70bd1698",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is for indirectly optimize the pertubation\n",
    "\n",
    "criteria = torch.nn.MSELoss()\n",
    "transform_func = torch.nn.Linear(64, 64)#.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "319e9fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class fairness_reprogramming(nn.Module):\n",
    "    def __init__(self, user_emb, item_emb, Rec, reg):\n",
    "        super().__init__()\n",
    "        ##init the embedding for U and I\n",
    "        self.user_emb = user_emb\n",
    "        self.item_emb = item_emb  \n",
    "        self.reg = reg\n",
    "        self.perturb = nn.Parameter(torch.empty(1, 64))  # dim embedding\n",
    "        nn.init.xavier_normal_(self.perturb.data)\n",
    "\n",
    "        \n",
    "## forward cal\n",
    "    def forward(self, u, i, j, epoch):\n",
    "        \"\"\"Return loss value.\n",
    "        \n",
    "        Args:\n",
    "            u(torch.LongTensor): tensor stored user indexes. [batch_size,]\n",
    "            i(torch.LongTensor): tensor stored item indexes which is prefered by user. [batch_size,]\n",
    "            j(torch.LongTensor): tensor stored item indexes which is not prefered by user. [batch_size,]\n",
    "            epoch\n",
    "\n",
    "        Returns:\n",
    "            torch.FloatTensor\n",
    "        \"\"\"\n",
    "        ##u,i,j respectively, each is a vector of dim embedding (default = 64)\n",
    "#         u = self.user_emb[u, :]\n",
    "#         i = self.item_emb[i, :]\n",
    "#         j = self.item_emb[j, :]\n",
    "\n",
    "        ## Enables this Tensor to have their grad populated during backward(), convert any non-leaf tensor into a leaf tensor,\n",
    "        ##https://stackoverflow.com/questions/73698041/how-retain-grad-in-pytorch-works-i-found-its-position-changes-the-grad-result\n",
    "#         self.perturb.retain_grad()\n",
    "\n",
    "#       transform perturbation\n",
    "        perturb = transform_func(self.perturb)\n",
    "    \n",
    "        transformation_loss = criteria(self.perturb,perturb)\n",
    "        ## mf, dot product of user with pos/neg item\n",
    "        x_ui = torch.mul(self.user_emb[u, :] , self.item_emb[i, :] + perturb).sum(dim=1)\n",
    "        x_uj = torch.mul(self.user_emb[u, :] , self.item_emb[j, :] + perturb).sum(dim=1)\n",
    "        \n",
    "\n",
    "        #extract prediction for item and genres \n",
    "        \n",
    "        \n",
    "        ## Fix here, adversary needs to predict the recommendation for embedding + perturbation\n",
    "        \n",
    "        #torch.matmul(list(model1.items())[0][1], list(model1.items())[1][1][i,:].T)\n",
    "        #torch.matmul(self.user_emb,(self.item_emb[i, :] + perturb).T).T[i,:]\n",
    "#         i_feature = torch.matmul(self.user_emb,(self.item_emb[i, :] + perturb).T).T[i,:]\n",
    "#         j_feature = torch.matmul(self.user_emb,(self.item_emb[j, :] + perturb).T).T[j,:]\n",
    "        i_feature = Rec.T[i,:]\n",
    "        j_feature = Rec.T[j,:]\n",
    "        \n",
    "#         i_genre = item_genre[i,:]\n",
    "#         j_genre = item_genre[j,:]\n",
    "        \n",
    "        \n",
    "        i.prob = adversary(i_feature).mean(axis = 0)\n",
    "        j.prob = adversary(j_feature).mean(axis = 0)\n",
    "        \n",
    "        \n",
    "        \n",
    "#         1000 in a batch, group A & B\n",
    "#         A 300, B 700 (    [0.3, 0.7] vs [0.5 0.5]    )\n",
    "        \n",
    "#         Conditional prob P(g=Ga|i) for each item\n",
    "        \n",
    "        #similar to clip value, find diff between ui and uj\n",
    "        x_uij =torch.clamp(x_ui - x_uj,min=-80.0,max=1e8)\n",
    "        #logsigmoid this is equivalent to equation 1 in the paper (classic loss of bpr)\n",
    "        log_prob = F.logsigmoid(x_uij).sum()\n",
    "        # regularization = lambda * l2 norm of u, i, j\n",
    "        regularization = self.reg * (self.user_emb[u, :].norm(dim=1).pow(2).sum() + self.item_emb[i, :].norm(dim=1).pow(2).sum() + self.item_emb[j, :].norm(dim=1).pow(2).sum())\n",
    "\n",
    "        ## original bpr loss,\n",
    "        loss_bpr = -log_prob + regularization\n",
    "#         loss_bpr.backward(retain_graph=True)\n",
    "        \n",
    "        \n",
    "        loss_adv = F.kl_div(uniform_dist.log(), i.prob, None, None, 'sum') + F.kl_div(uniform_dist.log(), j.prob , None, None, 'sum')\n",
    "        total_loss = transformation_loss + loss_bpr + loss_adv\n",
    "\n",
    "        total_loss.backward()\n",
    "        \n",
    "        \n",
    "        return total_loss, perturb\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c95449f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4a9ed903",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('preprocessed/ml-1m-3.pickle', 'rb') as f:\n",
    "    dataset = pickle.load(f)\n",
    "    user_size, item_size = dataset['user_size'], dataset['item_size']\n",
    "    train_user_list, test_user_list = dataset['train_user_list'], dataset['test_user_list']\n",
    "    train_pair = dataset['train_pair']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3d1f537f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset, model, optimizer\n",
    "dataset = GetTriplePair(item_size, train_user_list, train_pair, True, 200)\n",
    "#list(model1.items())[0][1], list(model1.items())[1][1]\n",
    "# load batch of 512 item triplets\n",
    "loader = DataLoader(dataset, batch_size=512)\n",
    "model = fairness_reprogramming(list(model1.items())[0][1], list(model1.items())[1][1], Rec, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f82a9fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perturb tensor([[ 1.0600e-01,  6.5238e-02, -2.6381e-01, -1.4774e-02,  2.8193e-01,\n",
      "         -9.1815e-02, -8.1203e-02, -3.5143e-01, -1.3697e-01,  4.1094e-01,\n",
      "          1.7212e-01, -3.4257e-01, -1.9636e-01, -2.2342e-01, -9.2034e-02,\n",
      "          2.1856e-01, -3.3790e-02,  1.3517e-01, -4.1042e-02, -9.4797e-02,\n",
      "         -1.2732e-01,  7.4473e-02,  1.1121e-01, -2.7012e-01,  4.4458e-01,\n",
      "          7.1873e-02, -3.1197e-02, -2.9815e-01,  4.9906e-02,  1.3369e-01,\n",
      "         -2.4740e-04,  1.6069e-01, -2.2408e-01, -4.9899e-02, -1.4498e-01,\n",
      "          1.9026e-01,  1.9839e-01, -1.3061e-01, -8.1006e-02, -2.5560e-01,\n",
      "          1.9954e-01, -8.6621e-02, -3.0126e-02, -2.2062e-01, -9.8317e-02,\n",
      "         -1.9159e-01,  1.6894e-02, -3.2057e-01, -1.1384e-01,  1.1021e-01,\n",
      "          1.1109e-01,  1.3879e-01, -6.7672e-02, -1.5262e-01,  5.2401e-02,\n",
      "         -3.2221e-01,  5.7577e-02, -2.0666e-01,  8.4511e-02,  7.6068e-03,\n",
      "         -3.7681e-01,  7.1875e-03, -1.1640e-01,  2.1399e-03]]) None\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print (name, param.data, param.data.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "df76aaed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time 0:00:01\n",
      "BPR-MF Epoch [20/1000]\n",
      "loss: 135.0531\n",
      "HR@50: 0.4536, HR@100: 0.5974, NDCG@50: 0.1472, NDCG@100: 0.1472\n",
      "BPR-MF Epoch [40/1000]\n",
      "loss: 160.0160\n",
      "HR@50: 0.4536, HR@100: 0.5975, NDCG@50: 0.1472, NDCG@100: 0.1472\n",
      "BPR-MF Epoch [60/1000]\n",
      "loss: 171.9583\n",
      "HR@50: 0.4536, HR@100: 0.5976, NDCG@50: 0.1472, NDCG@100: 0.1472\n",
      "BPR-MF Epoch [80/1000]\n",
      "loss: 135.7449\n",
      "HR@50: 0.4537, HR@100: 0.5976, NDCG@50: 0.1472, NDCG@100: 0.1472\n",
      "BPR-MF Epoch [100/1000]\n",
      "loss: 149.3399\n",
      "HR@50: 0.4537, HR@100: 0.5976, NDCG@50: 0.1472, NDCG@100: 0.1472\n",
      "time 0:00:55\n",
      "BPR-MF Epoch [120/1000]\n",
      "loss: 202.9521\n",
      "HR@50: 0.4537, HR@100: 0.5976, NDCG@50: 0.1472, NDCG@100: 0.1472\n",
      "BPR-MF Epoch [140/1000]\n",
      "loss: 172.0774\n",
      "HR@50: 0.4537, HR@100: 0.5976, NDCG@50: 0.1472, NDCG@100: 0.1472\n",
      "BPR-MF Epoch [160/1000]\n",
      "loss: 180.4559\n",
      "HR@50: 0.4537, HR@100: 0.5976, NDCG@50: 0.1472, NDCG@100: 0.1472\n",
      "BPR-MF Epoch [180/1000]\n",
      "loss: 177.8299\n",
      "HR@50: 0.4537, HR@100: 0.5976, NDCG@50: 0.1472, NDCG@100: 0.1472\n",
      "BPR-MF Epoch [200/1000]\n",
      "loss: 140.0361\n",
      "HR@50: 0.4537, HR@100: 0.5975, NDCG@50: 0.1472, NDCG@100: 0.1472\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.000025)\n",
    "\n",
    "# Training\n",
    "start_time = time.time()\n",
    "eval_best_loss = float('inf')\n",
    "\n",
    "##zero_grad: zeroes the grad attribute of all the parameters passed to the optimizer upon construction\n",
    "optimizer.zero_grad()\n",
    "epoch = 0\n",
    "HR_history = []\n",
    "NDCG_history = []\n",
    "perturb_list = []\n",
    "# result_history = []\n",
    "#loader has batch size of 512. In each batch there are 3 tensors of u i j accordingly\n",
    "for u, i, j in loader:\n",
    "    if epoch in range(200):\n",
    "        loss,perturb = model(u, i, j, epoch)\n",
    "\n",
    "        ##  updates the value of those parameters according to the optimization strategy implemented by the specific optimizer.\n",
    "        optimizer.step()\n",
    "        HR_list, NDCG_list = evaluate_k(list(model1.items())[0][1] + perturb,\n",
    "                                        list(model1.items())[1][1] + perturb,\n",
    "                                        train_user_list,\n",
    "                                        test_user_list,\n",
    "                                        klist=[50, 100])\n",
    "        if epoch % 20 == (20- 1):\n",
    "            if epoch in range(1000):\n",
    "                print('BPR-MF Epoch [{}/{}]'.format(epoch + 1, 1000))\n",
    "            print('loss: %.4f' % loss)\n",
    "            print('HR@50: %.4f, HR@100: %.4f, NDCG@50: %.4f, NDCG@100: %.4f' % (\n",
    "                HR_list[0], HR_list[1], NDCG_list[0], NDCG_list[1]))\n",
    "        perturb_list.append(perturb)\n",
    "        HR_history.append(HR_list[1])\n",
    "        NDCG_history.append(NDCG_list[1])\n",
    "        if epoch % 100 == 0:\n",
    "            if loss < eval_best_loss:\n",
    "                eval_best_loss = loss\n",
    "                dirname = os.path.dirname(os.path.abspath('output/perturbation'))\n",
    "                os.makedirs(dirname, exist_ok=True)\n",
    "                torch.save(model.state_dict(), 'output/perturbation')\n",
    "                time_dif = get_time_dif(start_time)\n",
    "                print(\"time\", time_dif)\n",
    "        epoch += 1\n",
    "    else:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b31e3f",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/66572604/optimize-input-instead-of-network-in-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "614bc549",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load the results of BPR\n",
    "pertubation = (torch.load('output/perturbation'))\n",
    "list(pertubation.items())[0][1].size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "caa01e15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5562, 543])"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load the results of BPR\n",
    "model1 = (torch.load('output/bpr_manual'))\n",
    "list(model1.items())[0][1].size(),list(model1.items())[1][1].size()\n",
    "\n",
    "\n",
    "\n",
    "Rec = np.matmul(list(model1.items())[0][1]+list(pertubation.items())[0][1], (list(model1.items())[1][1]+list(pertubation.items())[0][1]).T)\n",
    "Rec.size()\n",
    "# Rec[1,:].size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "5d4e7ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vuhoang181/Documents/code_base/APR-PyTorch/utility.py:291: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  top15 = (np.array([top15_item_idx_no_train, u_pred[top15_item_idx_no_train]])).T\n",
      "/home/vuhoang181/Documents/code_base/APR-PyTorch/utility.py:291: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  top15 = (np.array([top15_item_idx_no_train, u_pred[top15_item_idx_no_train]])).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "####################################################################################################\n",
      "# System-level Recall:\n",
      "# \t\t\tRecall@1\tRecall@5\tRecall@10\tRecall@15\n",
      "# Sci-Fi\t\t0.00743\t\t0.04135\t\t0.08665\t\t0.13359\n",
      "# Horror\t\t0.00027\t\t0.00214\t\t0.00547\t\t0.00828\n",
      "# relative std\t\t0.93061\t\t0.90176\t\t0.88116\t\t0.88330\n",
      "####################################################################################################\n",
      "# User-level Recall:\n",
      "# \t\t\tRecall@1\tRecall@5\tRecall@10\tRecall@15\n",
      "# Sci-Fi\t\t0.00967\t\t0.05499\t\t0.11560\t\t0.17443\n",
      "# Horror\t\t0.00051\t\t0.00464\t\t0.01163\t\t0.01687\n",
      "# relative std\t\t0.90049\t\t0.84452\t\t0.81715\t\t0.82363\n",
      "####################################################################################################\n",
      "# System-level top ranking probability:\n",
      "# \t\t\t@1\t\t@5\t\t@10\t\t@15\n",
      "# Sci-Fi\t\t0.00370\t\t0.00764\t\t0.00764\t\t0.00764\n",
      "# Horror\t\t0.00035\t\t0.00041\t\t0.00041\t\t0.00041\n",
      "# relative std\t\t0.82604\t\t0.89932\t\t0.89932\t\t0.89932\n",
      "####################################################################################################\n",
      "# User-level top ranking probability:\n",
      "# \t\t\t@1\t\t@5\t\t@10\t\t@15\n",
      "# Sci-Fi\t\t0.00374\t\t0.00773\t\t0.00773\t\t0.00773\n",
      "# Horror\t\t0.00036\t\t0.00042\t\t0.00042\t\t0.00042\n",
      "# relative std\t\t0.82259\t\t0.89772\t\t0.89772\t\t0.89772\n",
      "####################################################################################################\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.82603744, 0.89931872, 0.89931872, 0.89931872]),\n",
       " array([0.93060609, 0.90175728, 0.88115807, 0.88330188]))"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import utility\n",
    "utility.ranking_analysis(Rec, vali_df, train_df, key_genre,\n",
    "                                                      item_genre_list, user_genre_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6adf9362",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vuhoang/Documents/code_base/APR-PyTorch/utility.py:291: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  top15 = (np.array([top15_item_idx_no_train, u_pred[top15_item_idx_no_train]])).T\n",
      "/Users/vuhoang/Documents/code_base/APR-PyTorch/utility.py:291: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  top15 = (np.array([top15_item_idx_no_train, u_pred[top15_item_idx_no_train]])).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "####################################################################################################\n",
      "# System-level Recall:\n",
      "# \t\t\tRecall@1\tRecall@5\tRecall@10\tRecall@15\n",
      "# Sci-Fi\t\t0.01387\t\t0.07008\t\t0.13872\t\t0.20853\n",
      "# Horror\t\t0.00013\t\t0.00027\t\t0.00067\t\t0.00160\n",
      "# relative std\t\t0.98093\t\t0.99241\t\t0.99042\t\t0.98475\n",
      "####################################################################################################\n",
      "# User-level Recall:\n",
      "# \t\t\tRecall@1\tRecall@5\tRecall@10\tRecall@15\n",
      "# Sci-Fi\t\t0.01711\t\t0.08543\t\t0.17070\t\t0.25925\n",
      "# Horror\t\t0.00019\t\t0.00038\t\t0.00099\t\t0.00234\n",
      "# relative std\t\t0.97804\t\t0.99115\t\t0.98849\t\t0.98214\n",
      "####################################################################################################\n",
      "# System-level top ranking probability:\n",
      "# \t\t\t@1\t\t@5\t\t@10\t\t@15\n",
      "# Sci-Fi\t\t0.00357\t\t0.00752\t\t0.00752\t\t0.00752\n",
      "# Horror\t\t0.00044\t\t0.00047\t\t0.00047\t\t0.00047\n",
      "# relative std\t\t0.78056\t\t0.88257\t\t0.88257\t\t0.88257\n",
      "####################################################################################################\n",
      "# User-level top ranking probability:\n",
      "# \t\t\t@1\t\t@5\t\t@10\t\t@15\n",
      "# Sci-Fi\t\t0.00361\t\t0.00761\t\t0.00761\t\t0.00761\n",
      "# Horror\t\t0.00045\t\t0.00048\t\t0.00048\t\t0.00048\n",
      "# relative std\t\t0.77751\t\t0.88108\t\t0.88108\t\t0.88108\n",
      "####################################################################################################\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.78055942, 0.88256852, 0.88256852, 0.88256852]),\n",
       " array([0.98093382, 0.99240851, 0.99042126, 0.98475139]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#before training\n",
    "import utility\n",
    "utility.ranking_analysis(Rec, vali_df, train_df, key_genre,\n",
    "                                                      item_genre_list, user_genre_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd769aa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.9876, 3.1480, 2.5682,  ..., 1.8456, 2.9970, 1.9240])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(list(model1.items())[0][1], list(model1.items())[1][1][43,:].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "76d6f44f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4087/1973552975.py:12: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  top15 = (np.array([top15_item_idx_no_train, u_pred[top15_item_idx_no_train]])).T\n",
      "/tmp/ipykernel_4087/1973552975.py:12: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  top15 = (np.array([top15_item_idx_no_train, u_pred[top15_item_idx_no_train]])).T\n"
     ]
    }
   ],
   "source": [
    "for u in range(num_user):\n",
    "        #for each user list all the items that he likes, mark that to -10000\n",
    "        like_item = (train_df.loc[train_df['user_id'] == u, 'item_id']).tolist()\n",
    "        Rec[u, like_item] = -100000.0\n",
    "\n",
    "for u in range(num_user):  # iterate each user\n",
    "    #extract item that user actually match during testing, extract the prediction\n",
    "    u_test = (vali_df.loc[vali_df['user_id'] == u, 'item_id']).tolist()\n",
    "    u_pred = Rec[u, :]\n",
    "    \n",
    "    top15_item_idx_no_train = np.argpartition(u_pred, -1 * 15)[-1 * 15:]\n",
    "    top15 = (np.array([top15_item_idx_no_train, u_pred[top15_item_idx_no_train]])).T\n",
    "    top15 = sorted(top15, key=itemgetter(1), reverse=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e2cb0058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([339,   6, 208, 319,  34,  10, 108,  33,  68,  13,  23,  66,   3,  56,\n",
       "          92]),\n",
       " tensor([5.1091, 5.2037, 5.2686, 5.4941, 5.3357, 5.3461, 5.3352, 5.3745, 5.5207,\n",
       "         5.5348, 5.7181, 5.6727, 5.5717, 5.6219, 5.7541])]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d829144d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 325, 52, 201, 465, 66, 68, 643, 10, 556, 246, 451]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "63c2aeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_recall(new_user_prediction, test, item_idd_genre_list, key_genre):\n",
    "\n",
    "    #initialize dictionary to store result\n",
    "    test_dict = dict()\n",
    "    count_1_dict = dict()\n",
    "    count_5_dict = dict()\n",
    "    count_10_dict = dict()\n",
    "    count_15_dict = dict()\n",
    "    recall_1_dict = dict()\n",
    "    recall_5_dict = dict()\n",
    "    recall_10_dict = dict()\n",
    "    recall_15_dict = dict()\n",
    "\n",
    "    #initialize dictionary to store result, for each key genre\n",
    "    for k in key_genre:\n",
    "        test_dict[k] = 0.0\n",
    "        count_1_dict[k] = 0.0\n",
    "        count_5_dict[k] = 0.0\n",
    "        count_10_dict[k] = 0.0\n",
    "        count_15_dict[k] = 0.0\n",
    "        recall_1_dict[k] = 0.0\n",
    "        recall_5_dict[k] = 0.0\n",
    "        recall_10_dict[k] = 0.0\n",
    "        recall_15_dict[k] = 0.0\n",
    "\n",
    "\n",
    "    #for each item in the test list, if the item has the key genre concerned --> count and append to the test_dict dictionary\n",
    "    #test dict will return the number of movie in each key genre for each test list (list of movies associated with an user in the test data)\n",
    "    for t in test:\n",
    "        gl = item_idd_genre_list[t]\n",
    "        for g in gl:\n",
    "            if g in key_genre:\n",
    "                test_dict[g] += 1.0\n",
    "\n",
    "    #for each item in top 15, if they are in the test set, and belong to one of the key genre specified,\n",
    "    #we append them to the dictionary that track no. of movie in key_genre that make it to topk\n",
    "    for i in range(top4):\n",
    "        item_id = int(new_user_prediction[1][i])\n",
    "        if item_id in test:\n",
    "            gl = item_idd_genre_list[item_id]\n",
    "            if i < 10:\n",
    "                for g in gl:\n",
    "                    if g in key_genre:\n",
    "                        count_10_dict[g] += 1.0\n",
    "                if i < 5:\n",
    "                    for g in gl:\n",
    "                        if g in key_genre:\n",
    "                            count_5_dict[g] += 1.0\n",
    "                    if i < 1:\n",
    "                        for g in gl:\n",
    "                            if g in key_genre:\n",
    "                                count_1_dict[g] += 1.0\n",
    "            for g in gl:\n",
    "                if g in key_genre:\n",
    "                    count_15_dict[g] += 1.0\n",
    "\n",
    "    # recall@k\n",
    "    for k in key_genre:\n",
    "        l = test_dict[k]\n",
    "        #check the number of key genre movie in the top k list, if a key genre does not appear, then set l = 1 and tmp = -1\n",
    "        if l == 0:\n",
    "            tmp = -1\n",
    "            l = 1\n",
    "        else:\n",
    "            tmp = 0\n",
    "        #recall of a genre = number of movie in topk belong to that genre over total number of movie belongs to that genre in test list\n",
    "        recall_1_dict[k] = count_1_dict[k] / l + tmp\n",
    "        recall_5_dict[k] = count_5_dict[k] / l + tmp\n",
    "        recall_10_dict[k] = count_10_dict[k] / l + tmp\n",
    "        recall_15_dict[k] = count_15_dict[k] / l + tmp\n",
    "\n",
    "    # return precision, recall, ndcg_tmp\n",
    "    return recall_1_dict, recall_5_dict, recall_10_dict, recall_15_dict, \\\n",
    "           count_1_dict, count_5_dict, count_10_dict, count_15_dict, test_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0173ef4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "top4 = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2cbb1c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4087/3143874929.py:77: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  top15 = (np.array([top15_item_idx_no_train, u_pred[top15_item_idx_no_train]])).T\n",
      "/tmp/ipykernel_4087/3143874929.py:77: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  top15 = (np.array([top15_item_idx_no_train, u_pred[top15_item_idx_no_train]])).T\n"
     ]
    }
   ],
   "source": [
    "Rec = copy.copy(Rec)\n",
    "\n",
    "count1_dict = dict()\n",
    "count5_dict = dict()\n",
    "count10_dict = dict()\n",
    "count15_dict = dict()\n",
    "test_count = dict()\n",
    "\n",
    "recall1_dict = dict()\n",
    "recall5_dict = dict()\n",
    "recall10_dict = dict()\n",
    "recall15_dict = dict()\n",
    "user_count_dict = dict()\n",
    "\n",
    "num_user = Rec.shape[0]\n",
    "num_item = Rec.shape[1]\n",
    "\n",
    "top1_dict = dict()\n",
    "top5_dict = dict()\n",
    "top10_dict = dict()\n",
    "top15_dict = dict()\n",
    "avg_top1_dict = dict()\n",
    "avg_top5_dict = dict()\n",
    "avg_top10_dict = dict()\n",
    "avg_top15_dict = dict()\n",
    "tmp_top1_dict = dict()\n",
    "tmp_top5_dict = dict()\n",
    "tmp_top10_dict = dict()\n",
    "tmp_top15_dict = dict()\n",
    "genre_rank_count = dict()\n",
    "rank_count = np.ones(num_item) * 1e-10\n",
    "\n",
    "genre_to_be_rank = dict()\n",
    "\n",
    "for k in key_genre:\n",
    "    genre_rank_count[k] = np.zeros(num_item)\n",
    "    top1_dict[k] = 0.0\n",
    "    top5_dict[k] = 0.0\n",
    "    top10_dict[k] = 0.0\n",
    "    top15_dict[k] = 0.0\n",
    "    avg_top1_dict[k] = 0.0\n",
    "    avg_top5_dict[k] = 0.0\n",
    "    avg_top10_dict[k] = 0.0\n",
    "    avg_top15_dict[k] = 0.0\n",
    "    tmp_top1_dict[k] = 0.0\n",
    "    tmp_top5_dict[k] = 0.0\n",
    "    tmp_top10_dict[k] = 0.0\n",
    "    tmp_top15_dict[k] = 0.0\n",
    "\n",
    "    recall1_dict[k] = 0.0\n",
    "    recall5_dict[k] = 0.0\n",
    "    recall10_dict[k] = 0.0\n",
    "    recall15_dict[k] = 0.0\n",
    "    user_count_dict[k] = 0.0\n",
    "\n",
    "    count1_dict[k] = 0.0\n",
    "    count5_dict[k] = 0.0\n",
    "    count10_dict[k] = 0.0\n",
    "    count15_dict[k] = 0.0\n",
    "\n",
    "    genre_to_be_rank[k] = 0.0\n",
    "    test_count[k] = 0.0\n",
    "\n",
    "for u in range(num_user):\n",
    "    #for each user list all the items that he likes, mark that to -10000\n",
    "    like_item = (train_df.loc[train_df['user_id'] == u, 'item_id']).tolist()\n",
    "    Rec[u, like_item] = -100000.0\n",
    "\n",
    "for u in range(num_user):  # iterate each user\n",
    "    #extract item that user actually match during testing, extract the prediction\n",
    "    u_test = (vali_df.loc[vali_df['user_id'] == u, 'item_id']).tolist()\n",
    "    u_pred = Rec[u, :]\n",
    "\n",
    "\n",
    "    #get top 15 items\n",
    "    top15_item_idx_no_train = np.argpartition(u_pred, -1 * top4)[-1 * top4:]\n",
    "    top15 = (np.array([top15_item_idx_no_train, u_pred[top15_item_idx_no_train]])).T\n",
    "    top15 = sorted(top15, key=itemgetter(1), reverse=True)\n",
    "\n",
    "    # calculate the recall for different genres\n",
    "    if not len(u_test) == 0:\n",
    "        recall_1_tmp_dict, recall_5_tmp_dict, recall_10_tmp_dict, recall_15_tmp_dict, \\\n",
    "        count_1_tmp_dict, count_5_tmp_dict, count_10_tmp_dict, count_15_tmp_dict, test_tmp_dict\\\n",
    "            = user_recall(top15, u_test, item_idd_genre_list, key_genre)\n",
    "        for k in key_genre:\n",
    "            count1_dict[k] += count_1_tmp_dict[k]\n",
    "            count5_dict[k] += count_5_tmp_dict[k]\n",
    "            count10_dict[k] += count_10_tmp_dict[k]\n",
    "            count15_dict[k] += count_15_tmp_dict[k]\n",
    "            test_count[k] += test_tmp_dict[k]\n",
    "            if recall_1_tmp_dict[k] == -1:\n",
    "                continue\n",
    "            recall1_dict[k] += recall_1_tmp_dict[k]\n",
    "            recall5_dict[k] += recall_5_tmp_dict[k]\n",
    "            recall10_dict[k] += recall_10_tmp_dict[k]\n",
    "            recall15_dict[k] += recall_15_tmp_dict[k]\n",
    "            user_count_dict[k] += 1.0\n",
    "\n",
    "    # calculate ranking probability\n",
    "    rank = 1\n",
    "    for r in top15[0]:#top 15 items sorted\n",
    "    # extract the genre of each topk movie\n",
    "        gl = item_idd_genre_list[int(r)]\n",
    "        for g in gl:\n",
    "            if g in key_genre:\n",
    "                #if the movie belongs to a key genre ==> add 1 to the dict\n",
    "                genre_rank_count[g][rank - 1] += 1.0 #size = no. of items\n",
    "                rank_count[rank - 1] += 1.0\n",
    "                if rank <= top4:\n",
    "                    tmp_top15_dict[g] += 1.0 #no of movie in top15 for each key genre\n",
    "                    if rank <= 10:\n",
    "                        tmp_top10_dict[g] += 1.0\n",
    "                        if rank <= 5:\n",
    "                            tmp_top5_dict[g] += 1.0\n",
    "                            if rank <= 1:\n",
    "                                tmp_top1_dict[g] += 1.0\n",
    "        rank += 1 #15 rank\n",
    "    for k in key_genre:\n",
    "        top1_dict[k] += tmp_top1_dict[k]\n",
    "        top5_dict[k] += tmp_top5_dict[k]\n",
    "        top10_dict[k] += tmp_top10_dict[k]\n",
    "        top15_dict[k] += tmp_top15_dict[k]\n",
    "        avg_top1_dict[k] += (1.0 * tmp_top1_dict[k] / user_genre_count[u][k]) #user_genre_count = no. of more in each key_genre that the user has not intereacted with in training\n",
    "        avg_top5_dict[k] += (1.0 * tmp_top5_dict[k] / user_genre_count[u][k]) #no. of uninteracted items that appears in topj kust if yser\n",
    "        avg_top10_dict[k] += (1.0 * tmp_top10_dict[k] / user_genre_count[u][k])\n",
    "        avg_top15_dict[k] += (1.0 * tmp_top15_dict[k] / user_genre_count[u][k])\n",
    "        tmp_top1_dict[k] = 0.0 #reset tmp dict\n",
    "        tmp_top5_dict[k] = 0.0\n",
    "        tmp_top10_dict[k] = 0.0\n",
    "        tmp_top15_dict[k] = 0.0\n",
    "\n",
    "        genre_to_be_rank[k] += user_genre_count[u][k]\n",
    "\n",
    "# compute the average recall for different genres, and print out the results\n",
    "for k in key_genre:\n",
    "    #count1_dict track no. of movie in key_genre that make it to topk (in topk list predicted)\n",
    "    count1_dict[k] /= test_count[k]\n",
    "    count5_dict[k] /= test_count[k]\n",
    "    count10_dict[k] /= test_count[k]\n",
    "    count15_dict[k] /= test_count[k]\n",
    "    recall1_dict[k] /= user_count_dict[k]\n",
    "    recall5_dict[k] /= user_count_dict[k]\n",
    "    recall10_dict[k] /= user_count_dict[k]\n",
    "    recall15_dict[k] /= user_count_dict[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "68239d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in key_genre:\n",
    "        avg_top1_dict[k] /= num_user\n",
    "        avg_top5_dict[k] /= num_user\n",
    "        avg_top10_dict[k] /= num_user\n",
    "        avg_top15_dict[k] /= num_user\n",
    "\n",
    "        top1_dict[k] /= genre_to_be_rank[k]\n",
    "        top5_dict[k] /= genre_to_be_rank[k]\n",
    "        top10_dict[k] /= genre_to_be_rank[k]\n",
    "        top15_dict[k] /= genre_to_be_rank[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "964ae85b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Sci-Fi': 0.0015290108833840709,\n",
       " 'Horror': 0.000313697487272808,\n",
       " 'Crime': 0.0009078746177370031,\n",
       " 'Adventure': 0.0012507045550838023,\n",
       " \"Children's\": 0.0003809895217509753,\n",
       " 'Romance': 0.0004752738124514801}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top1_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "395562a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Sci-Fi': 1525169.0,\n",
       " 'Horror': 1938173.0,\n",
       " 'Crime': 1109184.0,\n",
       " 'Adventure': 1571914.0,\n",
       " \"Children's\": 1446234.0,\n",
       " 'Romance': 2594294.0}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_to_be_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "32f7e0b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Sci-Fi': 0.0003821656050955414,\n",
       " 'Horror': 0.0,\n",
       " 'Crime': 0.0,\n",
       " 'Adventure': 0.009645802155752326,\n",
       " \"Children's\": 0.004243983279900104,\n",
       " 'Romance': 0.004936206740419322}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall1_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cdaab24c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Sci-Fi': 3925.0,\n",
       " 'Horror': 2651.0,\n",
       " 'Crime': 3177.0,\n",
       " 'Adventure': 3754.0,\n",
       " \"Children's\": 2645.0,\n",
       " 'Romance': 4009.0}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_count_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8449acd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relative_std(dictionary):\n",
    "    tmp = []\n",
    "    for key, value in sorted(dictionary.items(), key = lambda x: x[0]):\n",
    "        tmp.append(value)\n",
    "    rstd = np.std(tmp) / (np.mean(tmp) + 1e-10)\n",
    "    return rstd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a81544cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9758867429456374"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relative_std(count1_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "59f475ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6036"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e9d562",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
