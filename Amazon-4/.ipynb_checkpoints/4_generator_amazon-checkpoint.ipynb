{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read user, item and rating from the raw files\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# VideoGame_df = pd.read_csv('./ratings_Video_Games.csv', names=['user_id', 'item_id', 'rating', 'time'])\n",
    "# VideoGame_df['genre'] = 'VideoGame'\n",
    "\n",
    "# Toy_df = pd.read_csv('./ratings_Toys_and_Games.csv', names=['user_id', 'item_id', 'rating', 'time'])\n",
    "# Toy_df['genre'] = 'Toy'\n",
    "\n",
    "Tool_df = pd.read_csv('./ratings_Tools_and_Home_Improvement.csv', names=['user_id', 'item_id', 'rating', 'time'])\n",
    "Tool_df['genre'] = 'Tool'\n",
    "\n",
    "Pet_df = pd.read_csv('./ratings_Pet_Supplies.csv', names=['user_id', 'item_id', 'rating', 'time'])\n",
    "Pet_df['genre'] = 'Pet'\n",
    "\n",
    "Office_df = pd.read_csv('./ratings_Office_Products.csv', names=['user_id', 'item_id', 'rating', 'time'])\n",
    "Office_df['genre'] = 'Office'\n",
    "\n",
    "# Beauty_df = pd.read_csv('./ratings_Beauty.csv', names=['user_id', 'item_id', 'rating', 'time'])\n",
    "# Beauty_df['genre'] = 'Beauty'\n",
    "\n",
    "Grocery_df = pd.read_csv('./ratings_Grocery_and_Gourmet_Food.csv', names=['user_id', 'item_id', 'rating', 'time'])\n",
    "Grocery_df['genre'] = 'Grocery'\n",
    "\n",
    "rdf = pd.concat([Grocery_df, Tool_df, Office_df, Pet_df], sort=False)\n",
    "rdf.drop(columns=['time'], inplace=True)\n",
    "rdf.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item num = 987689\n",
      "user num = 3917128\n"
     ]
    }
   ],
   "source": [
    "rdf.reset_index(drop=True, inplace=True)\n",
    "item_list = rdf['item_id'].unique()\n",
    "user_list = rdf['user_id'].unique()\n",
    "print('item num = ' + str(len(item_list)))\n",
    "print('user num = ' + str(len(user_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ACJT8MUC0LRF0     266\n",
       "A3OXHLG6DIBRW8    237\n",
       "A1UQBFCERIP7VJ    228\n",
       "AAA0TUKS5VBSA     225\n",
       "A1ITRGMT80D5TK    223\n",
       "AEL6CQNQXONBX     222\n",
       "A22CW0ZHY3NJH8    219\n",
       "A2QDOJFFLFGF18    214\n",
       "ALNFHVS3SC4FV     203\n",
       "A1W415JP5WEAJK    198\n",
       "A3VI2VETB90ZG5    198\n",
       "A25C2M3QF9G7OQ    196\n",
       "A2YKWYC3WQJX5J    188\n",
       "A2OCDK0BOW6UCY    184\n",
       "A36MP37DITBU6F    180\n",
       "A3R5GTYQ50QVMD    176\n",
       "A3NHUQ33CFH3VM    176\n",
       "A1ZPY91VE3IDN1    171\n",
       "A1ODOGXEYECQQ8    170\n",
       "A2RX62V4E2BF5Z    167\n",
       "A1EVV74UQYVKRY    166\n",
       "A376OJHLE6SU9Q    166\n",
       "A11OTLEDSW8ZXD    163\n",
       "AY3D7DG5L5WCK     162\n",
       "A1F7YU6O5RU432    162\n",
       "AYB4ELCS5AM8P     162\n",
       "A2P739KOM4U5JB    162\n",
       "A100WO06OQR8BQ    156\n",
       "A2503LT8PZIHAD    155\n",
       "A2ZKQC0XCIIAEM    154\n",
       "                 ... \n",
       "A1A3VXAK3HR6U6     10\n",
       "A28Q0JA9H8WZOD     10\n",
       "A38P818ISZ8XSZ     10\n",
       "A1WPQGUYP0XI99     10\n",
       "A2JOPUWVV0XQJ3     10\n",
       "A3AE2IM2KQ9ROH     10\n",
       "AF2FTSRJB3I5S      10\n",
       "A1BDMSNJVHCS8W     10\n",
       "A3PUJHAZ61SJ0      10\n",
       "A1F3DFRPGVEUI8     10\n",
       "A25635SYB9SR4N     10\n",
       "AQAT7HWPDXACL      10\n",
       "A3RXI6DI5HCOBN     10\n",
       "A2VDPF7NH2CD53     10\n",
       "A3F2TL0UCFT0MK     10\n",
       "AAEA4STR27PN2      10\n",
       "A23W55M32D2AC      10\n",
       "A19RGDJPNZ7NZ      10\n",
       "A26K25KKMYY9TG     10\n",
       "A1VCAOFHSTNK6G     10\n",
       "AZ5YC4S5ETSK3      10\n",
       "A31ICLWQ9CSHRS     10\n",
       "ACMRDAKUXXN5D      10\n",
       "A149L4IP4RQ8S9     10\n",
       "A3GM64N13BILUP     10\n",
       "A1HOXKR7OKJ1X1     10\n",
       "AROEAJRHBJ9ZT      10\n",
       "A1SPFZ5BOIMIXR     10\n",
       "A2U1SJB87Y4BEN     10\n",
       "A13WSEOC2I6U5G     10\n",
       "Name: user_id, Length: 4776, dtype: int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# iteratively remove items and users with less than 10 reviews\n",
    "rdf['user_freq'] = rdf.groupby('user_id')['user_id'].transform('count')\n",
    "rdf.drop(rdf.index[rdf['user_freq'] <= 9], inplace=True)\n",
    "rdf.reset_index(drop=True, inplace=True)\n",
    "rdf['item_freq'] = rdf.groupby('item_id')['item_id'].transform('count')\n",
    "rdf.drop(rdf.index[rdf['item_freq'] <= 9], inplace=True)\n",
    "rdf.reset_index(drop=True, inplace=True)\n",
    "rdf['user_freq'] = rdf.groupby('user_id')['user_id'].transform('count')\n",
    "rdf['user_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item num = 4175\n",
      "user num = 4776\n"
     ]
    }
   ],
   "source": [
    "item_list = rdf['item_id'].unique()\n",
    "user_list = rdf['user_id'].unique()\n",
    "print('item num = ' + str(len(item_list)))\n",
    "print('user num = ' + str(len(user_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Toy', 1096), ('Office', 951), ('Grocery', 835), ('Tool', 660), ('Pet', 633)]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count the number for each genre and sort\n",
    "rdf.reset_index(drop=True, inplace=True)\n",
    "item_genre_dict = dict()\n",
    "for i in range(len(rdf)):\n",
    "    item = rdf.at[i, 'item_id']\n",
    "    genre = rdf.at[i, 'genre']\n",
    "    if item not in item_genre_dict:\n",
    "        item_genre_dict[item] = set([genre])\n",
    "    else:\n",
    "        if genre not in item_genre_dict[item]:\n",
    "            item_genre_dict[item].add(genre)\n",
    "\n",
    "import operator\n",
    "genre_count = dict()\n",
    "for l in item_genre_dict:\n",
    "    for g in item_genre_dict[l]:\n",
    "        if not g in genre_count:\n",
    "            genre_count[g] = 1\n",
    "        else:\n",
    "            genre_count[g] += 1\n",
    "\n",
    "genre_count_sorted = sorted(genre_count.items(), key=operator.itemgetter(1), reverse=True)\n",
    "genre_count_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_genre = ['Office', 'Grocery', 'Tool', 'Pet', 'Toy']\n",
    "\n",
    "# get the key_genre->item_list dict\n",
    "key_genre_item = dict()\n",
    "for k in key_genre:\n",
    "    key_genre_item[k] = list()\n",
    "for item in item_genre_dict:\n",
    "    for g in item_genre_dict[item]:\n",
    "        if g in key_genre:\n",
    "            key_genre_item[g].append(item)\n",
    "            \n",
    "# collect all the items with key genres\n",
    "key_item = list()\n",
    "for genre in key_genre_item:\n",
    "    key_item = key_item + key_genre_item[genre]\n",
    "key_item_set = set(key_item)\n",
    "\n",
    "# remove the non-key genre items in rdf\n",
    "item_set = set(item_list)\n",
    "nonkey_item_set = item_set - key_item_set\n",
    "for item in nonkey_item_set:\n",
    "    rdf.drop(rdf.index[rdf['item_id'] == item], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the user and item str id->int id dict\n",
    "i = 0\n",
    "user_id_dict = dict()\n",
    "for u in user_list:\n",
    "    if not u in user_id_dict:\n",
    "        user_id_dict[u] = i\n",
    "        i += 1\n",
    "j = 0\n",
    "item_id_dict = dict()\n",
    "for i in item_list:\n",
    "    if not i in item_id_dict:\n",
    "        item_id_dict[i] = j\n",
    "        j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item num = 4175\n",
      "user num = 4776\n"
     ]
    }
   ],
   "source": [
    "item_list = rdf['item_id'].unique()\n",
    "user_list = rdf['user_id'].unique()\n",
    "print('item num = ' + str(len(item_list)))\n",
    "print('user num = ' + str(len(user_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparsity: 0.00783678873409\n"
     ]
    }
   ],
   "source": [
    "print('sparsity: ' + str(len(rdf) * 1.0 / (len(user_list) * len(item_list))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get the df of train, vali, and test set\n",
    "rdf.reset_index(inplace=True, drop=True)\n",
    "train_df = rdf.copy()\n",
    "vali_df = rdf.copy()\n",
    "test_df = rdf.copy()\n",
    "\n",
    "train_ratio = 0.6\n",
    "vali_ratio = 0.2\n",
    "test_ratio = 0.2\n",
    "num_all = len(rdf)\n",
    "vali_idx = []\n",
    "test_idx = []\n",
    "\n",
    "test_vali_idx = []\n",
    "i = 0\n",
    "num_user = len(user_list)\n",
    "for u in user_list:\n",
    "    u_idx = train_df.index[train_df['user_id'] == u]\n",
    "    idx_len = len(u_idx)\n",
    "    test_len = int(idx_len * (test_ratio + vali_ratio))\n",
    "    if test_len == 0:\n",
    "        test_len = 1\n",
    "    tmp = np.random.choice(u_idx, size=test_len, replace=False)\n",
    "    test_vali_idx += tmp.tolist()\n",
    "    i += 1\n",
    "    if i % 5000 == 0:\n",
    "        print(str(i) + '/' + str(num_user))\n",
    "\n",
    "# tmp = (np.random.choice(range(num_all), size=(test_len+vali_len), replace=False)).tolist()\n",
    "test_len = int(len(test_vali_idx) * test_ratio / (test_ratio + vali_ratio))\n",
    "vali_len = int(len(test_vali_idx) - test_len)\n",
    "test_idx = (np.random.choice(test_vali_idx, size=test_len, replace=False)).tolist()\n",
    "vali_idx = (np.random.choice(test_vali_idx, size=vali_len, replace=False)).tolist()\n",
    "\n",
    "test_set = set(test_idx)\n",
    "vali_set = set(vali_idx)\n",
    "train_set = set(range(num_all)) - test_set - vali_set\n",
    "train_idx = list(train_set)\n",
    "train_df.drop((test_idx + vali_idx), axis=0, inplace=True)\n",
    "test_df.drop((train_idx + vali_idx), axis=0, inplace=True)\n",
    "vali_df.drop((train_idx + test_idx), axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf.drop(columns=['rating'], inplace=True)\n",
    "train_df.drop(columns=['rating'], inplace=True)\n",
    "test_df.drop(columns=['rating'], inplace=True)\n",
    "vali_df.drop(columns=['rating'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the matrix of train, vali and test set\n",
    "\n",
    "train_df.reset_index(drop=True, inplace=True)\n",
    "test_df.reset_index(drop=True, inplace=True)\n",
    "vali_df.reset_index(drop=True, inplace=True)\n",
    "rdf.reset_index(drop=True, inplace=True)\n",
    "train = np.zeros((len(user_list), len(item_list)))\n",
    "test = np.zeros((len(user_list), len(item_list)))\n",
    "vali = np.zeros((len(user_list), len(item_list)))\n",
    "for r in range(len(train_df)):\n",
    "    train[user_id_dict[train_df.at[r, 'user_id']], item_id_dict[train_df.at[r, 'item_id']]] = 1.0\n",
    "for r in range(len(test_df)):\n",
    "    test[user_id_dict[test_df.at[r, 'user_id']], item_id_dict[test_df.at[r, 'item_id']]] = 1.0\n",
    "for r in range(len(vali_df)):\n",
    "    vali[user_id_dict[vali_df.at[r, 'user_id']], item_id_dict[vali_df.at[r, 'item_id']]] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the user int id-> str id list, and the same for item \n",
    "item_list = item_id_dict.keys()\n",
    "item_idd_list = list()\n",
    "for i in range(len(item_list)):\n",
    "    item_idd_list.append('')\n",
    "for item in item_id_dict:\n",
    "    item_idd_list[item_id_dict[item]] = item\n",
    "\n",
    "user_list = user_id_dict.keys()\n",
    "user_idd_list = list()\n",
    "for i in range(len(user_list)):\n",
    "    user_idd_list.append('')\n",
    "for user in user_id_dict:\n",
    "    user_idd_list[user_id_dict[user]] = user\n",
    "    \n",
    "# get the item int id->genres list\n",
    "item_idd_genre_list = list()\n",
    "for i in range(len(item_idd_list)):\n",
    "    item_idd_genre_list.append(item_genre_dict[item_idd_list[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.drop('user_freq', axis=1, inplace=True)\n",
    "train_df.drop('item_freq', axis=1, inplace=True)\n",
    "vali_df.drop('user_freq', axis=1, inplace=True)\n",
    "vali_df.drop('item_freq', axis=1, inplace=True)\n",
    "test_df.drop('user_freq', axis=1, inplace=True)\n",
    "test_df.drop('item_freq', axis=1, inplace=True)\n",
    "rdf.drop('user_freq', axis=1, inplace=True)\n",
    "rdf.drop('item_freq', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get df for rdf, train, vali, test with int id for user and item\n",
    "import copy\n",
    "rating_df = copy.copy(rdf)\n",
    "for i in range(len(rdf)):\n",
    "    rating_df.at[i, 'user_id'] = user_id_dict[rating_df.at[i, 'user_id']]\n",
    "    rating_df.at[i, 'item_id'] = item_id_dict[rating_df.at[i, 'item_id']]\n",
    "\n",
    "training_df = copy.copy(train_df)\n",
    "for i in range(len(training_df)):\n",
    "    training_df.at[i, 'user_id'] = user_id_dict[training_df.at[i, 'user_id']]\n",
    "    training_df.at[i, 'item_id'] = item_id_dict[training_df.at[i, 'item_id']]\n",
    "\n",
    "valiing_df = copy.copy(vali_df)\n",
    "for i in range(len(valiing_df)):\n",
    "    valiing_df.at[i, 'user_id'] = user_id_dict[valiing_df.at[i, 'user_id']]\n",
    "    valiing_df.at[i, 'item_id'] = item_id_dict[valiing_df.at[i, 'item_id']]\n",
    "\n",
    "testing_df = copy.copy(test_df)\n",
    "for i in range(len(testing_df)):\n",
    "    testing_df.at[i, 'user_id'] = user_id_dict[testing_df.at[i, 'user_id']]\n",
    "    testing_df.at[i, 'item_id'] = item_id_dict[testing_df.at[i, 'item_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the rating list for each key genre, get the genre->ratings dict\n",
    "rdf.reset_index(drop=True, inplace=True)\n",
    "key_genre_rating = dict()\n",
    "for k in key_genre:\n",
    "    key_genre_rating[k] = 0.0\n",
    "for r in range(len(rdf)):\n",
    "    item = rdf.at[r, 'item_id']\n",
    "    gl = item_genre_dict[item]\n",
    "    for k in key_genre:\n",
    "        if k in gl:\n",
    "            key_genre_rating[k] += 1.0\n",
    "\n",
    "# get the item int id->genres list\n",
    "genre_item_vector = dict()\n",
    "for k in key_genre:\n",
    "    genre_item_vector[k] = np.zeros((1, len(item_list)))\n",
    "for i in range(len(item_idd_genre_list)):\n",
    "    genre_list = item_idd_genre_list[i]\n",
    "    for g in genre_list:\n",
    "        if g in key_genre:\n",
    "            genre_item_vector[g][0, i] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"item_genre_dict.pkl\", \"wb\") as f:\n",
    "    pickle.dump(item_genre_dict, f, pickle.HIGHEST_PROTOCOL)\n",
    "with open(\"genre_item_vector.pkl\", \"wb\") as f:\n",
    "    pickle.dump(genre_item_vector, f, pickle.HIGHEST_PROTOCOL)\n",
    "with open(\"key_genre.pkl\", \"wb\") as f:\n",
    "    pickle.dump(key_genre, f, pickle.HIGHEST_PROTOCOL)\n",
    "with open(\"user_id_dict.pkl\", \"wb\") as f:\n",
    "    pickle.dump(user_id_dict, f, pickle.HIGHEST_PROTOCOL)\n",
    "with open(\"item_id_dict.pkl\", \"wb\") as f:\n",
    "    pickle.dump(item_id_dict, f, pickle.HIGHEST_PROTOCOL)\n",
    "with open(\"rdf.pkl\", \"wb\") as f:\n",
    "    pickle.dump(rdf, f, pickle.HIGHEST_PROTOCOL)\n",
    "with open(\"rating_df.pkl\", \"wb\") as f:\n",
    "    pickle.dump(rating_df, f, pickle.HIGHEST_PROTOCOL)\n",
    "with open(\"training_df.pkl\", \"wb\") as f:\n",
    "    pickle.dump(training_df, f, pickle.HIGHEST_PROTOCOL)\n",
    "with open(\"valiing_df.pkl\", \"wb\") as f:\n",
    "    pickle.dump(valiing_df, f, pickle.HIGHEST_PROTOCOL)\n",
    "with open(\"testing_df.pkl\", \"wb\") as f:\n",
    "    pickle.dump(testing_df, f, pickle.HIGHEST_PROTOCOL)\n",
    "with open(\"item_idd_genre_list.pkl\", \"wb\") as f:\n",
    "    pickle.dump(item_idd_genre_list, f, pickle.HIGHEST_PROTOCOL)\n",
    "with open(\"item_idd_list.pkl\", \"wb\") as f:\n",
    "    pickle.dump(item_idd_list, f, pickle.HIGHEST_PROTOCOL)\n",
    "with open(\"user_idd_list.pkl\", \"wb\") as f:\n",
    "    pickle.dump(user_idd_list, f, pickle.HIGHEST_PROTOCOL)\n",
    "with open(\"key_genre_rating.pkl\", \"wb\") as f:\n",
    "    pickle.dump(key_genre_rating, f, pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open(\"train.mat\", \"wb\") as f:\n",
    "    np.save(f, train)\n",
    "with open(\"test.mat\", \"wb\") as f:\n",
    "    np.save(f, test)\n",
    "with open(\"vali.mat\", \"wb\") as f:\n",
    "    np.save(f, vali)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the number for each genre and sort\n",
    "import pickle\n",
    "from operator import itemgetter\n",
    "# item_list = pickle.load(open('./rdf.pkl'))['item_id'].unique()\n",
    "# item_genre_dict = pickle.load(open('./item_genre_dict.pkl'))\n",
    "# key_genre = pickle.load(open('./key_genre.pkl'))\n",
    "\n",
    "genre_count = dict()\n",
    "for i in item_list:\n",
    "    gl = item_genre_dict[i]\n",
    "    for g in gl:\n",
    "        if g in key_genre:\n",
    "            if not g in genre_count:\n",
    "                genre_count[g] = 1\n",
    "            else:\n",
    "                genre_count[g] += 1\n",
    "\n",
    "with open(\"genre_count.pkl\", \"wb\") as f:\n",
    "    pickle.dump(genre_count, f, pickle.HIGHEST_PROTOCOL)\n",
    "                \n",
    "genre_count_sorted = sorted(genre_count.items(), key=itemgetter(1), reverse=True)\n",
    "genre_count_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import copy as copy\n",
    "\n",
    "item_idd_genre_list = np.array(item_idd_genre_list)\n",
    "\n",
    "\n",
    "mask = 1.0 * (train > 0)\n",
    "user_genre_count = list()\n",
    "for u in range(train.shape[0]):\n",
    "    temp_genre_count = copy.copy(genre_count)\n",
    "    mask_u = mask[u, :]\n",
    "    gll = item_idd_genre_list[mask_u == 1.0]\n",
    "    for gl in gll:\n",
    "        for g in gl:\n",
    "            if g in key_genre:\n",
    "                temp_genre_count[g] -= 1\n",
    "    user_genre_count.append(temp_genre_count)\n",
    "with open(\"user_genre_count.pkl\", \"wb\") as f:\n",
    "    pickle.dump(user_genre_count, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_avg_like = dict()\n",
    "for k in key_genre:\n",
    "    genre_avg_like[k] = key_genre_rating[k] * 1.0 / genre_count[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_avg_like_sorted = sorted(genre_avg_like.items(), key=itemgetter(1), reverse=True)\n",
    "genre_avg_like_sorted"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
