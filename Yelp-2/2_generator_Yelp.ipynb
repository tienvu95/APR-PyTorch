{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_genre_dict = pd.read_pickle('./item_genre_dict.pkl')\n",
    "rdf = pd.read_pickle('./rdf.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>r</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaZVUOzqk5b-l0mlki-9Og</td>\n",
       "      <td>tL2pS5UOmN6aAOi3Z-qFGg</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FtaTjyMUIY457tPJahjg1A</td>\n",
       "      <td>tL2pS5UOmN6aAOi3Z-qFGg</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ZibmYdOPKLlqDM9oR6xzOA</td>\n",
       "      <td>tL2pS5UOmN6aAOi3Z-qFGg</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trbt0Ex85yvwT8DHoEFCvg</td>\n",
       "      <td>tL2pS5UOmN6aAOi3Z-qFGg</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>xoGPeHR2RPnJW470-aYBUQ</td>\n",
       "      <td>tL2pS5UOmN6aAOi3Z-qFGg</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  item_id                 user_id     r\n",
       "0  NaZVUOzqk5b-l0mlki-9Og  tL2pS5UOmN6aAOi3Z-qFGg  True\n",
       "1  FtaTjyMUIY457tPJahjg1A  tL2pS5UOmN6aAOi3Z-qFGg  True\n",
       "2  ZibmYdOPKLlqDM9oR6xzOA  tL2pS5UOmN6aAOi3Z-qFGg  True\n",
       "3  Trbt0Ex85yvwT8DHoEFCvg  tL2pS5UOmN6aAOi3Z-qFGg  True\n",
       "4  xoGPeHR2RPnJW470-aYBUQ  tL2pS5UOmN6aAOi3Z-qFGg  True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item num = 2834\n",
      "user num = 6310\n"
     ]
    }
   ],
   "source": [
    "item_list = rdf['item_id'].unique()\n",
    "user_list = rdf['user_id'].unique()\n",
    "print('item num = ' + str(len(item_list)))\n",
    "print('user num = ' + str(len(user_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Restaurants', 31025),\n",
       " ('Food', 5598),\n",
       " ('Nightlife', 5111),\n",
       " ('Bars', 4958),\n",
       " ('American (Traditional)', 4340),\n",
       " ('Sandwiches', 3574),\n",
       " ('Pizza', 3131),\n",
       " ('Breakfast & Brunch', 3127),\n",
       " ('American (New)', 3022),\n",
       " ('Fast Food', 2992),\n",
       " ('Mexican', 2854),\n",
       " ('Italian', 2761),\n",
       " ('Burgers', 2732),\n",
       " ('Chinese', 2467),\n",
       " ('Japanese', 1703),\n",
       " ('Seafood', 1606),\n",
       " ('Salad', 1470),\n",
       " ('Cafes', 1447),\n",
       " ('Sushi Bars', 1430),\n",
       " ('Asian Fusion', 1217),\n",
       " ('Chicken Wings', 1189),\n",
       " ('Coffee & Tea', 1173),\n",
       " ('Event Planning & Services', 1093),\n",
       " ('Sports Bars', 1093),\n",
       " ('Steakhouses', 1072),\n",
       " ('Mediterranean', 1007),\n",
       " ('Barbeque', 995),\n",
       " ('Delis', 940),\n",
       " ('Canadian (New)', 904),\n",
       " ('Pubs', 891),\n",
       " ('Diners', 883),\n",
       " ('Thai', 881),\n",
       " ('Caterers', 807),\n",
       " ('Desserts', 786),\n",
       " ('Indian', 779),\n",
       " ('Specialty Food', 756),\n",
       " ('Vegetarian', 730),\n",
       " ('Bakeries', 673),\n",
       " ('Wine Bars', 644),\n",
       " ('Vietnamese', 617),\n",
       " ('Middle Eastern', 600),\n",
       " ('Greek', 590),\n",
       " ('Cocktail Bars', 574),\n",
       " ('Buffets', 570),\n",
       " ('French', 561),\n",
       " ('Beer', 554),\n",
       " ('Wine & Spirits', 554),\n",
       " ('Soup', 518),\n",
       " ('Korean', 515),\n",
       " ('Gluten-Free', 494),\n",
       " ('Vegan', 482),\n",
       " ('Tex-Mex', 458),\n",
       " ('Lounges', 435),\n",
       " ('Comfort Food', 429),\n",
       " ('Arts & Entertainment', 409),\n",
       " ('Juice Bars & Smoothies', 384),\n",
       " ('Gastropubs', 376),\n",
       " ('Hot Dogs', 360),\n",
       " ('Ice Cream & Frozen Yogurt', 335),\n",
       " ('Ethnic Food', 334),\n",
       " ('Latin American', 332),\n",
       " ('Southern', 313),\n",
       " ('Tapas/Small Plates', 294),\n",
       " ('Food Delivery Services', 278),\n",
       " ('Caribbean', 272),\n",
       " ('Noodles', 262),\n",
       " ('Halal', 246),\n",
       " ('Bagels', 245),\n",
       " ('Venues & Event Spaces', 219),\n",
       " ('Tapas Bars', 218),\n",
       " ('Hawaiian', 213),\n",
       " ('Music Venues', 201),\n",
       " ('Pakistani', 199),\n",
       " ('Dim Sum', 192),\n",
       " ('British', 188),\n",
       " ('Food Trucks', 181),\n",
       " ('Grocery', 180),\n",
       " ('Cajun/Creole', 169),\n",
       " ('Beer Bar', 165),\n",
       " ('Breweries', 162),\n",
       " ('Fish & Chips', 162),\n",
       " ('Modern European', 147),\n",
       " ('German', 147),\n",
       " ('Ramen', 146),\n",
       " ('Chicken Shop', 144),\n",
       " ('Soul Food', 144),\n",
       " ('Creperies', 138),\n",
       " ('Irish', 136),\n",
       " ('Cheesesteaks', 132),\n",
       " ('Dive Bars', 130),\n",
       " ('Spanish', 127),\n",
       " ('Taiwanese', 125),\n",
       " ('Portuguese', 121),\n",
       " ('Imported Food', 119),\n",
       " ('Filipino', 110),\n",
       " ('Food Stands', 108),\n",
       " ('Tacos', 104),\n",
       " ('Hotels & Travel', 102),\n",
       " ('Brasseries', 99),\n",
       " ('Karaoke', 99),\n",
       " ('Shopping', 98),\n",
       " ('Persian/Iranian', 97),\n",
       " ('Street Vendors', 95),\n",
       " ('Turkish', 92),\n",
       " ('Lebanese', 89),\n",
       " ('Tea Rooms', 85),\n",
       " ('Dance Clubs', 82),\n",
       " ('Local Flavor', 80),\n",
       " ('Poke', 79),\n",
       " ('Bubble Tea', 77),\n",
       " ('Poutineries', 74),\n",
       " ('Active Life', 72),\n",
       " ('African', 71),\n",
       " ('Falafel', 67),\n",
       " ('Szechuan', 64),\n",
       " ('Hot Pot', 63),\n",
       " ('Wraps', 61),\n",
       " ('Waffles', 61),\n",
       " ('Bistros', 61),\n",
       " ('Cantonese', 58),\n",
       " ('Party & Event Planning', 58),\n",
       " ('Peruvian', 58),\n",
       " ('Brazilian', 55),\n",
       " ('Donuts', 55),\n",
       " ('Health Markets', 53),\n",
       " ('Afghan', 52),\n",
       " ('Food Court', 51),\n",
       " ('Hotels', 51),\n",
       " ('Meat Shops', 50),\n",
       " ('Malaysian', 50),\n",
       " ('Casinos', 49),\n",
       " ('Cuban', 49),\n",
       " ('Ethiopian', 49),\n",
       " ('Polish', 48),\n",
       " ('Irish Pub', 47),\n",
       " ('Live/Raw Food', 45),\n",
       " ('Hookah Bars', 45),\n",
       " ('Pan Asian', 43),\n",
       " ('Jazz & Blues', 42),\n",
       " ('Arcades', 41),\n",
       " ('Kosher', 40),\n",
       " ('Himalayan/Nepalese', 39),\n",
       " ('Mongolian', 38),\n",
       " ('Bed & Breakfast', 37),\n",
       " ('Seafood Markets', 36),\n",
       " ('Scottish', 36),\n",
       " ('Internet Cafes', 36),\n",
       " ('Do-It-Yourself Food', 36),\n",
       " ('Salvadoran', 35),\n",
       " ('International', 35),\n",
       " ('Beer Gardens', 35),\n",
       " ('Fondue', 34),\n",
       " ('Pasta Shops', 34),\n",
       " ('Belgian', 34),\n",
       " ('Swabian', 33),\n",
       " ('Convenience Stores', 33),\n",
       " ('Pool Halls', 32),\n",
       " ('Smokehouse', 31),\n",
       " ('Moroccan', 31),\n",
       " ('Butcher', 30),\n",
       " ('Beer Garden', 28),\n",
       " ('Colombian', 28),\n",
       " ('Arabian', 28),\n",
       " ('Delicatessen', 27),\n",
       " ('Gelato', 27),\n",
       " ('Organic Stores', 27),\n",
       " ('Cheese Shops', 25),\n",
       " ('Russian', 24),\n",
       " ('New Mexican Cuisine', 24),\n",
       " ('Patisserie/Cake Shop', 24),\n",
       " ('Chocolatiers & Shops', 23),\n",
       " ('Shaved Ice', 23),\n",
       " ('Wineries', 23),\n",
       " ('Whiskey Bars', 22),\n",
       " ('Fruits & Veggies', 22),\n",
       " ('Acai Bowls', 21),\n",
       " ('Cambodian', 21),\n",
       " ('Kebab', 21),\n",
       " ('Local Services', 21),\n",
       " ('Basque', 20),\n",
       " ('Teppanyaki', 19),\n",
       " ('Golf', 19),\n",
       " ('Argentine', 19),\n",
       " ('Bowling', 19),\n",
       " ('Coffee Roasteries', 18),\n",
       " ('Hungarian', 18),\n",
       " ('Venezuelan', 17),\n",
       " ('Singaporean', 17),\n",
       " ('Farmers Market', 15),\n",
       " ('Hakka', 15),\n",
       " ('Puerto Rican', 15),\n",
       " ('Cupcakes', 14),\n",
       " ('Indonesian', 13),\n",
       " ('International Grocery', 13),\n",
       " ('Sri Lankan', 12),\n",
       " ('Performing Arts', 12),\n",
       " ('Health & Medical', 12),\n",
       " ('Wigs', 12),\n",
       " ('Education', 12),\n",
       " ('Automotive', 12),\n",
       " ('Donairs', 12),\n",
       " ('Ukrainian', 12),\n",
       " ('Laotian', 11),\n",
       " ('Gay Bars', 11),\n",
       " ('Custom Cakes', 11),\n",
       " ('Beauty & Spas', 11),\n",
       " ('Home Services', 11),\n",
       " ('Flowers & Gifts', 11),\n",
       " ('Scandinavian', 11),\n",
       " ('South African', 10),\n",
       " ('Pretzels', 10),\n",
       " ('Izakaya', 10),\n",
       " ('Wedding Planning', 10),\n",
       " ('Festivals', 9),\n",
       " ('Eatertainment', 9),\n",
       " ('Art Galleries', 9),\n",
       " ('Books', 9),\n",
       " ('Mags', 9),\n",
       " ('Music & Video', 9),\n",
       " ('Cafeteria', 9),\n",
       " ('Country Dance Halls', 8),\n",
       " ('Burmese', 8),\n",
       " ('Egyptian', 8),\n",
       " ('Speakeasies', 8),\n",
       " ('Gas Stations', 8),\n",
       " ('Fashion', 8),\n",
       " ('Home & Garden', 8),\n",
       " ('Social Clubs', 8),\n",
       " ('Shanghainese', 8),\n",
       " ('Bangladeshi', 8),\n",
       " ('Cinema', 7),\n",
       " ('Resorts', 7),\n",
       " ('Macarons', 7),\n",
       " ('Dinner Theater', 7),\n",
       " ('Brewpubs', 7),\n",
       " ('Dominican', 7),\n",
       " ('Tobacco Shops', 7),\n",
       " ('Piano Bars', 7),\n",
       " ('Specialty Schools', 7),\n",
       " ('Cooking Schools', 7),\n",
       " ('Bavarian', 7),\n",
       " ('Austrian', 6),\n",
       " ('Personal Chefs', 6),\n",
       " ('Beverage Store', 6),\n",
       " ('Bookstores', 6),\n",
       " ('Kids Activities', 6),\n",
       " ('Armenian', 6),\n",
       " ('Empanadas', 6),\n",
       " ('Real Estate', 5),\n",
       " ('Arts & Crafts', 5),\n",
       " ('Hobby Shops', 5),\n",
       " ('Gift Shops', 5),\n",
       " ('Swimming Pools', 5),\n",
       " ('Hair Salons', 5),\n",
       " ('Tiki Bars', 5),\n",
       " ('Ethical Grocery', 5),\n",
       " ('Champagne Bars', 5),\n",
       " ('Day Spas', 5),\n",
       " ('Couriers & Delivery Services', 5),\n",
       " ('Adult Entertainment', 5),\n",
       " ('Laser Tag', 4),\n",
       " ('Curry Sausage', 4),\n",
       " ('Syrian', 4),\n",
       " ('Supper Clubs', 4),\n",
       " ('Department Stores', 4),\n",
       " ('Kitchen & Bath', 4),\n",
       " ('Appliances', 4),\n",
       " ('Pub Food', 4),\n",
       " ('Playgrounds', 4),\n",
       " ('Shopping Centers', 4),\n",
       " ('Florists', 4),\n",
       " ('Public Services & Government', 4),\n",
       " ('Amusement Parks', 4),\n",
       " ('Australian', 4),\n",
       " ('Wine Tasting Room', 4),\n",
       " ('Community Service/Non-Profit', 4),\n",
       " ('Sugar Shacks', 4),\n",
       " ('Candy Stores', 4),\n",
       " ('Ethnic Grocery', 4),\n",
       " ('Professional Services', 3),\n",
       " ('Tuscan', 3),\n",
       " ('Haitian', 3),\n",
       " ('Iberian', 3),\n",
       " ('Antiques', 3),\n",
       " ('Nutritionists', 3),\n",
       " ('Museums', 3),\n",
       " ('Drugstores', 3),\n",
       " ('Trinidadian', 3),\n",
       " ('Cooking Classes', 3),\n",
       " ('Musicians', 3),\n",
       " ('Pets', 3),\n",
       " ('Sporting Goods', 3),\n",
       " ('Herbs & Spices', 3),\n",
       " ('Comedy Clubs', 3),\n",
       " ('Honduran', 3),\n",
       " ('Bartenders', 3),\n",
       " ('Uzbek', 2),\n",
       " ('Czech', 2),\n",
       " ('Pita', 2),\n",
       " ('Colleges & Universities', 2),\n",
       " ('Towing', 2),\n",
       " ('Vitamins & Supplements', 2),\n",
       " ('Weight Loss Centers', 2),\n",
       " ('Home Decor', 2),\n",
       " ('Tabletop Games', 2),\n",
       " ('Escape Games', 2),\n",
       " ('Recreation Centers', 2),\n",
       " ('Dry Cleaning & Laundry', 2),\n",
       " ('Animal Shelters', 2),\n",
       " ('Fitness & Instruction', 2),\n",
       " ('Interior Design', 2),\n",
       " ('Car Dealers', 2),\n",
       " ('Japanese Curry', 2),\n",
       " ('Leisure Centers', 2),\n",
       " ('Wholesale Stores', 2),\n",
       " ('Beer Hall', 2),\n",
       " ('Olive Oil', 2),\n",
       " ('Themed Cafes', 2),\n",
       " ('Distilleries', 2),\n",
       " ('Souvenir Shops', 2),\n",
       " ('Hotel bar', 2),\n",
       " ('Nicaraguan', 2),\n",
       " ('Screen Printing', 2),\n",
       " ('Printing Services', 2),\n",
       " ('Shared Office Spaces', 2),\n",
       " ('Flea Markets', 2),\n",
       " ('Rock Climbing', 2),\n",
       " ('Tours', 2),\n",
       " ('Pharmacy', 1),\n",
       " ('Czech/Slovakian', 1),\n",
       " ('Hair Removal', 1),\n",
       " ('Mortgage Brokers', 1),\n",
       " ('Hostels', 1),\n",
       " ('Stadiums & Arenas', 1),\n",
       " ('Beach Bars', 1),\n",
       " ('Drive-Thru Bars', 1),\n",
       " ('Airports', 1),\n",
       " ('Keys & Locksmiths', 1),\n",
       " (\"Men's Clothing\", 1),\n",
       " ('Mauritius', 1),\n",
       " ('Medical Centers', 1),\n",
       " ('Club Crawl', 1),\n",
       " ('Cideries', 1),\n",
       " ('Trainers', 1),\n",
       " ('Yoga', 1),\n",
       " ('Furniture Stores', 1),\n",
       " ('Baby Gear & Furniture', 1),\n",
       " ('Tasting Classes', 1),\n",
       " ('Cheese Tasting Classes', 1),\n",
       " ('Bike Rentals', 1),\n",
       " ('Bike Repair/Maintenance', 1),\n",
       " ('Bikes', 1),\n",
       " ('Yelp Events', 1),\n",
       " ('Doctors', 1),\n",
       " ('Game Meat', 1),\n",
       " ('Web Design', 1),\n",
       " ('Advertising', 1),\n",
       " ('Real Estate Agents', 1),\n",
       " ('Sports Wear', 1),\n",
       " ('Milkshake Bars', 1),\n",
       " (\"Women's Clothing\", 1),\n",
       " ('Video Game Stores', 1),\n",
       " ('Parks', 1),\n",
       " ('Libraries', 1),\n",
       " ('Farms', 1),\n",
       " ('Hong Kong Style Cafe', 1),\n",
       " ('Pool & Billiards', 1),\n",
       " ('Adult Education', 1),\n",
       " ('Tempura', 1),\n",
       " ('Tonkatsu', 1),\n",
       " ('Plumbing', 1),\n",
       " ('Financial Services', 1),\n",
       " ('Check Cashing/Pay-day Loans', 1),\n",
       " ('Currency Exchange', 1),\n",
       " ('Horseback Riding', 1),\n",
       " ('Mountain Biking', 1),\n",
       " ('Guamanian', 1),\n",
       " ('Pet Services', 1),\n",
       " ('Pet Adoption', 1),\n",
       " ('Beaches', 1),\n",
       " ('Cultural Center', 1),\n",
       " ('Sports Clubs', 1),\n",
       " ('Pop-Up Restaurants', 1),\n",
       " ('Dentists', 1),\n",
       " ('Country Clubs', 1),\n",
       " ('Sicilian', 1),\n",
       " ('Discount Store', 1),\n",
       " ('Rotisserie Chicken', 1),\n",
       " ('Used Bookstore', 1),\n",
       " ('Kombucha', 1),\n",
       " ('Travel Services', 1),\n",
       " ('Mini Golf', 1),\n",
       " ('Popcorn Shops', 1),\n",
       " ('Climbing', 1),\n",
       " ('Comic Books', 1),\n",
       " ('Team Building Activities', 1),\n",
       " ('CSA', 1),\n",
       " ('Party Supplies', 1),\n",
       " ('Strip Clubs', 1),\n",
       " ('Party Equipment Rentals', 1),\n",
       " ('Wedding Chapels', 1),\n",
       " ('Videos & Video Game Rental', 1),\n",
       " ('Hainan', 1),\n",
       " ('Slovakian', 1),\n",
       " ('Chiropractors', 1),\n",
       " ('Special Education', 1),\n",
       " ('Water Stores', 1),\n",
       " ('Botanical Gardens', 1),\n",
       " ('Post Offices', 1),\n",
       " ('Religious Organizations', 1),\n",
       " ('Conveyor Belt Sushi', 1),\n",
       " ('Toy Stores', 1),\n",
       " ('Friterie', 1),\n",
       " ('Opera & Ballet', 1),\n",
       " ('Coffee & Tea Supplies', 1),\n",
       " ('Cabaret', 1),\n",
       " ('DJs', 1),\n",
       " ('Zoos', 1),\n",
       " ('Reunion', 1),\n",
       " ('Appliances & Repair', 1),\n",
       " ('Auto Repair', 1),\n",
       " ('Truck Rental', 1),\n",
       " ('Car Wash', 1),\n",
       " ('Pop-up Shops', 1),\n",
       " ('Bar Crawl', 1),\n",
       " ('Security Systems', 1),\n",
       " ('Udon', 1),\n",
       " ('Building Supplies', 1),\n",
       " ('Shaved Snow', 1),\n",
       " ('Nurseries & Gardening', 1),\n",
       " ('Flatbread', 1),\n",
       " ('Ticket Sales', 1),\n",
       " ('Knife Sharpening', 1),\n",
       " ('Virtual Reality Centers', 1),\n",
       " ('Guest Houses', 1),\n",
       " ('Eastern European', 1),\n",
       " ('Cannabis Clinics', 1),\n",
       " ('Life Coach', 1),\n",
       " ('Ski Resorts', 1)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count the number for each genre and sort\n",
    "import operator\n",
    "genre_count = dict()\n",
    "for l in item_genre_dict:\n",
    "    for g in item_genre_dict[l]:\n",
    "        if not g in genre_count:\n",
    "            genre_count[g] = 1\n",
    "        else:\n",
    "            genre_count[g] += 1\n",
    "\n",
    "genre_count_sorted = sorted(genre_count.items(), key=operator.itemgetter(1), reverse=True)\n",
    "genre_count_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_genre = ['American (New)', 'Chinese']\n",
    "\n",
    "# get the key_genre->item_list dict\n",
    "key_genre_item = dict()\n",
    "for k in key_genre:\n",
    "    key_genre_item[k] = list()\n",
    "for item in item_genre_dict:\n",
    "    for g in item_genre_dict[item]:\n",
    "        if g in key_genre:\n",
    "            key_genre_item[g].append(item)\n",
    "            \n",
    "# collect all the items with key genres\n",
    "key_item = list()\n",
    "for genre in key_genre_item:\n",
    "    key_item = key_item + key_genre_item[genre]\n",
    "key_item_set = set(key_item)\n",
    "\n",
    "# remove the non-key genre items in rdf\n",
    "item_set = set(item_list)\n",
    "nonkey_item_set = item_set - key_item_set\n",
    "for item in nonkey_item_set:\n",
    "    rdf.drop(rdf.index[rdf['item_id'] == item], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "rdf_copy = copy.copy(rdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf = copy.copy(rdf_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CxDOIDnH8gp9KXzpBHJYXw    311\n",
       "cMEtAiW60I5wE_vLfTxoJQ    290\n",
       "d_TBs6J3twMy9GChqUEXkg    239\n",
       "bLbSNkLggFnqwNNzzq-Ijw    194\n",
       "PKEzKWv_FktMm2mGPjwd0Q    188\n",
       "                         ... \n",
       "UAB1Zyg6Q0oEpXeYRf5K_g     10\n",
       "QTsB8VtGe46nUbMAZd87uQ     10\n",
       "SXeMGP5lNgc03z7cl9Xihg     10\n",
       "rbZgyYEawUszQdOyN3b9qg     10\n",
       "rwUo0-Bh2ASxO4mNMWWadg     10\n",
       "Name: user_id, Length: 6310, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# iteratively remove items and users with less than 5 reviews\n",
    "\n",
    "rdf['user_freq'] = rdf.groupby('user_id')['user_id'].transform('count')\n",
    "rdf.drop(rdf.index[rdf['user_freq'] <= 9], inplace=True)\n",
    "rdf['item_freq'] = rdf.groupby('item_id')['item_id'].transform('count')\n",
    "rdf.drop(rdf.index[rdf['item_freq'] <= 9], inplace=True)\n",
    "rdf['user_freq'] = rdf.groupby('user_id')['user_id'].transform('count')\n",
    "rdf['user_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item num = 2834\n",
      "user num = 6310\n"
     ]
    }
   ],
   "source": [
    "item_list = rdf['item_id'].unique()\n",
    "user_list = rdf['user_id'].unique()\n",
    "print('item num = ' + str(len(item_list)))\n",
    "print('user num = ' + str(len(user_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the user and item str id->int id dict\n",
    "i = 0\n",
    "user_id_dict = dict()\n",
    "for u in user_list:\n",
    "    if not u in user_id_dict:\n",
    "        user_id_dict[u] = i\n",
    "        i += 1\n",
    "j = 0\n",
    "item_id_dict = dict()\n",
    "for i in item_list:\n",
    "    if not i in item_id_dict:\n",
    "        item_id_dict[i] = j\n",
    "        j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparsity: 0.006597440855717365\n"
     ]
    }
   ],
   "source": [
    "print('sparsity: ' + str(len(rdf) * 1.0 / (len(user_list) * len(item_list))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/6310\n"
     ]
    }
   ],
   "source": [
    "# get the df of train, vali, and test set\n",
    "rdf.reset_index(inplace=True, drop=True)\n",
    "train_df = rdf.copy()\n",
    "vali_df = rdf.copy()\n",
    "test_df = rdf.copy()\n",
    "\n",
    "train_ratio = 0.6\n",
    "vali_ratio = 0.2\n",
    "test_ratio = 0.2\n",
    "num_all = len(rdf)\n",
    "vali_idx = []\n",
    "test_idx = []\n",
    "\n",
    "test_vali_idx = []\n",
    "i = 0\n",
    "num_user = len(user_list)\n",
    "for u in user_list:\n",
    "    u_idx = train_df.index[train_df['user_id'] == u]\n",
    "    idx_len = len(u_idx)\n",
    "    test_len = int(idx_len * (test_ratio + vali_ratio))\n",
    "    if test_len == 0:\n",
    "        test_len = 1\n",
    "    tmp = np.random.choice(u_idx, size=test_len, replace=False)\n",
    "    test_vali_idx += tmp.tolist()\n",
    "    i += 1\n",
    "    if i % 5000 == 0:\n",
    "        print(str(i) + '/' + str(num_user))\n",
    "\n",
    "# tmp = (np.random.choice(range(num_all), size=(test_len+vali_len), replace=False)).tolist()\n",
    "test_len = int(len(test_vali_idx) * test_ratio / (test_ratio + vali_ratio))\n",
    "vali_len = int(len(test_vali_idx) - test_len)\n",
    "test_idx = (np.random.choice(test_vali_idx, size=test_len, replace=False)).tolist()\n",
    "vali_idx = (np.random.choice(test_vali_idx, size=vali_len, replace=False)).tolist()\n",
    "\n",
    "test_set = set(test_idx)\n",
    "vali_set = set(vali_idx)\n",
    "train_set = set(range(num_all)) - test_set - vali_set\n",
    "train_idx = list(train_set)\n",
    "train_df.drop((test_idx + vali_idx), axis=0, inplace=True)\n",
    "test_df.drop((train_idx + vali_idx), axis=0, inplace=True)\n",
    "vali_df.drop((train_idx + test_idx), axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rdf.drop(columns=['rating'], inplace=True)\n",
    "# train_df.drop(columns=['rating'], inplace=True)\n",
    "# test_df.drop(columns=['rating'], inplace=True)\n",
    "# vali_df.drop(columns=['rating'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the matrix of train, vali and test set\n",
    "\n",
    "train_df.reset_index(drop=True, inplace=True)\n",
    "test_df.reset_index(drop=True, inplace=True)\n",
    "vali_df.reset_index(drop=True, inplace=True)\n",
    "rdf.reset_index(drop=True, inplace=True)\n",
    "train = np.zeros((len(user_list), len(item_list)))\n",
    "test = np.zeros((len(user_list), len(item_list)))\n",
    "vali = np.zeros((len(user_list), len(item_list)))\n",
    "for r in range(len(train_df)):\n",
    "    train[user_id_dict[train_df.at[r, 'user_id']], item_id_dict[train_df.at[r, 'item_id']]] = 1.0\n",
    "for r in range(len(test_df)):\n",
    "    test[user_id_dict[test_df.at[r, 'user_id']], item_id_dict[test_df.at[r, 'item_id']]] = 1.0\n",
    "for r in range(len(vali_df)):\n",
    "    vali[user_id_dict[vali_df.at[r, 'user_id']], item_id_dict[vali_df.at[r, 'item_id']]] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>r</th>\n",
       "      <th>user_freq</th>\n",
       "      <th>item_freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaZVUOzqk5b-l0mlki-9Og</td>\n",
       "      <td>tL2pS5UOmN6aAOi3Z-qFGg</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZibmYdOPKLlqDM9oR6xzOA</td>\n",
       "      <td>tL2pS5UOmN6aAOi3Z-qFGg</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Trbt0Ex85yvwT8DHoEFCvg</td>\n",
       "      <td>tL2pS5UOmN6aAOi3Z-qFGg</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>xoGPeHR2RPnJW470-aYBUQ</td>\n",
       "      <td>tL2pS5UOmN6aAOi3Z-qFGg</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>So132GP_uy3XbGs0KNyzyw</td>\n",
       "      <td>tL2pS5UOmN6aAOi3Z-qFGg</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  item_id                 user_id     r  user_freq  item_freq\n",
       "0  NaZVUOzqk5b-l0mlki-9Og  tL2pS5UOmN6aAOi3Z-qFGg  True         10         28\n",
       "1  ZibmYdOPKLlqDM9oR6xzOA  tL2pS5UOmN6aAOi3Z-qFGg  True         10        226\n",
       "2  Trbt0Ex85yvwT8DHoEFCvg  tL2pS5UOmN6aAOi3Z-qFGg  True         10         34\n",
       "3  xoGPeHR2RPnJW470-aYBUQ  tL2pS5UOmN6aAOi3Z-qFGg  True         10         33\n",
       "4  So132GP_uy3XbGs0KNyzyw  tL2pS5UOmN6aAOi3Z-qFGg  True         10         87"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the user int id-> str id list, and the same for item \n",
    "item_list = item_id_dict.keys()\n",
    "item_idd_list = list()\n",
    "for i in range(len(item_list)):\n",
    "    item_idd_list.append('')\n",
    "for item in item_id_dict:\n",
    "    item_idd_list[item_id_dict[item]] = item\n",
    "\n",
    "user_list = user_id_dict.keys()\n",
    "user_idd_list = list()\n",
    "for i in range(len(user_list)):\n",
    "    user_idd_list.append('')\n",
    "for user in user_id_dict:\n",
    "    user_idd_list[user_id_dict[user]] = user\n",
    "    \n",
    "# get the item int id->genres list\n",
    "item_idd_genre_list = list()\n",
    "for i in range(len(item_idd_list)):\n",
    "    item_idd_genre_list.append(item_genre_dict[item_idd_list[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.drop('user_freq', axis=1, inplace=True)\n",
    "train_df.drop('item_freq', axis=1, inplace=True)\n",
    "vali_df.drop('user_freq', axis=1, inplace=True)\n",
    "vali_df.drop('item_freq', axis=1, inplace=True)\n",
    "test_df.drop('user_freq', axis=1, inplace=True)\n",
    "test_df.drop('item_freq', axis=1, inplace=True)\n",
    "rdf.drop('user_freq', axis=1, inplace=True)\n",
    "rdf.drop('item_freq', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>r</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaZVUOzqk5b-l0mlki-9Og</td>\n",
       "      <td>tL2pS5UOmN6aAOi3Z-qFGg</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZibmYdOPKLlqDM9oR6xzOA</td>\n",
       "      <td>tL2pS5UOmN6aAOi3Z-qFGg</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Trbt0Ex85yvwT8DHoEFCvg</td>\n",
       "      <td>tL2pS5UOmN6aAOi3Z-qFGg</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>xoGPeHR2RPnJW470-aYBUQ</td>\n",
       "      <td>tL2pS5UOmN6aAOi3Z-qFGg</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>So132GP_uy3XbGs0KNyzyw</td>\n",
       "      <td>tL2pS5UOmN6aAOi3Z-qFGg</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  item_id                 user_id     r\n",
       "0  NaZVUOzqk5b-l0mlki-9Og  tL2pS5UOmN6aAOi3Z-qFGg  True\n",
       "1  ZibmYdOPKLlqDM9oR6xzOA  tL2pS5UOmN6aAOi3Z-qFGg  True\n",
       "2  Trbt0Ex85yvwT8DHoEFCvg  tL2pS5UOmN6aAOi3Z-qFGg  True\n",
       "3  xoGPeHR2RPnJW470-aYBUQ  tL2pS5UOmN6aAOi3Z-qFGg  True\n",
       "4  So132GP_uy3XbGs0KNyzyw  tL2pS5UOmN6aAOi3Z-qFGg  True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get df for rdf, train, vali, test with int id for user and item\n",
    "import copy\n",
    "rating_df = copy.copy(rdf)\n",
    "for i in range(len(rdf)):\n",
    "    rating_df.at[i, 'user_id'] = user_id_dict[rating_df.at[i, 'user_id']]\n",
    "    rating_df.at[i, 'item_id'] = item_id_dict[rating_df.at[i, 'item_id']]\n",
    "\n",
    "training_df = copy.copy(train_df)\n",
    "for i in range(len(training_df)):\n",
    "    training_df.at[i, 'user_id'] = user_id_dict[training_df.at[i, 'user_id']]\n",
    "    training_df.at[i, 'item_id'] = item_id_dict[training_df.at[i, 'item_id']]\n",
    "\n",
    "valiing_df = copy.copy(vali_df)\n",
    "for i in range(len(valiing_df)):\n",
    "    valiing_df.at[i, 'user_id'] = user_id_dict[valiing_df.at[i, 'user_id']]\n",
    "    valiing_df.at[i, 'item_id'] = item_id_dict[valiing_df.at[i, 'item_id']]\n",
    "\n",
    "testing_df = copy.copy(test_df)\n",
    "for i in range(len(testing_df)):\n",
    "    testing_df.at[i, 'user_id'] = user_id_dict[testing_df.at[i, 'user_id']]\n",
    "    testing_df.at[i, 'item_id'] = item_id_dict[testing_df.at[i, 'item_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>r</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  item_id user_id     r\n",
       "0       0       0  True\n",
       "1       2       0  True\n",
       "2       3       0  True\n",
       "3       4       0  True\n",
       "4       5       0  True"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2834"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df['item_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6310"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df['user_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the rating list for each key genre, get the genre->ratings dict\n",
    "rdf.reset_index(drop=True, inplace=True)\n",
    "key_genre_rating = dict()\n",
    "for k in key_genre:\n",
    "    key_genre_rating[k] = 0.0\n",
    "for r in range(len(rdf)):\n",
    "    item = rdf.at[r, 'item_id']\n",
    "    gl = item_genre_dict[item]\n",
    "    for k in key_genre:\n",
    "        if k in gl:\n",
    "            key_genre_rating[k] += 1.0\n",
    "\n",
    "# get the item int id->genres list\n",
    "genre_item_vector = dict()\n",
    "for k in key_genre:\n",
    "    genre_item_vector[k] = np.zeros((1, len(item_list)))\n",
    "for i in range(len(item_idd_genre_list)):\n",
    "    genre_list = item_idd_genre_list[i]\n",
    "    for g in genre_list:\n",
    "        if g in key_genre:\n",
    "            genre_item_vector[g][0, i] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>r</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  item_id user_id     r\n",
       "0       0       0  True\n",
       "1       2       0  True\n",
       "2       3       0  True\n",
       "3       4       0  True\n",
       "4       5       0  True"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"item_genre_dict.pkl\", \"wb\") as f:\n",
    "    pickle.dump(item_genre_dict, f, pickle.HIGHEST_PROTOCOL)\n",
    "with open(\"genre_item_vector.pkl\", \"wb\") as f:\n",
    "    pickle.dump(genre_item_vector, f, pickle.HIGHEST_PROTOCOL)\n",
    "with open(\"key_genre.pkl\", \"wb\") as f:\n",
    "    pickle.dump(key_genre, f, pickle.HIGHEST_PROTOCOL)\n",
    "with open(\"user_id_dict.pkl\", \"wb\") as f:\n",
    "    pickle.dump(user_id_dict, f, pickle.HIGHEST_PROTOCOL)\n",
    "with open(\"item_id_dict.pkl\", \"wb\") as f:\n",
    "    pickle.dump(item_id_dict, f, pickle.HIGHEST_PROTOCOL)\n",
    "with open(\"rdf.pkl\", \"wb\") as f:\n",
    "    pickle.dump(rdf, f, pickle.HIGHEST_PROTOCOL)\n",
    "with open(\"rating_df.pkl\", \"wb\") as f:\n",
    "    pickle.dump(rating_df, f, pickle.HIGHEST_PROTOCOL)\n",
    "with open(\"training_df.pkl\", \"wb\") as f:\n",
    "    pickle.dump(training_df, f, pickle.HIGHEST_PROTOCOL)\n",
    "with open(\"valiing_df.pkl\", \"wb\") as f:\n",
    "    pickle.dump(valiing_df, f, pickle.HIGHEST_PROTOCOL)\n",
    "with open(\"testing_df.pkl\", \"wb\") as f:\n",
    "    pickle.dump(testing_df, f, pickle.HIGHEST_PROTOCOL)\n",
    "with open(\"item_idd_genre_list.pkl\", \"wb\") as f:\n",
    "    pickle.dump(item_idd_genre_list, f, pickle.HIGHEST_PROTOCOL)\n",
    "with open(\"item_idd_list.pkl\", \"wb\") as f:\n",
    "    pickle.dump(item_idd_list, f, pickle.HIGHEST_PROTOCOL)\n",
    "with open(\"user_idd_list.pkl\", \"wb\") as f:\n",
    "    pickle.dump(user_idd_list, f, pickle.HIGHEST_PROTOCOL)\n",
    "with open(\"key_genre_rating.pkl\", \"wb\") as f:\n",
    "    pickle.dump(key_genre_rating, f, pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open(\"train.mat\", \"wb\") as f:\n",
    "    np.save(f, train)\n",
    "with open(\"test.mat\", \"wb\") as f:\n",
    "    np.save(f, test)\n",
    "with open(\"vali.mat\", \"wb\") as f:\n",
    "    np.save(f, vali)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'American (New)', 1766), (u'Chinese', 1078)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count the number for each genre and sort\n",
    "import pickle\n",
    "from operator import itemgetter\n",
    "# item_list = pickle.load(open('./rdf.pkl'))['item_id'].unique()\n",
    "# item_genre_dict = pickle.load(open('./item_genre_dict.pkl'))\n",
    "# key_genre = pickle.load(open('./key_genre.pkl'))\n",
    "\n",
    "genre_count = dict()\n",
    "for i in item_list:\n",
    "    gl = item_genre_dict[i]\n",
    "    for g in gl:\n",
    "        if g in key_genre:\n",
    "            if not g in genre_count:\n",
    "                genre_count[g] = 1\n",
    "            else:\n",
    "                genre_count[g] += 1\n",
    "\n",
    "with open(\"genre_count.pkl\", \"wb\") as f:\n",
    "    pickle.dump(genre_count, f, pickle.HIGHEST_PROTOCOL)\n",
    "                \n",
    "genre_count_sorted = sorted(genre_count.items(), key=itemgetter(1), reverse=True)\n",
    "genre_count_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import copy as copy\n",
    "\n",
    "item_idd_genre_list = np.array(item_idd_genre_list)\n",
    "\n",
    "\n",
    "mask = 1.0 * (train > 0)\n",
    "user_genre_count = list()\n",
    "for u in range(train.shape[0]):\n",
    "    temp_genre_count = copy.copy(genre_count)\n",
    "    mask_u = mask[u, :]\n",
    "    gll = item_idd_genre_list[mask_u == 1.0]\n",
    "    for gl in gll:\n",
    "        for g in gl:\n",
    "            if g in key_genre:\n",
    "                temp_genre_count[g] -= 1\n",
    "    user_genre_count.append(temp_genre_count)\n",
    "with open(\"user_genre_count.pkl\", \"wb\") as f:\n",
    "    pickle.dump(user_genre_count, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_avg_like = dict()\n",
    "for k in key_genre:\n",
    "    genre_avg_like[k] = key_genre_rating[k] * 1.0 / genre_count[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('American (New)', 48.81087202718007), ('Chinese', 29.94990723562152)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_avg_like_sorted = sorted(genre_avg_like.items(), key=itemgetter(1), reverse=True)\n",
    "genre_avg_like_sorted"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
