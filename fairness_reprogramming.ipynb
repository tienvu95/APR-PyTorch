{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35dba935",
   "metadata": {},
   "source": [
    "Thinking of APR. Are we doing the dual optimization with the classification model + the pertubation added?\n",
    "\n",
    "To do: think of how to split data to train/test/ tune 80/10/10 --> Done. Ready to run experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "04a30440",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import relevant library\n",
    "\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import pickle\n",
    "import argparse\n",
    "from collections import deque\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "# from torchvision.datasets import CIFAR10\n",
    "from torch.utils.data import DataLoader\n",
    "# from torchvision import transforms\n",
    "from torch.utils.data import IterableDataset, DataLoader, get_worker_info\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f262aa84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5a29fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "## time the process\n",
    "def get_time_dif(start_time):\n",
    "    \"\"\"get the running time\"\"\"\n",
    "    end_time = time.time()\n",
    "    time_dif = end_time - start_time\n",
    "    return timedelta(seconds=int(round(time_dif)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85059586",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## set up the u,i,j triplet for BPR framework\n",
    "class GetTriplePair(IterableDataset):\n",
    "    # for ml-1m we load in 3760 item 6040 user and 994169 train pair\n",
    "    def __init__(self, item_size, user_list, pair, shuffle, num_epochs):\n",
    "        self.item_size = item_size\n",
    "        self.user_list = user_list\n",
    "        self.pair = pair\n",
    "        self.shuffle = shuffle\n",
    "        self.num_epochs = num_epochs\n",
    "\n",
    "    def __iter__(self):\n",
    "        self.example_size = self.num_epochs * len(self.pair)\n",
    "        self.example_index_queue = deque([])\n",
    "        self.seed = 0\n",
    "        self.start_list_index = None\n",
    "        self.num_workers = 1\n",
    "        self.index = 0\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.index >= self.example_size:\n",
    "            raise StopIteration\n",
    "        # If `example_index_queue` is used up, replenish this list.\n",
    "        while len(self.example_index_queue) == 0:\n",
    "            index_list = list(range(len(self.pair)))\n",
    "            if self.shuffle:\n",
    "                random.Random(self.seed).shuffle(index_list)\n",
    "                self.seed += 1\n",
    "            if self.start_list_index is not None:\n",
    "                index_list = index_list[self.start_list_index::self.num_workers]\n",
    "\n",
    "                # Calculate next start index\n",
    "                self.start_list_index = (self.start_list_index + (self.num_workers - (len(self.pair) % self.num_workers))) % self.num_workers\n",
    "            self.example_index_queue.extend(index_list)\n",
    "        result = self._example(self.example_index_queue.popleft())\n",
    "        self.index += self.num_workers\n",
    "        return result\n",
    "\n",
    "    def _example(self, idx):\n",
    "        # in a train pair, format = (u,i), j = a random item which does not exist in user u's list of items\n",
    "        u = self.pair[idx][0]\n",
    "        i = self.pair[idx][1]\n",
    "        j = np.random.randint(self.item_size)\n",
    "        while j in self.user_list[u]:\n",
    "            j = np.random.randint(self.item_size)\n",
    "        return u, i, j\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "162137b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adversary(torch.nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, with_y=False, with_logits=False, use_mlp=False, with_logits_y=False,\n",
    "                 with_single_y=False):\n",
    "        super(Adversary4Z, self).__init__() #inherit properties\n",
    "        self.c = torch.nn.Parameter(torch.tensor(1.0, requires_grad=True)) #initialize parameters to optimize for\n",
    "        self.input_dim = input_dim #number of labels\n",
    "        self.with_y = with_y #number of groups\n",
    "        self.with_logits = with_logits \n",
    "        self.with_logits_y = with_logits_y\n",
    "        self.with_single_y = with_single_y\n",
    "\n",
    "        # the basic input = [s], to determine which defition of fairness we are going with\n",
    "        if self.with_logits:  # input = concat([input, logits])\n",
    "            self.input_dim += input_dim\n",
    "        if self.with_y:  # input = concat([input, s*y, s*(1-y)])\n",
    "            self.input_dim += input_dim * 2\n",
    "        if self.with_logits_y:  # input = concat([input, logits*y, logits*(1-y)])\n",
    "            self.input_dim += input_dim * 2\n",
    "        if self.with_single_y:  # input = concat([input, y])\n",
    "            self.input_dim += 1\n",
    "\n",
    "        self.use_mlp = use_mlp\n",
    "        # basically its a mlp that predict group from input dimension\n",
    "        if self.use_mlp:\n",
    "            hidden_dim = [128, 128]\n",
    "            hidden_dim = [self.input_dim] + list(hidden_dim) + [output_dim]\n",
    "            self.seq = torch.nn.ModuleList() #this is just like a python list but an instance of submodule\n",
    "            for i in range(1, len(hidden_dim)):\n",
    "                self.seq.append(torch.nn.Linear(hidden_dim[i - 1], hidden_dim[i]))\n",
    "                if i != (len(hidden_dim) - 1):\n",
    "                    self.seq.append(torch.nn.ReLU())\n",
    "        else:\n",
    "            self.fc = torch.nn.Linear(self.input_dim, output_dim, bias=True)\n",
    "            \n",
    "    # Forward defines the computation in the model\n",
    "    def forward(self, inputs, *, y=None):\n",
    "        assert len(inputs.shape) == 2 #test if shape of input is 2 else raise assertion error\n",
    "\n",
    "        #define for binary -- use sigmoid and multiclass -- use softmax adversary\n",
    "        if inputs.shape[1] > 1:\n",
    "            s = torch.softmax(inputs * (1 + torch.abs(self.c)), dim=-1)\n",
    "            if self.with_y or self.with_logits_y or self.with_single_y:\n",
    "                raise NotImplementedError  # only support binary case with y\n",
    "        else:\n",
    "            s = torch.sigmoid(inputs * (1 + torch.abs(self.c)))\n",
    "\n",
    "        if self.with_y:\n",
    "            assert y is not None #if adversary test with y then there must be an available value for y\n",
    "            _y = y.view(-1, 1).long() # -1 is infered from other dim, if dim = n x n then view (-1,1) transform to n x 1\n",
    "            assert len(_y) == inputs.shape[0] #size of y must be compatible with the input\n",
    "            encoded_inputs = torch.cat([s, s * _y, s * (1 - _y)], dim=1)\n",
    "        else:\n",
    "            assert y is None\n",
    "            encoded_inputs = s\n",
    "\n",
    "        if self.with_logits:\n",
    "            encoded_inputs = torch.cat([encoded_inputs, inputs], dim=1)\n",
    "\n",
    "        if self.with_logits_y:\n",
    "            assert y is not None\n",
    "            _y = y.view(-1, 1).long()\n",
    "            assert len(_y) == inputs.shape[0]\n",
    "            encoded_inputs = torch.cat([encoded_inputs, inputs * _y, inputs * (1 - _y)], dim=1)\n",
    "\n",
    "        if self.with_single_y:\n",
    "            assert y is not None\n",
    "            _y = y.view(-1, 1).long()\n",
    "            assert len(_y) == inputs.shape[0]\n",
    "            encoded_inputs = torch.cat([encoded_inputs, _y], dim=1)\n",
    "\n",
    "        if self.use_mlp:\n",
    "            logits = encoded_inputs\n",
    "            for i, l in enumerate(self.seq):\n",
    "                logits = l(logits)\n",
    "        else:\n",
    "            logits = self.fc(encoded_inputs)\n",
    "\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4d731693",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = [128, 128]\n",
    "hidden_dim = [2] + list(hidden_dim) + [2]\n",
    "seq = torch.nn.ModuleList() #this is just like a python list but an instance of submodule\n",
    "for i in range(1, len(hidden_dim)):\n",
    "    seq.append(torch.nn.Linear(hidden_dim[i - 1], hidden_dim[i]))\n",
    "    if i != (len(hidden_dim) - 1):\n",
    "        seq.append(torch.nn.ReLU())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1fdac218",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): Linear(in_features=2, out_features=128, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (3): ReLU()\n",
       "  (4): Linear(in_features=128, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9e6d922e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## chunk to define matrix factorization part\n",
    "class fair_reprogram(nn.Module):\n",
    "    def __init__(self, user_emb, item_emb, dim, reg, reg_adv, eps):\n",
    "        super().__init__()\n",
    "        ##init the embedding for U and I\n",
    "        self.user_emb = user_emb  # User embedding taken from the pre-trained model (retrieved from checkpoint)\n",
    "        self.item_emb = item_emb  # Item embedding taken from the pre-trained model (retrieved from checkpoint)\n",
    "        self.reg = reg\n",
    "        self.dim = dim\n",
    "        self.reg_adv = reg_adv\n",
    "        self.eps = eps\n",
    "        self.update_u = None\n",
    "        self.update_i = None\n",
    "        self.update_j = None\n",
    "\n",
    "## we first initialize an mlp that capable of tracing the the age or gender of the users\n",
    "    def forward(self, u, i, epoch):\n",
    "\n",
    "        ##u,i,j respectively, each is a vector of dim embedding (default = 64), retrieve embedding from previous checkpoint\n",
    "        u = self.user_emb[u, :]\n",
    "        i = self.item_emb[i, :]\n",
    "\n",
    "\n",
    "        ## predicted score for ui uj\n",
    "        x_ui = torch.mul(u, i).sum(dim=1)\n",
    "\n",
    "        ## predict the gender from the predicted scores and from the true y value \n",
    "        y_logits = adv(x_ui) # model outputs raw logits \n",
    "        y_pred = torch.softmax(y_logits, dim=1).argmax(dim=1) # go from logits -> prediction probabilities -> prediction labels\n",
    "        \n",
    "        ## original bpr loss,\n",
    "        loss_fn = nn.CrossEntropyLoss()\n",
    "        loss = loss_fn(y_logits, y_blob_train)\n",
    "\n",
    "        loss.backward()\n",
    "        return loss\n",
    "        # add adv training after a certain number of epochs, here is the part which we add hypernet module\n",
    "        if epoch not in range(args.epochs, args.adv_epoch + args.epochs):\n",
    "            \"\"\"Normal training\"\"\"\n",
    "            loss.backward()\n",
    "            return loss\n",
    "\n",
    "#         else:\n",
    "#             \"\"\"Adversarial training:\n",
    "#                     1.Backward to get grads\n",
    "#                     2.Construct adversarial perturbation\n",
    "#                     3.Add adversarial perturbation to embeddings\n",
    "#                     4.Calculate APR loss\n",
    "#             \"\"\"\n",
    "#             # Backward to get grads\n",
    "#             # this would be the part we change in defining delta, delta = HPN (phi)\n",
    "\n",
    "#             # should we calculate based on gradient of the adv_loss instead of the loss function?, originally, computed based on loss function\n",
    "#             loss.backward(retain_graph=True) ## need to retain graph here so as to we can backprop the adv_loss\n",
    "#             ##recheck this\n",
    "#             grad_u = u.grad\n",
    "#             grad_i = i.grad\n",
    "#             grad_j = j.grad\n",
    "\n",
    "#             # Construct adversarial perturbation based on gradient of loss function, and normalize it with epsilon * norm\n",
    "#             if grad_u is not None:\n",
    "#                 delta_u = nn.functional.normalize(grad_u, p=2, dim=1, eps=self.eps)\n",
    "#             else:\n",
    "#                 delta_u = torch.rand(u.size())\n",
    "#             if grad_i is not None:\n",
    "#                 delta_i = nn.functional.normalize(grad_i, p=2, dim=1, eps=self.eps)\n",
    "#             else:\n",
    "#                 delta_i = torch.rand(i.size())\n",
    "#             if grad_j is not None:\n",
    "#                 delta_j = nn.functional.normalize(grad_j, p=2, dim=1, eps=self.eps)\n",
    "#             else:\n",
    "#                 delta_j = torch.rand(j.size())\n",
    "\n",
    "#             # Add adversarial perturbation to embeddings, now we have q+delta, p+delta\n",
    "#             x_ui_adv = torch.mul(u + delta_u, i + delta_i).sum(dim=1)\n",
    "#             x_uj_adv = torch.mul(u + delta_u, j + delta_j).sum(dim=1)\n",
    "\n",
    "#             # find difference between pos and neg item, then clip value\n",
    "#             x_uij_adv = torch.clamp(x_ui_adv - x_uj_adv,min=-80.0,max=1e8)\n",
    "\n",
    "#             # Calculate APR loss with logsigmoid\n",
    "#             log_prob = F.logsigmoid(x_uij_adv).sum()\n",
    "#             adv_loss = self.reg_adv *(-log_prob) + loss # this is adversarial loss (equation 4 in paper)\n",
    "#             adv_loss.backward()\n",
    "\n",
    "#             return adv_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4961396",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fairness_reprogramming(self, u, i, j):\n",
    "    \"\"\"Reprogramming phase:\n",
    "        1.Freeze the user and item embedding -- done by saving checkpoint\n",
    "        2.Calculate the perturbation to achieve fairness objective\n",
    "        3.Add perturbation to the alr frozen embedding\n",
    "        4.Calculate the overall loss function after update\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize a fix random perturbation\n",
    "    perturbation = torch.rand(1)\n",
    "    \n",
    "    #load user and item embedding, which has been trained in BPR\n",
    "    u = list(model1.items())[0][1]\n",
    "    i = list(model1.items())[1][1][i]\n",
    "    j = list(model1.items())[1][1][j]\n",
    "        \n",
    "    # Add adversarial perturbation to embeddings, now we have q+delta, p+delta\n",
    "    x_ui_adv = torch.mul(u , i + perturbation).sum(dim=1)\n",
    "    x_uj_adv = torch.mul(u , j + perturbation).sum(dim=1)\n",
    "\n",
    "    # find difference between pos and neg item, then clip value\n",
    "    x_uij_adv = torch.clamp(x_ui_adv - x_uj_adv,min=-80.0,max=1e8)\n",
    "\n",
    "    # Calculate loss with perturbed embedding with logsigmoid\n",
    "    log_prob = F.logsigmoid(x_uij_adv).sum()\n",
    "            \n",
    "    #set up an adversary to identify group of items\n",
    "    adversary_rs        \n",
    "            \n",
    "    # modify the adversarial loss here\n",
    "    adv_loss = self.reg_adv *(-log_prob) + loss # this is adversarial loss (equation 4 in paper)\n",
    "    adv_loss.backward()\n",
    "\n",
    "    return adv_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3a3b93ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3760, 64])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load the results of BPR\n",
    "model1 = (torch.load('models/01_pytorch_workflow_model_1.pth'))\n",
    "list(model1.items())[1][1].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb7a8d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "87f05379",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 9.3768e-04, -4.2642e-02,  2.0659e-02,  ..., -2.2226e-02,\n",
       "          3.1339e-02, -3.3840e-02],\n",
       "        [ 1.5390e-04, -3.8164e-03,  1.1938e-02,  ..., -1.9504e-03,\n",
       "         -5.5167e-03,  2.5199e-02],\n",
       "        [-1.7836e-03, -3.0050e-02, -3.0792e-02,  ...,  1.1926e-02,\n",
       "         -1.7736e-02,  6.9641e-03],\n",
       "        ...,\n",
       "        [-3.4588e-02, -1.5128e-03, -5.1930e-02,  ...,  3.3526e-02,\n",
       "         -3.9308e-03,  1.3962e-02],\n",
       "        [ 1.6954e-05, -1.2272e-02,  3.1606e-02,  ..., -2.2976e-02,\n",
       "         -1.5850e-03, -2.3360e-02],\n",
       "        [ 1.0627e-02, -2.0485e-02, -3.4491e-02,  ..., -1.7362e-02,\n",
       "          3.7945e-03,  7.2581e-03]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model1.items())[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "1c514cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "adv = Adversary4Z(input_dim=2, output_dim =6,use_mlp=True)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(adv.parameters(), lr=1e-3)\n",
    "\n",
    "# Calculate accuracy (a classification metric)\n",
    "def accuracy_fn(y_true, y_pred):\n",
    "    correct = torch.eq(y_true, y_pred).sum().item() # torch.eq() calculates where two tensors are equal\n",
    "    acc = (correct / len(y_pred)) * 100 \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "88893c38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Loss: 1.79241, Acc: 0.00% | Test Loss: 1.74086, Test Acc: 73.26%\n",
      "Epoch: 10 | Loss: 1.26619, Acc: 75.38% | Test Loss: 1.21143, Test Acc: 75.12%\n",
      "Epoch: 20 | Loss: 0.78448, Acc: 75.38% | Test Loss: 0.75899, Test Acc: 75.12%\n",
      "Epoch: 30 | Loss: 0.62760, Acc: 75.38% | Test Loss: 0.62399, Test Acc: 75.12%\n",
      "Epoch: 40 | Loss: 0.57636, Acc: 75.38% | Test Loss: 0.57793, Test Acc: 75.12%\n",
      "Epoch: 50 | Loss: 0.56802, Acc: 75.38% | Test Loss: 0.56953, Test Acc: 75.12%\n",
      "Epoch: 60 | Loss: 0.56411, Acc: 75.38% | Test Loss: 0.56688, Test Acc: 75.12%\n",
      "Epoch: 70 | Loss: 0.56192, Acc: 75.38% | Test Loss: 0.56456, Test Acc: 75.12%\n",
      "Epoch: 80 | Loss: 0.56090, Acc: 75.38% | Test Loss: 0.56373, Test Acc: 75.12%\n",
      "Epoch: 90 | Loss: 0.56030, Acc: 75.38% | Test Loss: 0.56305, Test Acc: 75.12%\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Set number of epochs\n",
    "epochs = 100\n",
    "\n",
    "test_df = pd.read_csv('Data/train_df.csv', sep=',', encoding=\"utf-8\",engine='python',header =None)\n",
    "test_df = test_df.iloc[:, [3, 5, 6]]\n",
    "\n",
    "X = torch.tensor(np.array(test_df.iloc[:,[0,2]])).type(torch.float)\n",
    "Y = torch.tensor(test_df.iloc[:,1].astype('category').cat.codes).type(torch.LongTensor)   \n",
    "\n",
    "\n",
    "X_blob_train, X_blob_test, y_blob_train, y_blob_test = train_test_split(X,\n",
    "    Y,\n",
    "    test_size=0.2,\n",
    "    random_state=181\n",
    ")\n",
    "\n",
    "# Put data to target device\n",
    "X_blob_train, y_blob_train = X_blob_train.to(device), y_blob_train.to(device)\n",
    "X_blob_test, y_blob_test = X_blob_test.to(device), y_blob_test.to(device)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    ### Training\n",
    "    adv.train()\n",
    "\n",
    "    # 1. Forward pass\n",
    "    y_logits = adv(X_blob_train) # model outputs raw logits \n",
    "    y_pred = torch.softmax(y_logits, dim=1).argmax(dim=1) # go from logits -> prediction probabilities -> prediction labels\n",
    "    # print(y_logits)\n",
    "    # 2. Calculate loss and accuracy\n",
    "    loss = loss_fn(y_logits, y_blob_train) \n",
    "    acc = accuracy_fn(y_true=y_blob_train,\n",
    "                      y_pred=y_pred)\n",
    "\n",
    "    # 3. Optimizer zero grad\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # 4. Loss backwards\n",
    "    loss.backward()\n",
    "\n",
    "    # 5. Optimizer step\n",
    "    optimizer.step()\n",
    "\n",
    "    ### Testing\n",
    "    adv.eval()\n",
    "    with torch.inference_mode():\n",
    "      # 1. Forward pass\n",
    "        test_logits = adv(X_blob_test)\n",
    "        test_pred = torch.softmax(test_logits, dim=1).argmax(dim=1)\n",
    "      # 2. Calculate test loss and accuracy\n",
    "        test_loss = loss_fn(test_logits, y_blob_test)\n",
    "        test_acc = accuracy_fn(y_true=y_blob_test,\n",
    "                             y_pred=test_pred)\n",
    "\n",
    "    # Print out what's happening\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch: {epoch} | Loss: {loss:.5f}, Acc: {acc:.2f}% | Test Loss: {test_loss:.5f}, Test Acc: {test_acc:.2f}%\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a8f952fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([637114])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_blob_train.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "1c01e04f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1274228, 1])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_blob_train.view(-1,1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f51d8700",
   "metadata": {},
   "outputs": [],
   "source": [
    "#goal = input y and yhat and return the group of the item?\n",
    "\n",
    "# Build model\n",
    "class adversary_rs(nn.Module):\n",
    "    def __init__(self, input_features, output_features, hidden_units=8):\n",
    "        \"\"\"Initializes all required hyperparameters for a multi-class classification model.\n",
    "\n",
    "        Args:\n",
    "            input_features (int): Number of input features to the model.\n",
    "            out_features (int): Number of output features of the model\n",
    "              (how many classes there are).\n",
    "            hidden_units (int): Number of hidden units between layers, default 8.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.linear_layer_stack = nn.Sequential(\n",
    "            nn.Linear(in_features=input_features, out_features=hidden_units),\n",
    "            # nn.ReLU(), # <- does our dataset require non-linear layers? (try uncommenting and see if the results change)\n",
    "            nn.Linear(in_features=hidden_units, out_features=hidden_units),\n",
    "            # nn.ReLU(), # <- does our dataset require non-linear layers? (try uncommenting and see if the results change)\n",
    "            nn.Linear(in_features=hidden_units, out_features=output_features), # how many classes are there?\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.linear_layer_stack(x)\n",
    "\n",
    "# Create an instance of BlobModel and send it to the target device\n",
    "mlp = adversary_rs(input_features=1, \n",
    "                    output_features=6, \n",
    "                    hidden_units=500).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e0990b22",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Define the loss function and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(mlp.parameters(), lr=1e-4)\n",
    "  # Prepare CIFAR-10 dataset\n",
    "# trainloader = torch.utils.data.DataLoader(X, batch_size=512, shuffle=True, num_workers=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "13f3e72f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "adversary_rs(\n",
       "  (linear_layer_stack): Sequential(\n",
       "    (0): Linear(in_features=1, out_features=500, bias=True)\n",
       "    (1): Linear(in_features=500, out_features=500, bias=True)\n",
       "    (2): Linear(in_features=500, out_features=6, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "97f3aca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy (a classification metric)\n",
    "def accuracy_fn(y_true, y_pred):\n",
    "    correct = torch.eq(y_true, y_pred).sum().item() # torch.eq() calculates where two tensors are equal\n",
    "    acc = (correct / len(y_pred)) * 100 \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "864d60f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Loss: 1.73429, Acc: 40.30% | Test Loss: 1.47605, Test Acc: 44.84%\n",
      "Epoch: 10 | Loss: 1.42034, Acc: 44.80% | Test Loss: 1.40173, Test Acc: 44.84%\n",
      "Epoch: 20 | Loss: 1.39443, Acc: 45.17% | Test Loss: 1.38122, Test Acc: 45.13%\n",
      "Epoch: 30 | Loss: 1.37248, Acc: 45.83% | Test Loss: 1.35702, Test Acc: 46.02%\n",
      "Epoch: 40 | Loss: 1.35933, Acc: 47.01% | Test Loss: 1.34779, Test Acc: 46.02%\n",
      "Epoch: 50 | Loss: 1.35134, Acc: 48.19% | Test Loss: 1.34180, Test Acc: 48.67%\n",
      "Epoch: 60 | Loss: 1.34569, Acc: 47.82% | Test Loss: 1.33921, Test Acc: 48.38%\n",
      "Epoch: 70 | Loss: 1.34156, Acc: 47.97% | Test Loss: 1.33752, Test Acc: 48.97%\n",
      "Epoch: 80 | Loss: 1.33857, Acc: 48.12% | Test Loss: 1.33625, Test Acc: 48.67%\n",
      "Epoch: 90 | Loss: 1.33634, Acc: 48.12% | Test Loss: 1.33610, Test Acc: 48.67%\n",
      "Epoch: 100 | Loss: 1.33465, Acc: 48.12% | Test Loss: 1.33587, Test Acc: 48.67%\n",
      "Epoch: 110 | Loss: 1.33335, Acc: 48.12% | Test Loss: 1.33594, Test Acc: 48.67%\n",
      "Epoch: 120 | Loss: 1.33233, Acc: 48.12% | Test Loss: 1.33612, Test Acc: 48.67%\n",
      "Epoch: 130 | Loss: 1.33153, Acc: 48.19% | Test Loss: 1.33632, Test Acc: 48.97%\n",
      "Epoch: 140 | Loss: 1.33090, Acc: 48.12% | Test Loss: 1.33662, Test Acc: 48.97%\n",
      "Epoch: 150 | Loss: 1.33040, Acc: 48.04% | Test Loss: 1.33695, Test Acc: 48.97%\n",
      "Epoch: 160 | Loss: 1.33000, Acc: 48.04% | Test Loss: 1.33730, Test Acc: 48.97%\n",
      "Epoch: 170 | Loss: 1.32969, Acc: 48.12% | Test Loss: 1.33765, Test Acc: 48.67%\n",
      "Epoch: 180 | Loss: 1.32944, Acc: 48.19% | Test Loss: 1.33800, Test Acc: 48.67%\n",
      "Epoch: 190 | Loss: 1.32925, Acc: 48.19% | Test Loss: 1.33834, Test Acc: 48.67%\n",
      "Epoch: 200 | Loss: 1.32910, Acc: 48.19% | Test Loss: 1.33866, Test Acc: 48.67%\n",
      "Epoch: 210 | Loss: 1.32898, Acc: 48.19% | Test Loss: 1.33897, Test Acc: 48.67%\n",
      "Epoch: 220 | Loss: 1.32889, Acc: 48.19% | Test Loss: 1.33925, Test Acc: 48.67%\n",
      "Epoch: 230 | Loss: 1.32883, Acc: 48.19% | Test Loss: 1.33950, Test Acc: 48.67%\n",
      "Epoch: 240 | Loss: 1.32878, Acc: 48.19% | Test Loss: 1.33974, Test Acc: 48.67%\n",
      "Epoch: 250 | Loss: 1.32874, Acc: 48.19% | Test Loss: 1.33995, Test Acc: 48.67%\n",
      "Epoch: 260 | Loss: 1.32871, Acc: 48.19% | Test Loss: 1.34014, Test Acc: 48.67%\n",
      "Epoch: 270 | Loss: 1.32869, Acc: 48.19% | Test Loss: 1.34031, Test Acc: 48.67%\n",
      "Epoch: 280 | Loss: 1.32868, Acc: 48.19% | Test Loss: 1.34045, Test Acc: 48.67%\n",
      "Epoch: 290 | Loss: 1.32867, Acc: 48.19% | Test Loss: 1.34058, Test Acc: 48.67%\n",
      "Epoch: 300 | Loss: 1.32866, Acc: 48.19% | Test Loss: 1.34069, Test Acc: 48.67%\n",
      "Epoch: 310 | Loss: 1.32865, Acc: 48.19% | Test Loss: 1.34079, Test Acc: 48.67%\n",
      "Epoch: 320 | Loss: 1.32865, Acc: 48.19% | Test Loss: 1.34087, Test Acc: 48.67%\n",
      "Epoch: 330 | Loss: 1.32865, Acc: 48.19% | Test Loss: 1.34094, Test Acc: 48.67%\n",
      "Epoch: 340 | Loss: 1.32865, Acc: 48.19% | Test Loss: 1.34099, Test Acc: 48.67%\n",
      "Epoch: 350 | Loss: 1.32864, Acc: 48.19% | Test Loss: 1.34104, Test Acc: 48.67%\n",
      "Epoch: 360 | Loss: 1.32864, Acc: 48.27% | Test Loss: 1.34108, Test Acc: 48.67%\n",
      "Epoch: 370 | Loss: 1.32864, Acc: 48.27% | Test Loss: 1.34112, Test Acc: 48.67%\n",
      "Epoch: 380 | Loss: 1.32864, Acc: 48.27% | Test Loss: 1.34114, Test Acc: 48.67%\n",
      "Epoch: 390 | Loss: 1.32864, Acc: 48.27% | Test Loss: 1.34117, Test Acc: 48.67%\n",
      "Epoch: 400 | Loss: 1.32864, Acc: 48.34% | Test Loss: 1.34118, Test Acc: 48.67%\n",
      "Epoch: 410 | Loss: 1.32864, Acc: 48.34% | Test Loss: 1.34120, Test Acc: 48.67%\n",
      "Epoch: 420 | Loss: 1.32864, Acc: 48.34% | Test Loss: 1.34121, Test Acc: 48.67%\n",
      "Epoch: 430 | Loss: 1.32864, Acc: 48.34% | Test Loss: 1.34122, Test Acc: 48.67%\n",
      "Epoch: 440 | Loss: 1.32864, Acc: 48.34% | Test Loss: 1.34123, Test Acc: 48.67%\n",
      "Epoch: 450 | Loss: 1.32864, Acc: 48.34% | Test Loss: 1.34123, Test Acc: 48.67%\n",
      "Epoch: 460 | Loss: 1.32864, Acc: 48.34% | Test Loss: 1.34124, Test Acc: 48.67%\n",
      "Epoch: 470 | Loss: 1.32864, Acc: 48.34% | Test Loss: 1.34124, Test Acc: 48.67%\n",
      "Epoch: 480 | Loss: 1.32864, Acc: 48.34% | Test Loss: 1.34125, Test Acc: 48.67%\n",
      "Epoch: 490 | Loss: 1.32864, Acc: 48.34% | Test Loss: 1.34125, Test Acc: 48.67%\n",
      "Epoch: 500 | Loss: 1.32864, Acc: 48.34% | Test Loss: 1.34125, Test Acc: 48.67%\n",
      "Epoch: 510 | Loss: 1.32864, Acc: 48.34% | Test Loss: 1.34125, Test Acc: 48.67%\n",
      "Epoch: 520 | Loss: 1.32864, Acc: 48.34% | Test Loss: 1.34125, Test Acc: 48.67%\n",
      "Epoch: 530 | Loss: 1.32864, Acc: 48.34% | Test Loss: 1.34125, Test Acc: 48.67%\n",
      "Epoch: 540 | Loss: 1.32864, Acc: 48.34% | Test Loss: 1.34125, Test Acc: 48.67%\n",
      "Epoch: 550 | Loss: 1.32864, Acc: 48.34% | Test Loss: 1.34125, Test Acc: 48.67%\n",
      "Epoch: 560 | Loss: 1.32864, Acc: 48.34% | Test Loss: 1.34125, Test Acc: 48.67%\n",
      "Epoch: 570 | Loss: 1.32864, Acc: 48.34% | Test Loss: 1.34125, Test Acc: 48.67%\n",
      "Epoch: 580 | Loss: 1.32864, Acc: 48.34% | Test Loss: 1.34125, Test Acc: 48.67%\n",
      "Epoch: 590 | Loss: 1.32864, Acc: 48.34% | Test Loss: 1.34125, Test Acc: 48.67%\n",
      "Epoch: 600 | Loss: 1.32864, Acc: 48.34% | Test Loss: 1.34125, Test Acc: 48.67%\n",
      "Epoch: 610 | Loss: 1.32864, Acc: 48.34% | Test Loss: 1.34125, Test Acc: 48.67%\n",
      "Epoch: 620 | Loss: 1.32864, Acc: 48.34% | Test Loss: 1.34125, Test Acc: 48.67%\n",
      "Epoch: 630 | Loss: 1.32864, Acc: 48.34% | Test Loss: 1.34126, Test Acc: 48.67%\n",
      "Epoch: 640 | Loss: 1.32864, Acc: 48.34% | Test Loss: 1.34126, Test Acc: 48.67%\n",
      "Epoch: 650 | Loss: 1.32864, Acc: 48.34% | Test Loss: 1.34126, Test Acc: 48.67%\n",
      "Epoch: 660 | Loss: 1.32864, Acc: 48.34% | Test Loss: 1.34126, Test Acc: 48.67%\n",
      "Epoch: 670 | Loss: 1.32864, Acc: 48.34% | Test Loss: 1.34126, Test Acc: 48.67%\n",
      "Epoch: 680 | Loss: 1.32864, Acc: 48.34% | Test Loss: 1.34126, Test Acc: 48.67%\n",
      "Epoch: 690 | Loss: 1.32864, Acc: 48.34% | Test Loss: 1.34126, Test Acc: 48.67%\n",
      "Epoch: 700 | Loss: 1.32864, Acc: 48.34% | Test Loss: 1.34126, Test Acc: 48.67%\n",
      "Epoch: 710 | Loss: 1.32864, Acc: 48.34% | Test Loss: 1.34126, Test Acc: 48.67%\n",
      "Epoch: 720 | Loss: 1.32864, Acc: 48.34% | Test Loss: 1.34126, Test Acc: 48.67%\n",
      "Epoch: 730 | Loss: 1.32864, Acc: 48.34% | Test Loss: 1.34126, Test Acc: 48.67%\n",
      "Epoch: 740 | Loss: 1.32864, Acc: 48.34% | Test Loss: 1.34126, Test Acc: 48.67%\n",
      "Epoch: 750 | Loss: 1.32864, Acc: 48.34% | Test Loss: 1.34126, Test Acc: 48.67%\n",
      "Epoch: 760 | Loss: 1.32864, Acc: 48.34% | Test Loss: 1.34126, Test Acc: 48.67%\n",
      "Epoch: 770 | Loss: 1.32864, Acc: 48.34% | Test Loss: 1.34126, Test Acc: 48.67%\n",
      "Epoch: 780 | Loss: 1.32864, Acc: 48.34% | Test Loss: 1.34126, Test Acc: 48.67%\n",
      "Epoch: 790 | Loss: 1.32864, Acc: 48.34% | Test Loss: 1.34126, Test Acc: 48.67%\n",
      "Epoch: 800 | Loss: 1.32864, Acc: 48.34% | Test Loss: 1.34126, Test Acc: 48.67%\n",
      "Epoch: 810 | Loss: 1.32864, Acc: 48.34% | Test Loss: 1.34126, Test Acc: 48.67%\n",
      "Epoch: 820 | Loss: 1.32864, Acc: 48.34% | Test Loss: 1.34126, Test Acc: 48.67%\n",
      "Epoch: 830 | Loss: 1.32864, Acc: 48.34% | Test Loss: 1.34126, Test Acc: 48.67%\n",
      "Epoch: 840 | Loss: 1.32864, Acc: 48.34% | Test Loss: 1.34126, Test Acc: 48.67%\n",
      "Epoch: 850 | Loss: 1.32864, Acc: 48.34% | Test Loss: 1.34126, Test Acc: 48.67%\n",
      "Epoch: 860 | Loss: 1.32864, Acc: 48.34% | Test Loss: 1.34126, Test Acc: 48.67%\n",
      "Epoch: 870 | Loss: 1.32864, Acc: 48.34% | Test Loss: 1.34126, Test Acc: 48.67%\n",
      "Epoch: 880 | Loss: 1.32864, Acc: 48.34% | Test Loss: 1.34126, Test Acc: 48.67%\n",
      "Epoch: 890 | Loss: 1.32864, Acc: 48.34% | Test Loss: 1.34126, Test Acc: 48.67%\n",
      "Epoch: 900 | Loss: 1.32864, Acc: 48.34% | Test Loss: 1.34126, Test Acc: 48.67%\n",
      "Epoch: 910 | Loss: 1.32864, Acc: 48.34% | Test Loss: 1.34126, Test Acc: 48.67%\n",
      "Epoch: 920 | Loss: 1.32864, Acc: 48.34% | Test Loss: 1.34126, Test Acc: 48.67%\n",
      "Epoch: 930 | Loss: 1.32864, Acc: 48.34% | Test Loss: 1.34126, Test Acc: 48.67%\n",
      "Epoch: 940 | Loss: 1.32864, Acc: 48.34% | Test Loss: 1.34126, Test Acc: 48.67%\n",
      "Epoch: 950 | Loss: 1.32864, Acc: 48.34% | Test Loss: 1.34126, Test Acc: 48.67%\n",
      "Epoch: 960 | Loss: 1.32864, Acc: 48.34% | Test Loss: 1.34126, Test Acc: 48.67%\n",
      "Epoch: 970 | Loss: 1.32864, Acc: 48.34% | Test Loss: 1.34126, Test Acc: 48.67%\n",
      "Epoch: 980 | Loss: 1.32864, Acc: 48.34% | Test Loss: 1.34126, Test Acc: 48.67%\n",
      "Epoch: 990 | Loss: 1.32864, Acc: 48.34% | Test Loss: 1.34126, Test Acc: 48.67%\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Set number of epochs\n",
    "epochs = 1000\n",
    "\n",
    "test_df = pd.read_csv('test_adversary2.dat', sep=',', encoding=\"utf-8\",engine='python')\n",
    "test_df = test_df[['genres', 'rating']]\n",
    "\n",
    "X = torch.tensor(test_df['rating'].values).type(torch.float)\n",
    "Y = torch.tensor(test_df['genres'].astype('category').cat.codes).type(torch.LongTensor)   \n",
    "\n",
    "\n",
    "X_blob_train, X_blob_test, y_blob_train, y_blob_test = train_test_split(X,\n",
    "    Y,\n",
    "    test_size=0.2,\n",
    "    random_state=181\n",
    ")\n",
    "\n",
    "# Put data to target device\n",
    "X_blob_train, y_blob_train = X_blob_train.to(device).view(-1,1), y_blob_train.to(device)\n",
    "X_blob_test, y_blob_test = X_blob_test.to(device).view(-1,1), y_blob_test.to(device)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    ### Training\n",
    "    mlp.train()\n",
    "\n",
    "    # 1. Forward pass\n",
    "    y_logits = mlp(X_blob_train) # model outputs raw logits \n",
    "    y_pred = torch.softmax(y_logits, dim=1).argmax(dim=1) # go from logits -> prediction probabilities -> prediction labels\n",
    "    # print(y_logits)\n",
    "    # 2. Calculate loss and accuracy\n",
    "    loss = loss_fn(y_logits, y_blob_train) \n",
    "    acc = accuracy_fn(y_true=y_blob_train,\n",
    "                      y_pred=y_pred)\n",
    "\n",
    "    # 3. Optimizer zero grad\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # 4. Loss backwards\n",
    "    loss.backward()\n",
    "\n",
    "    # 5. Optimizer step\n",
    "    optimizer.step()\n",
    "\n",
    "    ### Testing\n",
    "    mlp.eval()\n",
    "    with torch.inference_mode():\n",
    "      # 1. Forward pass\n",
    "        test_logits = mlp(X_blob_test)\n",
    "        test_pred = torch.softmax(test_logits, dim=1).argmax(dim=1)\n",
    "      # 2. Calculate test loss and accuracy\n",
    "        test_loss = loss_fn(test_logits, y_blob_test)\n",
    "        test_acc = accuracy_fn(y_true=y_blob_test,\n",
    "                             y_pred=test_pred)\n",
    "\n",
    "    # Print out what's happening\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch: {epoch} | Loss: {loss:.5f}, Acc: {acc:.2f}% | Test Loss: {test_loss:.5f}, Test Acc: {test_acc:.2f}%\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ac77aa2f",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'5'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_33869/628362754.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtest_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Data/train_df.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'python'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'5'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'counts'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'counts'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mgroupby\u001b[0;34m(self, by, axis, level, as_index, sort, group_keys, squeeze, observed, dropna)\u001b[0m\n\u001b[1;32m   1882\u001b[0m         \u001b[0;31m# error: Argument \"squeeze\" to \"SeriesGroupBy\" has incompatible type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1883\u001b[0m         \u001b[0;31m# \"Union[bool, NoDefault]\"; expected \"bool\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1884\u001b[0;31m         return SeriesGroupBy(\n\u001b[0m\u001b[1;32m   1885\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1886\u001b[0m             \u001b[0mkeys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, squeeze, observed, mutated, dropna)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrouper\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_grouper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             grouper, exclusions, obj = get_grouper(\n\u001b[0m\u001b[1;32m    890\u001b[0m                 \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m                 \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/groupby/grouper.py\u001b[0m in \u001b[0;36mget_grouper\u001b[0;34m(obj, key, axis, level, sort, observed, mutated, validate, dropna)\u001b[0m\n\u001b[1;32m    860\u001b[0m                 \u001b[0min_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGrouper\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mgpr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m             \u001b[0;31m# Add key to exclusions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '5'"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv('Data/train_df.csv', sep=',', encoding=\"utf-8\",engine='python', header=None)\n",
    "test_df.iloc[:, 5].groupby(['5']).size().reset_index(name='counts').sort_values(by=['counts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6f57c8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of       Unnamed: 0  movie_id    genres    rating\n",
       "0              4         5    Comedy  3.006757\n",
       "1              8         9    Action  2.656863\n",
       "2             13        14     Drama  3.542484\n",
       "3             17        18  Thriller  3.337580\n",
       "4             18        19    Comedy  2.480720\n",
       "...          ...       ...       ...       ...\n",
       "1689        3700      3947  Thriller  3.472727\n",
       "1690        3701      3948    Comedy  3.635731\n",
       "1691        3702      3949     Drama  4.115132\n",
       "1692        3703      3950     Drama  3.666667\n",
       "1693        3704      3951     Drama  3.900000\n",
       "\n",
       "[1694 rows x 4 columns]>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('test_adversary2.dat', sep=',', encoding=\"utf-8\",engine='python')\n",
    "test_df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "8a63a116",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 2])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_blob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "dbbb0b2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
       "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
       "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
       "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
       "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
       "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
       "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
       "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
       "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
       "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
       "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
       "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
       "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
       "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
       "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
       "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
       "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
       "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
       "        252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265,\n",
       "        266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279,\n",
       "        280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293,\n",
       "        294, 295, 296, 297, 298, 299, 300])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.unique(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e6a683d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5dee3bf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>978824330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>4</td>\n",
       "      <td>978824330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>978824291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>4</td>\n",
       "      <td>978824291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>978824291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  movie_id  rating  timestamp\n",
       "0        0        32       4  978824330\n",
       "1        0        34       4  978824330\n",
       "2        0         4       5  978824291\n",
       "3        0        35       4  978824291\n",
       "4        0        30       4  978824291"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnames = ['user_id', 'movie_id', 'rating', 'timestamp']\n",
    "\n",
    "\n",
    "train = pd.read_csv('Data/ml-1m.train.rating', sep='\\t', encoding=\"utf-8\",engine='python',header=None, names=rnames)\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ace16d1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>978824351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>133</td>\n",
       "      <td>3</td>\n",
       "      <td>978300174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>207</td>\n",
       "      <td>4</td>\n",
       "      <td>978298504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>208</td>\n",
       "      <td>4</td>\n",
       "      <td>978294282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>222</td>\n",
       "      <td>2</td>\n",
       "      <td>978246585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  movie_id  rating  timestamp\n",
       "0        0        25       5  978824351\n",
       "1        1       133       3  978300174\n",
       "2        2       207       4  978298504\n",
       "3        3       208       4  978294282\n",
       "4        4       222       2  978246585"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('Data/ml-1m.test.rating', sep='\\t', encoding=\"utf-8\",engine='python',header=None,  names=rnames)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "50f55d5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>5</td>\n",
       "      <td>402</td>\n",
       "      <td>3</td>\n",
       "      <td>978237813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7628</th>\n",
       "      <td>52</td>\n",
       "      <td>402</td>\n",
       "      <td>4</td>\n",
       "      <td>977979943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8983</th>\n",
       "      <td>61</td>\n",
       "      <td>402</td>\n",
       "      <td>3</td>\n",
       "      <td>977969947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10729</th>\n",
       "      <td>77</td>\n",
       "      <td>402</td>\n",
       "      <td>3</td>\n",
       "      <td>977811982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31983</th>\n",
       "      <td>215</td>\n",
       "      <td>402</td>\n",
       "      <td>1</td>\n",
       "      <td>976864249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971086</th>\n",
       "      <td>5887</td>\n",
       "      <td>402</td>\n",
       "      <td>3</td>\n",
       "      <td>957481438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975314</th>\n",
       "      <td>5916</td>\n",
       "      <td>402</td>\n",
       "      <td>2</td>\n",
       "      <td>957315233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975787</th>\n",
       "      <td>5921</td>\n",
       "      <td>402</td>\n",
       "      <td>3</td>\n",
       "      <td>957297788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981240</th>\n",
       "      <td>5957</td>\n",
       "      <td>402</td>\n",
       "      <td>2</td>\n",
       "      <td>957062785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981494</th>\n",
       "      <td>5959</td>\n",
       "      <td>402</td>\n",
       "      <td>5</td>\n",
       "      <td>957027288</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>119 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  movie_id  rating  timestamp\n",
       "465           5       402       3  978237813\n",
       "7628         52       402       4  977979943\n",
       "8983         61       402       3  977969947\n",
       "10729        77       402       3  977811982\n",
       "31983       215       402       1  976864249\n",
       "...         ...       ...     ...        ...\n",
       "971086     5887       402       3  957481438\n",
       "975314     5916       402       2  957315233\n",
       "975787     5921       402       3  957297788\n",
       "981240     5957       402       2  957062785\n",
       "981494     5959       402       5  957027288\n",
       "\n",
       "[119 rows x 4 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train['movie_id'] == 402]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d755b49c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5596</th>\n",
       "      <td>5596</td>\n",
       "      <td>402</td>\n",
       "      <td>5</td>\n",
       "      <td>959215944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5953</th>\n",
       "      <td>5953</td>\n",
       "      <td>402</td>\n",
       "      <td>1</td>\n",
       "      <td>957707693</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id  movie_id  rating  timestamp\n",
       "5596     5596       402       5  959215944\n",
       "5953     5953       402       1  957707693"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[test['movie_id'] == 402]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "341531b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3704"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['movie_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494ea526",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
